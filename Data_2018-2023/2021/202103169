{"abstracts-retrieval-response": {
    "item": {
        "ait:process-info": {
            "ait:status": {
                "@state": "update",
                "@type": "core",
                "@stage": "S300"
            },
            "ait:date-delivered": {
                "@day": "28",
                "@timestamp": "2023-03-28T05:10:34.000034-04:00",
                "@year": "2023",
                "@month": "03"
            },
            "ait:date-sort": {
                "@day": "01",
                "@year": "2021",
                "@month": "01"
            }
        },
        "xocs:meta": {"xocs:funding-list": {
            "@pui-match": "primary",
            "@has-funding-info": "1",
            "xocs:funding-addon-generated-timestamp": "2021-11-20T23:40:46.045Z",
            "xocs:funding-text": "The authors would like to thank the members of the Thai Natural Language Processing Facebook group and other volunteers who participated in the assessment of the Thai dataset. We also would like to thank the organizers of the Blizzard challenges for providing the quality assessment datasets. Lastly, we wish to thank New Era AI Robotic Inc. for providing the Thai datasets and infrastructures used in this work.",
            "xocs:funding-addon-type": "http://vtw.elsevier.com/data/voc/AddOnTypes/50.7/nlp-car"
        }},
        "bibrecord": {
            "head": {
                "author-group": {
                    "affiliation": {
                        "country": "Thailand",
                        "@afid": "60028190",
                        "@country": "tha",
                        "organization": [
                            {"$": "Department of Computer Engineering"},
                            {"$": "Chulalongkorn University"}
                        ],
                        "affiliation-id": {
                            "@afid": "60028190",
                            "@dptid": "113891981"
                        },
                        "ce:source-text": "Department of Computer Engineering, Chulalongkorn University, Thailand",
                        "@dptid": "113891981"
                    },
                    "author": [
                        {
                            "ce:given-name": "Thananchai",
                            "preferred-name": {
                                "ce:given-name": "Thananchai",
                                "ce:initials": "T.",
                                "ce:surname": "Kongthaworn",
                                "ce:indexed-name": "Kongthaworn T."
                            },
                            "@seq": "1",
                            "ce:initials": "T.",
                            "@_fa": "true",
                            "@type": "auth",
                            "ce:surname": "Kongthaworn",
                            "@auid": "57219740937",
                            "ce:indexed-name": "Kongthaworn T."
                        },
                        {
                            "ce:given-name": "Burin",
                            "preferred-name": {
                                "ce:given-name": "Burin",
                                "ce:initials": "B.",
                                "ce:surname": "Naowarat",
                                "ce:indexed-name": "Naowarat B."
                            },
                            "@seq": "2",
                            "ce:initials": "B.",
                            "@_fa": "true",
                            "@type": "auth",
                            "ce:surname": "Naowarat",
                            "@auid": "57219732667",
                            "ce:indexed-name": "Naowarat B."
                        },
                        {
                            "ce:given-name": "Ekapol",
                            "preferred-name": {
                                "ce:given-name": "Ekapol",
                                "ce:initials": "E.",
                                "ce:surname": "Chuangsuwanich",
                                "ce:indexed-name": "Chuangsuwanich E."
                            },
                            "@seq": "3",
                            "ce:initials": "E.",
                            "@_fa": "true",
                            "@type": "auth",
                            "ce:surname": "Chuangsuwanich",
                            "@auid": "36987854100",
                            "ce:indexed-name": "Chuangsuwanich E."
                        }
                    ]
                },
                "citation-title": "Spectral and latent speech representation distortion for TTS evaluation",
                "abstracts": "© 2021 ISCAOne of the main problems in the development of text-to-speech (TTS) systems is its reliance on subjective measures, typically the Mean Opinion Score (MOS). MOS requires a large number of people to reliably rate each utterance, making the development process slow and expensive. Recent research on speech quality assessment tends to focus on training models to estimate MOS, which requires a large number of training data, something that might not be available in low-resource languages. We propose an objective assessment metric based on the DTW distance using the spectrogram and the high-level features from an Automatic Speech Recognition (ASR) model to cover both acoustic and linguistic information. Experiments on Thai TTS and the Blizzard Challenge datasets show that our method outperformed other baselines in both utterance- and system-level by a large margin in terms of correlation coefficients. Our metric also outperformed the best baseline by 9.58% when used in head-to-head utterance-level comparisons. Ablation studies suggest that the middle layers of the ASR model are most suitable for TTS evaluation when used in conjunction with spectral features.",
                "citation-info": {
                    "author-keywords": {"author-keyword": [
                        {
                            "$": "Speech recognition",
                            "@xml:lang": "eng",
                            "@original": "y"
                        },
                        {
                            "$": "Speech synthesis",
                            "@xml:lang": "eng",
                            "@original": "y"
                        },
                        {
                            "$": "TTS evaluation",
                            "@xml:lang": "eng",
                            "@original": "y"
                        }
                    ]},
                    "citation-type": {"@code": "cp"},
                    "citation-language": {
                        "@language": "English",
                        "@xml:lang": "eng"
                    },
                    "abstract-language": {
                        "@language": "English",
                        "@xml:lang": "eng"
                    }
                },
                "source": {
                    "website": {"ce:e-address": {
                        "$": "https://www.isca-speech.org/iscaweb/index.php/online-archive",
                        "@type": "email"
                    }},
                    "translated-sourcetitle": {
                        "$": "Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH",
                        "@xml:lang": "eng"
                    },
                    "volisspag": {
                        "voliss": {"@volume": "5"},
                        "pagerange": {
                            "@first": "3516",
                            "@last": "3520"
                        }
                    },
                    "@type": "p",
                    "isbn": {
                        "@level": "volume",
                        "$": "9781713836902",
                        "@type": "electronic",
                        "@length": "13"
                    },
                    "additional-srcinfo": {"conferenceinfo": {
                        "confpublication": {"procpartno": "5 of 6"},
                        "confevent": {
                            "confname": "22nd Annual Conference of the International Speech Communication Association, INTERSPEECH 2021",
                            "confnumber": "22",
                            "confseriestitle": "Conference of the International Speech Communication Association",
                            "conflocation": {
                                "@country": "cze",
                                "city": "Brno"
                            },
                            "confcode": "173493",
                            "confdate": {
                                "enddate": {
                                    "@day": "03",
                                    "@year": "2021",
                                    "@month": "09"
                                },
                                "startdate": {
                                    "@day": "30",
                                    "@year": "2021",
                                    "@month": "08"
                                }
                            }
                        }
                    }},
                    "sourcetitle": "Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH",
                    "publicationdate": {
                        "year": "2021",
                        "date-text": {
                            "@xfab-added": "true",
                            "$": "2021"
                        }
                    },
                    "sourcetitle-abbrev": "Proc. Annu. Conf. Int. Speech. Commun. Assoc., INTERSPEECH",
                    "@country": "fra",
                    "issuetitle": "22nd Annual Conference of the International Speech Communication Association, INTERSPEECH 2021",
                    "issn": [
                        {
                            "$": "19909772",
                            "@type": "electronic"
                        },
                        {
                            "$": "2308457X",
                            "@type": "print"
                        }
                    ],
                    "publicationyear": {"@first": "2021"},
                    "publisher": {"publishername": "International Speech Communication Association"},
                    "@srcid": "21100212301"
                },
                "enhancement": {"classificationgroup": {"classifications": [
                    {
                        "@type": "ASJC",
                        "classification": [
                            {"$": "1203"},
                            {"$": "1709"},
                            {"$": "1711"},
                            {"$": "1712"},
                            {"$": "2611"}
                        ]
                    },
                    {
                        "@type": "CPXCLASS",
                        "classification": [
                            {
                                "classification-code": "723.2",
                                "classification-description": "Data Processing and Image Processing"
                            },
                            {
                                "classification-code": "751.5",
                                "classification-description": "Speech"
                            }
                        ]
                    },
                    {
                        "@type": "FLXCLASS",
                        "classification": {
                            "classification-code": "902",
                            "classification-description": "FLUIDEX; Related Topics"
                        }
                    },
                    {
                        "@type": "SUBJABBR",
                        "classification": [
                            {"$": "ARTS"},
                            {"$": "COMP"},
                            {"$": "MATH"}
                        ]
                    }
                ]}},
                "grantlist": {
                    "@complete": "y",
                    "grant-text": {
                        "$": "The authors would like to thank the members of the Thai Natural Language Processing Facebook group and other volunteers who participated in the assessment of the Thai dataset. We also would like to thank the organizers of the Blizzard challenges for providing the quality assessment datasets. Lastly, we wish to thank New Era AI Robotic Inc. for providing the Thai datasets and infrastructures used in this work.",
                        "@xml:lang": "eng"
                    },
                    "grant": {
                        "grant-acronym": "FB",
                        "grant-agency": {
                            "@iso-code": "usa",
                            "$": "Facebook"
                        },
                        "grant-agency-id": "100005801"
                    }
                }
            },
            "item-info": {
                "copyright": {
                    "$": "Copyright 2021 Elsevier B.V., All rights reserved.",
                    "@type": "Elsevier"
                },
                "dbcollection": [
                    {"$": "CPX"},
                    {"$": "SCOPUS"},
                    {"$": "Scopusbase"}
                ],
                "history": {"date-created": {
                    "@day": "20",
                    "@timestamp": "BST 17:01:28",
                    "@year": "2021",
                    "@month": "11"
                }},
                "itemidlist": {
                    "itemid": [
                        {
                            "$": "636468518",
                            "@idtype": "PUI"
                        },
                        {
                            "$": "936803791",
                            "@idtype": "CAR-ID"
                        },
                        {
                            "$": "20214711190499",
                            "@idtype": "CPX"
                        },
                        {
                            "$": "20213869270",
                            "@idtype": "SCOPUS"
                        },
                        {
                            "$": "85119205081",
                            "@idtype": "SCP"
                        },
                        {
                            "$": "85119205081",
                            "@idtype": "SGR"
                        }
                    ],
                    "ce:doi": "10.21437/Interspeech.2021-2258"
                }
            },
            "tail": {"bibliography": {
                "@refcount": "31",
                "reference": [
                    {
                        "@aii:was-generated-by": "http://data.elsevier.com/art/structure-references art:version v1.0.181",
                        "ref-fulltext": "M. H. Soni and H. A. Patil, \u201cNon-intrusive quality assessment of synthesized speech using spectral features and support vector regression,\u201d in 9th ISCA Speech Synthesis Workshop, 2016, pp. 127-133. [Online]. Available: http://dx.doi.org/10.21437/SSW. 2016-21",
                        "@id": "1",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2016"},
                            "ref-website": {"ce:e-address": {
                                "$": "http://dx.doi.org/10.21437/SSW.2016-21",
                                "@type": "email"
                            }},
                            "ref-title": {"ref-titletext": "Non-intrusive quality assessment of synthesized speech using spectral features and support vector regression"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85098211862",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "127",
                                "@last": "133"
                            }},
                            "ref-text": "[Online]. Available",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "M. H.",
                                    "@_fa": "true",
                                    "ce:surname": "Soni",
                                    "ce:indexed-name": "Soni M. H."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "H. A.",
                                    "@_fa": "true",
                                    "ce:surname": "Patil",
                                    "ce:indexed-name": "Patil H. A."
                                }
                            ]},
                            "ref-sourcetitle": "9th ISCA Speech Synthesis Workshop"
                        },
                        "ce:source-text": "M. H. Soni and H. A. Patil, \u201cNon-intrusive quality assessment of synthesized speech using spectral features and support vector regression,\u201d in 9th ISCA Speech Synthesis Workshop, 2016, pp. 127-133. [Online]. Available: http://dx.doi.org/10.21437/SSW. 2016-21"
                    },
                    {
                        "@aii:was-generated-by": "http://data.elsevier.com/art/structure-references art:version v1.0.181",
                        "ref-fulltext": "Qiang Fu, Kechu Yi, and Mingui Sun, \u201cSpeech quality objective assessment using neural network,\u201d in ICASSP 2000, vol. 3, 2000, pp. 1511-1514 vol.3.",
                        "@id": "2",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2000"},
                            "ref-title": {"ref-titletext": "Speech quality objective assessment using neural network"},
                            "refd-itemidlist": {"itemid": {
                                "$": "0033719625",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {"@volume": "3"},
                                "pagerange": {
                                    "@first": "1511",
                                    "@last": "1514"
                                }
                            },
                            "ref-text": "2000, vol.3",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "Qiang",
                                    "@_fa": "true",
                                    "ce:surname": "Fu",
                                    "ce:indexed-name": "Fu Qiang"
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "Kechu",
                                    "@_fa": "true",
                                    "ce:surname": "Yi",
                                    "ce:indexed-name": "Yi Kechu"
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "Mingui",
                                    "@_fa": "true",
                                    "ce:surname": "Sun",
                                    "ce:indexed-name": "Sun Mingui"
                                }
                            ]},
                            "ref-sourcetitle": "ICASSP"
                        },
                        "ce:source-text": "Qiang Fu, Kechu Yi, and Mingui Sun, \u201cSpeech quality objective assessment using neural network,\u201d in ICASSP 2000, vol. 3, 2000, pp. 1511-1514 vol.3."
                    },
                    {
                        "@aii:was-generated-by": "http://data.elsevier.com/art/structure-references art:version v1.0.181",
                        "ref-fulltext": "S.-W. Fu, Y. Tsao, H.-T. Hwang, and H.-M. Wang, \u201cQuality-Net: An end-to-end non-intrusive speech quality assessment model based on blstm,\u201d in Interspeech, 2018.",
                        "@id": "3",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2018"},
                            "ref-title": {"ref-titletext": "Quality-Net: An end-to-end non-intrusive speech quality assessment model based on blstm"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85054977942",
                                "@idtype": "SGR"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "S.-W.",
                                    "@_fa": "true",
                                    "ce:surname": "Fu",
                                    "ce:indexed-name": "Fu S.-W."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Tsao",
                                    "ce:indexed-name": "Tsao Y."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "H.-T.",
                                    "@_fa": "true",
                                    "ce:surname": "Hwang",
                                    "ce:indexed-name": "Hwang H.-T."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "H.-M.",
                                    "@_fa": "true",
                                    "ce:surname": "Wang",
                                    "ce:indexed-name": "Wang H.-M."
                                }
                            ]},
                            "ref-sourcetitle": "Interspeech"
                        },
                        "ce:source-text": "S.-W. Fu, Y. Tsao, H.-T. Hwang, and H.-M. Wang, \u201cQuality-Net: An end-to-end non-intrusive speech quality assessment model based on blstm,\u201d in Interspeech, 2018."
                    },
                    {
                        "@aii:was-generated-by": "http://data.elsevier.com/art/structure-references art:version v1.0.181",
                        "ref-fulltext": "M. Tang and J. Zhu, \u201cText-to-speech quality evaluation based on lstm recurrent neural networks,\u201d in 2019 International Conference on Computing, Networking and Communications (ICNC), 2019, pp. 260-264.",
                        "@id": "4",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2019"},
                            "ref-title": {"ref-titletext": "Text-to-speech quality evaluation based on lstm recurrent neural networks"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85064972225",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "260",
                                "@last": "264"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "M.",
                                    "@_fa": "true",
                                    "ce:surname": "Tang",
                                    "ce:indexed-name": "Tang M."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "J.",
                                    "@_fa": "true",
                                    "ce:surname": "Zhu",
                                    "ce:indexed-name": "Zhu J."
                                }
                            ]},
                            "ref-sourcetitle": "2019 International Conference on Computing, Networking and Communications (ICNC)"
                        },
                        "ce:source-text": "M. Tang and J. Zhu, \u201cText-to-speech quality evaluation based on lstm recurrent neural networks,\u201d in 2019 International Conference on Computing, Networking and Communications (ICNC), 2019, pp. 260-264."
                    },
                    {
                        "@aii:was-generated-by": "http://data.elsevier.com/art/structure-references art:version v1.0.181",
                        "ref-fulltext": "A. R. Avila, H. Gamper, C. Reddy, R. Cutler, I. Tashev, and J. Gehrke, \u201cNon-intrusive speech quality assessment using neural networks,\u201d in ICASSP 2019, 2019, pp. 631-635.",
                        "@id": "5",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2019"},
                            "ref-title": {"ref-titletext": "Non-intrusive speech quality assessment using neural networks"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85068967232",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "631",
                                "@last": "635"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "A. R.",
                                    "@_fa": "true",
                                    "ce:surname": "Avila",
                                    "ce:indexed-name": "Avila A. R."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "H.",
                                    "@_fa": "true",
                                    "ce:surname": "Gamper",
                                    "ce:indexed-name": "Gamper H."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "C.",
                                    "@_fa": "true",
                                    "ce:surname": "Reddy",
                                    "ce:indexed-name": "Reddy C."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "R.",
                                    "@_fa": "true",
                                    "ce:surname": "Cutler",
                                    "ce:indexed-name": "Cutler R."
                                },
                                {
                                    "@seq": "5",
                                    "ce:initials": "I.",
                                    "@_fa": "true",
                                    "ce:surname": "Tashev",
                                    "ce:indexed-name": "Tashev I."
                                },
                                {
                                    "@seq": "6",
                                    "ce:initials": "J.",
                                    "@_fa": "true",
                                    "ce:surname": "Gehrke",
                                    "ce:indexed-name": "Gehrke J."
                                }
                            ]},
                            "ref-sourcetitle": "ICASSP 2019"
                        },
                        "ce:source-text": "A. R. Avila, H. Gamper, C. Reddy, R. Cutler, I. Tashev, and J. Gehrke, \u201cNon-intrusive speech quality assessment using neural networks,\u201d in ICASSP 2019, 2019, pp. 631-635."
                    },
                    {
                        "@aii:was-generated-by": "http://data.elsevier.com/art/structure-references art:version v1.0.181",
                        "ref-fulltext": "G. Mittag and S. Möller, \u201cDeep Learning Based Assessment of Synthetic Speech Naturalness,\u201d in Interspeech 2020, 2020, pp. 1748-1752. [Online]. Available: http://dx.doi.org/10.21437/Interspeech.2020-2382",
                        "@id": "6",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2020"},
                            "ref-website": {"ce:e-address": {
                                "$": "http://dx.doi.org/10.21437/Interspeech.2020-2382",
                                "@type": "email"
                            }},
                            "ref-title": {"ref-titletext": "Deep Learning Based Assessment of Synthetic Speech Naturalness"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85098172498",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "1748",
                                "@last": "1752"
                            }},
                            "ref-text": "[Online]. Available",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "G.",
                                    "@_fa": "true",
                                    "ce:surname": "Mittag",
                                    "ce:indexed-name": "Mittag G."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Möller",
                                    "ce:indexed-name": "Moller S."
                                }
                            ]},
                            "ref-sourcetitle": "Interspeech 2020"
                        },
                        "ce:source-text": "G. Mittag and S. Möller, \u201cDeep Learning Based Assessment of Synthetic Speech Naturalness,\u201d in Interspeech 2020, 2020, pp. 1748-1752. [Online]. Available: http://dx.doi.org/10.21437/Interspeech.2020-2382"
                    },
                    {
                        "@aii:was-generated-by": "http://data.elsevier.com/art/structure-references art:version v1.0.181",
                        "ref-fulltext": "R. Kubichek, \u201cMel-cepstral distance measure for objective speech quality assessment,\u201d in Proceedings of IEEE Pacific Rim Conference on Communications Computers and Signal Processing, vol. 1, 1993, pp. 125-128 vol.1.",
                        "@id": "7",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "1993"},
                            "ref-title": {"ref-titletext": "Mel-cepstral distance measure for objective speech quality assessment"},
                            "refd-itemidlist": {"itemid": {
                                "$": "0027247004",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {"@volume": "1"},
                                "pagerange": {
                                    "@first": "125",
                                    "@last": "128"
                                }
                            },
                            "ref-text": "vol.1",
                            "ref-authors": {"author": [{
                                "@seq": "1",
                                "ce:initials": "R.",
                                "@_fa": "true",
                                "ce:surname": "Kubichek",
                                "ce:indexed-name": "Kubichek R."
                            }]},
                            "ref-sourcetitle": "Proceedings of IEEE Pacific Rim Conference on Communications Computers and Signal Processing"
                        },
                        "ce:source-text": "R. Kubichek, \u201cMel-cepstral distance measure for objective speech quality assessment,\u201d in Proceedings of IEEE Pacific Rim Conference on Communications Computers and Signal Processing, vol. 1, 1993, pp. 125-128 vol.1."
                    },
                    {
                        "@aii:was-generated-by": "http://data.elsevier.com/art/structure-references art:version v1.0.181",
                        "ref-fulltext": "S. Wang, A. Sekey, and A. Gersho, \u201cAn objective measure for predicting subjective quality of speech coders,\u201d IEEE Journal on Selected Areas in Communications, vol. 10, no. 5, pp. 819-829, 1992.",
                        "@id": "8",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "1992"},
                            "ref-title": {"ref-titletext": "An objective measure for predicting subjective quality of speech coders"},
                            "refd-itemidlist": {"itemid": {
                                "$": "0000008694",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {
                                    "@volume": "10",
                                    "@issue": "5"
                                },
                                "pagerange": {
                                    "@first": "819",
                                    "@last": "829"
                                }
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Wang",
                                    "ce:indexed-name": "Wang S."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "A.",
                                    "@_fa": "true",
                                    "ce:surname": "Sekey",
                                    "ce:indexed-name": "Sekey A."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "A.",
                                    "@_fa": "true",
                                    "ce:surname": "Gersho",
                                    "ce:indexed-name": "Gersho A."
                                }
                            ]},
                            "ref-sourcetitle": "IEEE Journal on Selected Areas in Communications"
                        },
                        "ce:source-text": "S. Wang, A. Sekey, and A. Gersho, \u201cAn objective measure for predicting subjective quality of speech coders,\u201d IEEE Journal on Selected Areas in Communications, vol. 10, no. 5, pp. 819-829, 1992."
                    },
                    {
                        "@aii:was-generated-by": "http://data.elsevier.com/art/structure-references art:version v1.0.181",
                        "ref-fulltext": "S. Rao, C. Mahima, S. Vishnu, S. Adithya, A. Sricharan, and V. Ramasubramanian, \u201cTTS evaluation: Double-ended objective quality measures,\u201d in 2015 IEEE International Conference on Electronics, Computing and Communication Technologies (CONECCT), 2015, pp. 1-6.",
                        "@id": "9",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2015"},
                            "ref-title": {"ref-titletext": "TTS evaluation: Double-ended objective quality measures"},
                            "refd-itemidlist": {"itemid": {
                                "$": "84964761831",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "1",
                                "@last": "6"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Rao",
                                    "ce:indexed-name": "Rao S."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "C.",
                                    "@_fa": "true",
                                    "ce:surname": "Mahima",
                                    "ce:indexed-name": "Mahima C."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Vishnu",
                                    "ce:indexed-name": "Vishnu S."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Adithya",
                                    "ce:indexed-name": "Adithya S."
                                },
                                {
                                    "@seq": "5",
                                    "ce:initials": "A.",
                                    "@_fa": "true",
                                    "ce:surname": "Sricharan",
                                    "ce:indexed-name": "Sricharan A."
                                },
                                {
                                    "@seq": "6",
                                    "ce:initials": "V.",
                                    "@_fa": "true",
                                    "ce:surname": "Ramasubramanian",
                                    "ce:indexed-name": "Ramasubramanian V."
                                }
                            ]},
                            "ref-sourcetitle": "2015 IEEE International Conference on Electronics, Computing and Communication Technologies (CONECCT)"
                        },
                        "ce:source-text": "S. Rao, C. Mahima, S. Vishnu, S. Adithya, A. Sricharan, and V. Ramasubramanian, \u201cTTS evaluation: Double-ended objective quality measures,\u201d in 2015 IEEE International Conference on Electronics, Computing and Communication Technologies (CONECCT), 2015, pp. 1-6."
                    },
                    {
                        "@aii:was-generated-by": "http://data.elsevier.com/art/structure-references art:version v1.0.181",
                        "ref-fulltext": "H. B. Sailor and H. A. Patil, \u201cFusion of magnitude and phase-based features for objective evaluation of TTS voice,\u201d Proceedings of the 9th International Symposium on Chinese Spoken Language Processing, ISCSLP 2014, pp. 521-525, 2014.",
                        "@id": "10",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2014"},
                            "ref-title": {"ref-titletext": "Fusion of magnitude and phase-based features for objective evaluation of TTS voice"},
                            "refd-itemidlist": {"itemid": {
                                "$": "84912075070",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "521",
                                "@last": "525"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "H. B.",
                                    "@_fa": "true",
                                    "ce:surname": "Sailor",
                                    "ce:indexed-name": "Sailor H. B."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "H. A.",
                                    "@_fa": "true",
                                    "ce:surname": "Patil",
                                    "ce:indexed-name": "Patil H. A."
                                }
                            ]},
                            "ref-sourcetitle": "Proceedings of the 9th International Symposium on Chinese Spoken Language Processing, ISCSLP 2014"
                        },
                        "ce:source-text": "H. B. Sailor and H. A. Patil, \u201cFusion of magnitude and phase-based features for objective evaluation of TTS voice,\u201d Proceedings of the 9th International Symposium on Chinese Spoken Language Processing, ISCSLP 2014, pp. 521-525, 2014."
                    },
                    {
                        "@aii:was-generated-by": "http://data.elsevier.com/art/structure-references art:version v1.0.181",
                        "ref-fulltext": "M. Binkowski, J. Donahue, S. Dieleman, A. Clark, E. Elsen, N. Casagrande, L. C. Cobo, and K. Simonyan, \u201cHigh fidelity speech synthesis with adversarial networks,\u201d in International Conference on Learning Representations, 2020.",
                        "@id": "11",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2020"},
                            "ref-title": {"ref-titletext": "High fidelity speech synthesis with adversarial networks"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85150617183",
                                "@idtype": "SGR"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "M.",
                                    "@_fa": "true",
                                    "ce:surname": "Binkowski",
                                    "ce:indexed-name": "Binkowski M."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "J.",
                                    "@_fa": "true",
                                    "ce:surname": "Donahue",
                                    "ce:indexed-name": "Donahue J."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Dieleman",
                                    "ce:indexed-name": "Dieleman S."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "A.",
                                    "@_fa": "true",
                                    "ce:surname": "Clark",
                                    "ce:indexed-name": "Clark A."
                                },
                                {
                                    "@seq": "5",
                                    "ce:initials": "E.",
                                    "@_fa": "true",
                                    "ce:surname": "Elsen",
                                    "ce:indexed-name": "Elsen E."
                                },
                                {
                                    "@seq": "6",
                                    "ce:initials": "N.",
                                    "@_fa": "true",
                                    "ce:surname": "Casagrande",
                                    "ce:indexed-name": "Casagrande N."
                                },
                                {
                                    "@seq": "7",
                                    "ce:initials": "L. C.",
                                    "@_fa": "true",
                                    "ce:surname": "Cobo",
                                    "ce:indexed-name": "Cobo L. C."
                                },
                                {
                                    "@seq": "8",
                                    "ce:initials": "K.",
                                    "@_fa": "true",
                                    "ce:surname": "Simonyan",
                                    "ce:indexed-name": "Simonyan K."
                                }
                            ]},
                            "ref-sourcetitle": "International Conference on Learning Representations"
                        },
                        "ce:source-text": "M. Binkowski, J. Donahue, S. Dieleman, A. Clark, E. Elsen, N. Casagrande, L. C. Cobo, and K. Simonyan, \u201cHigh fidelity speech synthesis with adversarial networks,\u201d in International Conference on Learning Representations, 2020."
                    },
                    {
                        "@aii:was-generated-by": "http://data.elsevier.com/art/structure-references art:version v1.0.181",
                        "ref-fulltext": "Y. Belinkov and J. Glass, \u201cAnalyzing hidden representations in end-to-end automatic speech recognition systems,\u201d in Advances in Neural Information Processing Systems (NIPS), December 2017.",
                        "@id": "12",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2017"},
                            "ref-title": {"ref-titletext": "Analyzing hidden representations in end-to-end automatic speech recognition systems"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85047004778",
                                "@idtype": "SGR"
                            }},
                            "ref-text": "December",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Belinkov",
                                    "ce:indexed-name": "Belinkov Y."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "J.",
                                    "@_fa": "true",
                                    "ce:surname": "Glass",
                                    "ce:indexed-name": "Glass J."
                                }
                            ]},
                            "ref-sourcetitle": "Advances in Neural Information Processing Systems (NIPS)"
                        },
                        "ce:source-text": "Y. Belinkov and J. Glass, \u201cAnalyzing hidden representations in end-to-end automatic speech recognition systems,\u201d in Advances in Neural Information Processing Systems (NIPS), December 2017."
                    },
                    {
                        "@aii:was-generated-by": "http://data.elsevier.com/art/structure-references art:version v1.0.181",
                        "ref-fulltext": "C. Li, P. Yuan, and H. Lee, \u201cWhat does a network layer hear? Analyzing hidden representations of end-to-end ASR through speech synthesis,\u201d in ICASSP 2020, 2020, pp. 6434-6438.",
                        "@id": "13",
                        "ref-info": {
                            "ref-title": {"ref-titletext": "What does a network layer hear? Analyzing hidden representations of end-to-end ASR through speech synthesis"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85091313173",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {"@volume": "2020"},
                                "pagerange": {
                                    "@first": "6434",
                                    "@last": "6438"
                                }
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "C.",
                                    "@_fa": "true",
                                    "ce:surname": "Li",
                                    "ce:indexed-name": "Li C."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "P.",
                                    "@_fa": "true",
                                    "ce:surname": "Yuan",
                                    "ce:indexed-name": "Yuan P."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "H.",
                                    "@_fa": "true",
                                    "ce:surname": "Lee",
                                    "ce:indexed-name": "Lee H."
                                }
                            ]},
                            "ref-sourcetitle": "ICASSP 2020"
                        },
                        "ce:source-text": "C. Li, P. Yuan, and H. Lee, \u201cWhat does a network layer hear? Analyzing hidden representations of end-to-end ASR through speech synthesis,\u201d in ICASSP 2020, 2020, pp. 6434-6438."
                    },
                    {
                        "@aii:was-generated-by": "http://data.elsevier.com/art/structure-references art:version v1.0.181",
                        "ref-fulltext": "Y. Belinkov, A. Ali, and J. Glass, \u201cAnalyzing phonetic and graphemic representations in end-to-end automatic speech recognition,\u201d in Advances in Neural Information Processing Systems (NIPS), 09 2019, pp. 81-85.",
                        "@id": "14",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2019"},
                            "ref-title": {"ref-titletext": "Analyzing phonetic and graphemic representations in end-to-end automatic speech recognition"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85074733942",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "81",
                                "@last": "85"
                            }},
                            "ref-text": "09",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Belinkov",
                                    "ce:indexed-name": "Belinkov Y."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "A.",
                                    "@_fa": "true",
                                    "ce:surname": "Ali",
                                    "ce:indexed-name": "Ali A."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "J.",
                                    "@_fa": "true",
                                    "ce:surname": "Glass",
                                    "ce:indexed-name": "Glass J."
                                }
                            ]},
                            "ref-sourcetitle": "Advances in Neural Information Processing Systems (NIPS)"
                        },
                        "ce:source-text": "Y. Belinkov, A. Ali, and J. Glass, \u201cAnalyzing phonetic and graphemic representations in end-to-end automatic speech recognition,\u201d in Advances in Neural Information Processing Systems (NIPS), 09 2019, pp. 81-85."
                    },
                    {
                        "@aii:was-generated-by": "http://data.elsevier.com/art/structure-references art:version v1.0.181",
                        "ref-fulltext": "H. Sakoe and S. Chiba, \u201cDynamic programming algorithm optimization for spoken word recognition,\u201d IEEE Transactions on Acoustics, Speech, and Signal Processing, vol. 26, no. 1, pp. 43-49, 1978.",
                        "@id": "15",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "1978"},
                            "ref-title": {"ref-titletext": "Dynamic programming algorithm optimization for spoken word recognition"},
                            "refd-itemidlist": {"itemid": {
                                "$": "0017930815",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {
                                    "@volume": "26",
                                    "@issue": "1"
                                },
                                "pagerange": {
                                    "@first": "43",
                                    "@last": "49"
                                }
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "H.",
                                    "@_fa": "true",
                                    "ce:surname": "Sakoe",
                                    "ce:indexed-name": "Sakoe H."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Chiba",
                                    "ce:indexed-name": "Chiba S."
                                }
                            ]},
                            "ref-sourcetitle": "IEEE Transactions on Acoustics, Speech, and Signal Processing"
                        },
                        "ce:source-text": "H. Sakoe and S. Chiba, \u201cDynamic programming algorithm optimization for spoken word recognition,\u201d IEEE Transactions on Acoustics, Speech, and Signal Processing, vol. 26, no. 1, pp. 43-49, 1978."
                    },
                    {
                        "@aii:was-generated-by": "http://data.elsevier.com/art/structure-references art:version v1.0.181",
                        "ref-fulltext": "H. Sakoe and S. Chiba, \u201cA dynamic programming approach to continuous speech recognition,\u201d in Proceedings of the Seventh International Congress on Acoustics, Budapest, vol. 3. Budapest: Akadémiai Kiadó, 1971, pp. 65-69.",
                        "@id": "16",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "1971"},
                            "ref-title": {"ref-titletext": "A dynamic programming approach to continuous speech recognition"},
                            "refd-itemidlist": {"itemid": {
                                "$": "0005670423",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {"@volume": "3"},
                                "pagerange": {
                                    "@first": "65",
                                    "@last": "69"
                                }
                            },
                            "ref-text": "Budapest, Budapest: Akadémiai Kiadó",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "H.",
                                    "@_fa": "true",
                                    "ce:surname": "Sakoe",
                                    "ce:indexed-name": "Sakoe H."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Chiba",
                                    "ce:indexed-name": "Chiba S."
                                }
                            ]},
                            "ref-sourcetitle": "Proceedings of the Seventh International Congress on Acoustics"
                        },
                        "ce:source-text": "H. Sakoe and S. Chiba, \u201cA dynamic programming approach to continuous speech recognition,\u201d in Proceedings of the Seventh International Congress on Acoustics, Budapest, vol. 3. Budapest: Akadémiai Kiadó, 1971, pp. 65-69."
                    },
                    {
                        "@aii:was-generated-by": "http://data.elsevier.com/art/structure-references art:version v1.0.181",
                        "ref-fulltext": "S. King and V. Karaiskos, \u201cThe Blizzard Challenge 2012,\u201d in Proceedings of the Blizzard Challenge workshop 2012, 2012.",
                        "@id": "17",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2012"},
                            "ref-title": {"ref-titletext": "The Blizzard Challenge 2012"},
                            "refd-itemidlist": {"itemid": {
                                "$": "84890516589",
                                "@idtype": "SGR"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "King",
                                    "ce:indexed-name": "King S."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "V.",
                                    "@_fa": "true",
                                    "ce:surname": "Karaiskos",
                                    "ce:indexed-name": "Karaiskos V."
                                }
                            ]},
                            "ref-sourcetitle": "Proceedings of the Blizzard Challenge workshop 2012"
                        },
                        "ce:source-text": "S. King and V. Karaiskos, \u201cThe Blizzard Challenge 2012,\u201d in Proceedings of the Blizzard Challenge workshop 2012, 2012."
                    },
                    {
                        "@aii:was-generated-by": "http://data.elsevier.com/art/structure-references art:version v1.0.181",
                        "ref-fulltext": "S. King and V. Karaiskos, \u201cThe Blizzard Challenge 2013,\u201d in Proceedings of the Blizzard Challenge workshop 2013, 2013.",
                        "@id": "18",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2013"},
                            "ref-title": {"ref-titletext": "The Blizzard Challenge 2013"},
                            "refd-itemidlist": {"itemid": {
                                "$": "84904680338",
                                "@idtype": "SGR"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "King",
                                    "ce:indexed-name": "King S."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "V.",
                                    "@_fa": "true",
                                    "ce:surname": "Karaiskos",
                                    "ce:indexed-name": "Karaiskos V."
                                }
                            ]},
                            "ref-sourcetitle": "Proceedings of the Blizzard Challenge workshop 2013"
                        },
                        "ce:source-text": "S. King and V. Karaiskos, \u201cThe Blizzard Challenge 2013,\u201d in Proceedings of the Blizzard Challenge workshop 2013, 2013."
                    },
                    {
                        "@aii:was-generated-by": "http://data.elsevier.com/art/structure-references art:version v1.0.181",
                        "ref-fulltext": "O. Kuchaiev, B. Ginsburg, I. Gitman, V. Lavrukhin, J. Li, H. Nguyen, C. Case, and P. Micikevicius, \u201cMixed-Precision Training for NLP and Speech Recognition with OpenSeq2Seq,\u201d 2018.",
                        "@id": "19",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2018"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85068994305",
                                "@idtype": "SGR"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "O.",
                                    "@_fa": "true",
                                    "ce:surname": "Kuchaiev",
                                    "ce:indexed-name": "Kuchaiev O."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "B.",
                                    "@_fa": "true",
                                    "ce:surname": "Ginsburg",
                                    "ce:indexed-name": "Ginsburg B."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "I.",
                                    "@_fa": "true",
                                    "ce:surname": "Gitman",
                                    "ce:indexed-name": "Gitman I."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "V.",
                                    "@_fa": "true",
                                    "ce:surname": "Lavrukhin",
                                    "ce:indexed-name": "Lavrukhin V."
                                },
                                {
                                    "@seq": "5",
                                    "ce:initials": "J.",
                                    "@_fa": "true",
                                    "ce:surname": "Li",
                                    "ce:indexed-name": "Li J."
                                },
                                {
                                    "@seq": "6",
                                    "ce:initials": "H.",
                                    "@_fa": "true",
                                    "ce:surname": "Nguyen",
                                    "ce:indexed-name": "Nguyen H."
                                },
                                {
                                    "@seq": "7",
                                    "ce:initials": "C.",
                                    "@_fa": "true",
                                    "ce:surname": "Case",
                                    "ce:indexed-name": "Case C."
                                },
                                {
                                    "@seq": "8",
                                    "ce:initials": "P.",
                                    "@_fa": "true",
                                    "ce:surname": "Micikevicius",
                                    "ce:indexed-name": "Micikevicius P."
                                }
                            ]},
                            "ref-sourcetitle": "Mixed-Precision Training for NLP and Speech Recognition with OpenSeq2Seq"
                        },
                        "ce:source-text": "O. Kuchaiev, B. Ginsburg, I. Gitman, V. Lavrukhin, J. Li, H. Nguyen, C. Case, and P. Micikevicius, \u201cMixed-Precision Training for NLP and Speech Recognition with OpenSeq2Seq,\u201d 2018."
                    },
                    {
                        "@aii:was-generated-by": "http://data.elsevier.com/art/structure-references art:version v1.0.181",
                        "ref-fulltext": "B. Naowarat, T. Kongthaworn, K. Karunratanakul, S. H. Wu, and E. Chuangsuwanich, \u201cReducing Spelling Inconsistencies in Code-Switching ASR using Contextualized CTC Loss,\u201d in ICASSP 2021, 2021.",
                        "@id": "20",
                        "ref-info": {
                            "ref-title": {"ref-titletext": "Reducing Spelling Inconsistencies in Code-Switching ASR using Contextualized CTC Loss"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85115158645",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {"@volume": "2021"},
                                "pagerange": {"@first": "2021"}
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "B.",
                                    "@_fa": "true",
                                    "ce:surname": "Naowarat",
                                    "ce:indexed-name": "Naowarat B."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "T.",
                                    "@_fa": "true",
                                    "ce:surname": "Kongthaworn",
                                    "ce:indexed-name": "Kongthaworn T."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "K.",
                                    "@_fa": "true",
                                    "ce:surname": "Karunratanakul",
                                    "ce:indexed-name": "Karunratanakul K."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "S. H.",
                                    "@_fa": "true",
                                    "ce:surname": "Wu",
                                    "ce:indexed-name": "Wu S. H."
                                },
                                {
                                    "@seq": "5",
                                    "ce:initials": "E.",
                                    "@_fa": "true",
                                    "ce:surname": "Chuangsuwanich",
                                    "ce:indexed-name": "Chuangsuwanich E."
                                }
                            ]},
                            "ref-sourcetitle": "ICASSP"
                        },
                        "ce:source-text": "B. Naowarat, T. Kongthaworn, K. Karunratanakul, S. H. Wu, and E. Chuangsuwanich, \u201cReducing Spelling Inconsistencies in Code-Switching ASR using Contextualized CTC Loss,\u201d in ICASSP 2021, 2021."
                    },
                    {
                        "@aii:was-generated-by": "http://data.elsevier.com/art/structure-references art:version v1.0.181",
                        "ref-fulltext": "S. Salvador and P. Chan, \u201cFastDTW: Toward accurate dynamic time warping in linear time and space,\u201d Intelligent Data Analysis, vol. 11, no. 5, pp. 561-580, 2007.",
                        "@id": "21",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2007"},
                            "ref-title": {"ref-titletext": "FastDTW: Toward accurate dynamic time warping in linear time and space"},
                            "refd-itemidlist": {"itemid": {
                                "$": "41749090269",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {
                                    "@volume": "11",
                                    "@issue": "5"
                                },
                                "pagerange": {
                                    "@first": "561",
                                    "@last": "580"
                                }
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Salvador",
                                    "ce:indexed-name": "Salvador S."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "P.",
                                    "@_fa": "true",
                                    "ce:surname": "Chan",
                                    "ce:indexed-name": "Chan P."
                                }
                            ]},
                            "ref-sourcetitle": "Intelligent Data Analysis"
                        },
                        "ce:source-text": "S. Salvador and P. Chan, \u201cFastDTW: Toward accurate dynamic time warping in linear time and space,\u201d Intelligent Data Analysis, vol. 11, no. 5, pp. 561-580, 2007."
                    },
                    {
                        "@aii:was-generated-by": "http://data.elsevier.com/art/structure-references art:version v1.0.181",
                        "ref-fulltext": "J. Shen, R. Pang, R. J. Weiss, M. Schuster, N. Jaitly, Z. Yang, Z. Chen, Y. Zhang, Y. Wang, R. Skerrv-Ryan, R. A. Saurous, Y. Agiomvrgiannakis, and Y. Wu, \u201cNatural TTS synthesis by conditioning wavenet on mel spectrogram predictions,\u201d in ICASSP 2018, 2018, pp. 4779-4783.",
                        "@id": "22",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2018"},
                            "ref-title": {"ref-titletext": "Natural TTS synthesis by conditioning wavenet on mel spectrogram predictions"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85052990096",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "4779",
                                "@last": "4783"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "J.",
                                    "@_fa": "true",
                                    "ce:surname": "Shen",
                                    "ce:indexed-name": "Shen J."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "R.",
                                    "@_fa": "true",
                                    "ce:surname": "Pang",
                                    "ce:indexed-name": "Pang R."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "R. J.",
                                    "@_fa": "true",
                                    "ce:surname": "Weiss",
                                    "ce:indexed-name": "Weiss R. J."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "M.",
                                    "@_fa": "true",
                                    "ce:surname": "Schuster",
                                    "ce:indexed-name": "Schuster M."
                                },
                                {
                                    "@seq": "5",
                                    "ce:initials": "N.",
                                    "@_fa": "true",
                                    "ce:surname": "Jaitly",
                                    "ce:indexed-name": "Jaitly N."
                                },
                                {
                                    "@seq": "6",
                                    "ce:initials": "Z.",
                                    "@_fa": "true",
                                    "ce:surname": "Yang",
                                    "ce:indexed-name": "Yang Z."
                                },
                                {
                                    "@seq": "7",
                                    "ce:initials": "Z.",
                                    "@_fa": "true",
                                    "ce:surname": "Chen",
                                    "ce:indexed-name": "Chen Z."
                                },
                                {
                                    "@seq": "8",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Zhang",
                                    "ce:indexed-name": "Zhang Y."
                                },
                                {
                                    "@seq": "9",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Wang",
                                    "ce:indexed-name": "Wang Y."
                                },
                                {
                                    "@seq": "10",
                                    "ce:initials": "R.",
                                    "@_fa": "true",
                                    "ce:surname": "Skerrv-Ryan",
                                    "ce:indexed-name": "Skerrv-Ryan R."
                                },
                                {
                                    "@seq": "11",
                                    "ce:initials": "R. A.",
                                    "@_fa": "true",
                                    "ce:surname": "Saurous",
                                    "ce:indexed-name": "Saurous R. A."
                                },
                                {
                                    "@seq": "12",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Agiomvrgiannakis",
                                    "ce:indexed-name": "Agiomvrgiannakis Y."
                                },
                                {
                                    "@seq": "13",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Wu",
                                    "ce:indexed-name": "Wu Y."
                                }
                            ]},
                            "ref-sourcetitle": "ICASSP 2018"
                        },
                        "ce:source-text": "J. Shen, R. Pang, R. J. Weiss, M. Schuster, N. Jaitly, Z. Yang, Z. Chen, Y. Zhang, Y. Wang, R. Skerrv-Ryan, R. A. Saurous, Y. Agiomvrgiannakis, and Y. Wu, \u201cNatural TTS synthesis by conditioning wavenet on mel spectrogram predictions,\u201d in ICASSP 2018, 2018, pp. 4779-4783."
                    },
                    {
                        "@aii:was-generated-by": "http://data.elsevier.com/art/structure-references art:version v1.0.181",
                        "ref-fulltext": "Y. Ren, Y. Ruan, X. Tan, T. Qin, S. Zhao, Z. Zhao, and T. Liu, \u201cFastSpeech: Fast, Robust and Controllable Text to Speech,\u201d in Annual Conference on Neural Information Processing Systems 2019, H. M. Wallach, H. Larochelle, A. Beygelzimer, F. d'AlchéBuc, E. B. Fox, and R. Garnett, Eds., 2019, pp. 3165-3174.",
                        "@id": "23",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2019"},
                            "ref-title": {"ref-titletext": "FastSpeech: Fast, Robust and Controllable Text to Speech"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85081616359",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "3165",
                                "@last": "3174"
                            }},
                            "ref-text": "H. M. Wallach, H. Larochelle, A. Beygelzimer, F. d'AlchéBuc, E. B. Fox, and R. Garnett, Eds",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Ren",
                                    "ce:indexed-name": "Ren Y."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Ruan",
                                    "ce:indexed-name": "Ruan Y."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "X.",
                                    "@_fa": "true",
                                    "ce:surname": "Tan",
                                    "ce:indexed-name": "Tan X."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "T.",
                                    "@_fa": "true",
                                    "ce:surname": "Qin",
                                    "ce:indexed-name": "Qin T."
                                },
                                {
                                    "@seq": "5",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Zhao",
                                    "ce:indexed-name": "Zhao S."
                                },
                                {
                                    "@seq": "6",
                                    "ce:initials": "Z.",
                                    "@_fa": "true",
                                    "ce:surname": "Zhao",
                                    "ce:indexed-name": "Zhao Z."
                                },
                                {
                                    "@seq": "7",
                                    "ce:initials": "T.",
                                    "@_fa": "true",
                                    "ce:surname": "Liu",
                                    "ce:indexed-name": "Liu T."
                                }
                            ]},
                            "ref-sourcetitle": "Annual Conference on Neural Information Processing Systems 2019"
                        },
                        "ce:source-text": "Y. Ren, Y. Ruan, X. Tan, T. Qin, S. Zhao, Z. Zhao, and T. Liu, \u201cFastSpeech: Fast, Robust and Controllable Text to Speech,\u201d in Annual Conference on Neural Information Processing Systems 2019, H. M. Wallach, H. Larochelle, A. Beygelzimer, F. d'AlchéBuc, E. B. Fox, and R. Garnett, Eds., 2019, pp. 3165-3174."
                    },
                    {
                        "@aii:was-generated-by": "http://data.elsevier.com/art/structure-references art:version v1.0.181",
                        "ref-fulltext": "R. Prenger, R. Valle, and B. Catanzaro, \u201cWaveglow: A Flow-based Generative Network for Speech Synthesis,\u201d in ICASSP 2019, 2019, pp. 3617-3621.",
                        "@id": "24",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2019"},
                            "ref-title": {"ref-titletext": "Waveglow: A Flow-based Generative Network for Speech Synthesis"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85068215917",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "3617",
                                "@last": "3621"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "R.",
                                    "@_fa": "true",
                                    "ce:surname": "Prenger",
                                    "ce:indexed-name": "Prenger R."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "R.",
                                    "@_fa": "true",
                                    "ce:surname": "Valle",
                                    "ce:indexed-name": "Valle R."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "B.",
                                    "@_fa": "true",
                                    "ce:surname": "Catanzaro",
                                    "ce:indexed-name": "Catanzaro B."
                                }
                            ]},
                            "ref-sourcetitle": "ICASSP 2019"
                        },
                        "ce:source-text": "R. Prenger, R. Valle, and B. Catanzaro, \u201cWaveglow: A Flow-based Generative Network for Speech Synthesis,\u201d in ICASSP 2019, 2019, pp. 3617-3621."
                    },
                    {
                        "@aii:was-generated-by": "http://data.elsevier.com/art/structure-references art:version v1.0.181",
                        "ref-fulltext": "R. J. Weiss, R. Skerry-Ryan, E. Battenberg, S. Mariooryad, and D. P. Kingma, \u201cWave-Tacotron: Spectrogram-free end-to-end text-to-speech synthesis,\u201d in ICASSP 2021, 2021.",
                        "@id": "25",
                        "ref-info": {
                            "ref-title": {"ref-titletext": "Wave-Tacotron: Spectrogram-free end-to-end text-to-speech synthesis"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85105083538",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {"@volume": "2021"},
                                "pagerange": {"@first": "2021"}
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "R. J.",
                                    "@_fa": "true",
                                    "ce:surname": "Weiss",
                                    "ce:indexed-name": "Weiss R. J."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "R.",
                                    "@_fa": "true",
                                    "ce:surname": "Skerry-Ryan",
                                    "ce:indexed-name": "Skerry-Ryan R."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "E.",
                                    "@_fa": "true",
                                    "ce:surname": "Battenberg",
                                    "ce:indexed-name": "Battenberg E."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Mariooryad",
                                    "ce:indexed-name": "Mariooryad S."
                                },
                                {
                                    "@seq": "5",
                                    "ce:initials": "D. P.",
                                    "@_fa": "true",
                                    "ce:surname": "Kingma",
                                    "ce:indexed-name": "Kingma D. P."
                                }
                            ]},
                            "ref-sourcetitle": "ICASSP"
                        },
                        "ce:source-text": "R. J. Weiss, R. Skerry-Ryan, E. Battenberg, S. Mariooryad, and D. P. Kingma, \u201cWave-Tacotron: Spectrogram-free end-to-end text-to-speech synthesis,\u201d in ICASSP 2021, 2021."
                    },
                    {
                        "@aii:was-generated-by": "http://data.elsevier.com/art/structure-references art:version v1.0.181",
                        "ref-fulltext": "A. W. Rix, J. G. Beerends, M. P. Hollier, and A. P. Hekstra, \u201cPerceptual evaluation of speech quality (PESQ)-a new method for speech quality assessment of telephone networks and codecs,\u201d in ICASSP 2001, vol. 2, 2001, pp. 749-752 vol.2.",
                        "@id": "26",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2001"},
                            "ref-title": {"ref-titletext": "Perceptual evaluation of speech quality (PESQ)-a new method for speech quality assessment of telephone networks and codecs"},
                            "refd-itemidlist": {"itemid": {
                                "$": "0034847662",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {"@volume": "2"},
                                "pagerange": {
                                    "@first": "749",
                                    "@last": "752"
                                }
                            },
                            "ref-text": "2001, vol.2",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "A. W.",
                                    "@_fa": "true",
                                    "ce:surname": "Rix",
                                    "ce:indexed-name": "Rix A. W."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "J. G.",
                                    "@_fa": "true",
                                    "ce:surname": "Beerends",
                                    "ce:indexed-name": "Beerends J. G."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "M. P.",
                                    "@_fa": "true",
                                    "ce:surname": "Hollier",
                                    "ce:indexed-name": "Hollier M. P."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "A. P.",
                                    "@_fa": "true",
                                    "ce:surname": "Hekstra",
                                    "ce:indexed-name": "Hekstra A. P."
                                }
                            ]},
                            "ref-sourcetitle": "ICASSP"
                        },
                        "ce:source-text": "A. W. Rix, J. G. Beerends, M. P. Hollier, and A. P. Hekstra, \u201cPerceptual evaluation of speech quality (PESQ)-a new method for speech quality assessment of telephone networks and codecs,\u201d in ICASSP 2001, vol. 2, 2001, pp. 749-752 vol.2."
                    },
                    {
                        "@aii:was-generated-by": "http://data.elsevier.com/art/structure-references art:version v1.0.181",
                        "ref-fulltext": "M. Cerňak and M. Rusko, \u201cAn evaluation of a synthetic speech using the PESQ measure,\u201d in Proceedings of Forum Acusticum 2005, 2005.",
                        "@id": "27",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2005"},
                            "ref-title": {"ref-titletext": "An evaluation of a synthetic speech using the PESQ measure"},
                            "refd-itemidlist": {"itemid": {
                                "$": "84864626246",
                                "@idtype": "SGR"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "M.",
                                    "@_fa": "true",
                                    "ce:surname": "Cerňak",
                                    "ce:indexed-name": "Cernak M."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "M.",
                                    "@_fa": "true",
                                    "ce:surname": "Rusko",
                                    "ce:indexed-name": "Rusko M."
                                }
                            ]},
                            "ref-sourcetitle": "Proceedings of Forum Acusticum 2005"
                        },
                        "ce:source-text": "M. Cerňak and M. Rusko, \u201cAn evaluation of a synthetic speech using the PESQ measure,\u201d in Proceedings of Forum Acusticum 2005, 2005."
                    },
                    {
                        "@aii:was-generated-by": "http://data.elsevier.com/art/structure-references art:version v1.0.181",
                        "ref-fulltext": "M. Chinen, F. S. C. Lim, J. Skoglund, N. Gureev, F. O'Gorman, and A. Hines, \u201cViSQOL v3: An open source production ready objective speech and audio metric,\u201d in 2020 Twelfth International Conference on Quality of Multimedia Experience (QoMEX), 2020, pp. 1-6.",
                        "@id": "28",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2020"},
                            "ref-title": {"ref-titletext": "ViSQOL v3: An open source production ready objective speech and audio metric"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85087717647",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "1",
                                "@last": "6"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "M.",
                                    "@_fa": "true",
                                    "ce:surname": "Chinen",
                                    "ce:indexed-name": "Chinen M."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "F. S. C.",
                                    "@_fa": "true",
                                    "ce:surname": "Lim",
                                    "ce:indexed-name": "Lim F. S. C."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "J.",
                                    "@_fa": "true",
                                    "ce:surname": "Skoglund",
                                    "ce:indexed-name": "Skoglund J."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "N.",
                                    "@_fa": "true",
                                    "ce:surname": "Gureev",
                                    "ce:indexed-name": "Gureev N."
                                },
                                {
                                    "@seq": "5",
                                    "ce:initials": "F.",
                                    "@_fa": "true",
                                    "ce:surname": "O'Gorman",
                                    "ce:indexed-name": "O'Gorman F."
                                },
                                {
                                    "@seq": "6",
                                    "ce:initials": "A.",
                                    "@_fa": "true",
                                    "ce:surname": "Hines",
                                    "ce:indexed-name": "Hines A."
                                }
                            ]},
                            "ref-sourcetitle": "2020 Twelfth International Conference on Quality of Multimedia Experience (QoMEX)"
                        },
                        "ce:source-text": "M. Chinen, F. S. C. Lim, J. Skoglund, N. Gureev, F. O'Gorman, and A. Hines, \u201cViSQOL v3: An open source production ready objective speech and audio metric,\u201d in 2020 Twelfth International Conference on Quality of Multimedia Experience (QoMEX), 2020, pp. 1-6."
                    },
                    {
                        "@aii:was-generated-by": "http://data.elsevier.com/art/structure-references art:version v1.0.181",
                        "ref-fulltext": "A. Hines and N. Harte, \u201cSpeech intelligibility prediction using a Neurogram Similarity Index Measure,\u201d Speech Communication, vol. 54, pp. 306-320, 02 2012.",
                        "@id": "29",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2012"},
                            "ref-title": {"ref-titletext": "Speech intelligibility prediction using a Neurogram Similarity Index Measure"},
                            "refd-itemidlist": {"itemid": {
                                "$": "80055066385",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {"@volume": "54"},
                                "pagerange": {
                                    "@first": "306",
                                    "@last": "320"
                                }
                            },
                            "ref-text": "02",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "A.",
                                    "@_fa": "true",
                                    "ce:surname": "Hines",
                                    "ce:indexed-name": "Hines A."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "N.",
                                    "@_fa": "true",
                                    "ce:surname": "Harte",
                                    "ce:indexed-name": "Harte N."
                                }
                            ]},
                            "ref-sourcetitle": "Speech Communication"
                        },
                        "ce:source-text": "A. Hines and N. Harte, \u201cSpeech intelligibility prediction using a Neurogram Similarity Index Measure,\u201d Speech Communication, vol. 54, pp. 306-320, 02 2012."
                    },
                    {
                        "@aii:was-generated-by": "http://data.elsevier.com/art/structure-references art:version v1.0.181",
                        "ref-fulltext": "C.-C. Lo, S.-W. Fu, W.-C. Huang, X. Wang, J. Yamagishi, Y. Tsao, and H.-M. Wang, \u201cMOSNet: Deep learning based objective assessment for voice conversion,\u201d in Proc. Interspeech 2019, 2019.",
                        "@id": "30",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2019"},
                            "ref-title": {"ref-titletext": "MOSNet: Deep learning based objective assessment for voice conversion"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85074711230",
                                "@idtype": "SGR"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "C.-C.",
                                    "@_fa": "true",
                                    "ce:surname": "Lo",
                                    "ce:indexed-name": "Lo C.-C."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "S.-W.",
                                    "@_fa": "true",
                                    "ce:surname": "Fu",
                                    "ce:indexed-name": "Fu S.-W."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "W.-C.",
                                    "@_fa": "true",
                                    "ce:surname": "Huang",
                                    "ce:indexed-name": "Huang W.-C."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "X.",
                                    "@_fa": "true",
                                    "ce:surname": "Wang",
                                    "ce:indexed-name": "Wang X."
                                },
                                {
                                    "@seq": "5",
                                    "ce:initials": "J.",
                                    "@_fa": "true",
                                    "ce:surname": "Yamagishi",
                                    "ce:indexed-name": "Yamagishi J."
                                },
                                {
                                    "@seq": "6",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Tsao",
                                    "ce:indexed-name": "Tsao Y."
                                },
                                {
                                    "@seq": "7",
                                    "ce:initials": "H.-M.",
                                    "@_fa": "true",
                                    "ce:surname": "Wang",
                                    "ce:indexed-name": "Wang H.-M."
                                }
                            ]},
                            "ref-sourcetitle": "Proc. Interspeech 2019"
                        },
                        "ce:source-text": "C.-C. Lo, S.-W. Fu, W.-C. Huang, X. Wang, J. Yamagishi, Y. Tsao, and H.-M. Wang, \u201cMOSNet: Deep learning based objective assessment for voice conversion,\u201d in Proc. Interspeech 2019, 2019."
                    },
                    {
                        "@aii:was-generated-by": "http://data.elsevier.com/art/structure-references art:version v1.0.181",
                        "ref-fulltext": "J. Lorenzo-Trueba, J. Yamagishi, T. Toda, D. Saito, F. Villavicencio, T. Kinnunen, and Z. Ling, \u201cThe Voice Conversion Challenge 2018: Promoting development of parallel and nonparallel methods,\u201d in Proc. Odyssey 2018 The Speaker and Language Recognition Workshop, 2018, pp. 195-202. [Online]. Available: http://dx.doi.org/10.21437/Odyssey.2018-28",
                        "@id": "31",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2018"},
                            "ref-website": {"ce:e-address": {
                                "$": "http://dx.doi.org/10.21437/Odyssey.2018-28",
                                "@type": "email"
                            }},
                            "ref-title": {"ref-titletext": "The Voice Conversion Challenge 2018: Promoting development of parallel and nonparallel methods"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85119664319",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "195",
                                "@last": "202"
                            }},
                            "ref-text": "[Online]. Available",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "J.",
                                    "@_fa": "true",
                                    "ce:surname": "Lorenzo-Trueba",
                                    "ce:indexed-name": "Lorenzo-Trueba J."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "J.",
                                    "@_fa": "true",
                                    "ce:surname": "Yamagishi",
                                    "ce:indexed-name": "Yamagishi J."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "T.",
                                    "@_fa": "true",
                                    "ce:surname": "Toda",
                                    "ce:indexed-name": "Toda T."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "D.",
                                    "@_fa": "true",
                                    "ce:surname": "Saito",
                                    "ce:indexed-name": "Saito D."
                                },
                                {
                                    "@seq": "5",
                                    "ce:initials": "F.",
                                    "@_fa": "true",
                                    "ce:surname": "Villavicencio",
                                    "ce:indexed-name": "Villavicencio F."
                                },
                                {
                                    "@seq": "6",
                                    "ce:initials": "T.",
                                    "@_fa": "true",
                                    "ce:surname": "Kinnunen",
                                    "ce:indexed-name": "Kinnunen T."
                                },
                                {
                                    "@seq": "7",
                                    "ce:initials": "Z.",
                                    "@_fa": "true",
                                    "ce:surname": "Ling",
                                    "ce:indexed-name": "Ling Z."
                                }
                            ]},
                            "ref-sourcetitle": "Proc. Odyssey 2018 The Speaker and Language Recognition Workshop"
                        },
                        "ce:source-text": "J. Lorenzo-Trueba, J. Yamagishi, T. Toda, D. Saito, F. Villavicencio, T. Kinnunen, and Z. Ling, \u201cThe Voice Conversion Challenge 2018: Promoting development of parallel and nonparallel methods,\u201d in Proc. Odyssey 2018 The Speaker and Language Recognition Workshop, 2018, pp. 195-202. [Online]. Available: http://dx.doi.org/10.21437/Odyssey.2018-28"
                    }
                ]
            }}
        }
    },
    "affiliation": {
        "affiliation-city": "Bangkok",
        "@id": "60028190",
        "affilname": "Chulalongkorn University",
        "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60028190",
        "affiliation-country": "Thailand"
    },
    "coredata": {
        "srctype": "p",
        "eid": "2-s2.0-85119205081",
        "dc:description": "One of the main problems in the development of text-to-speech (TTS) systems is its reliance on subjective measures, typically the Mean Opinion Score (MOS). MOS requires a large number of people to reliably rate each utterance, making the development process slow and expensive. Recent research on speech quality assessment tends to focus on training models to estimate MOS, which requires a large number of training data, something that might not be available in low-resource languages. We propose an objective assessment metric based on the DTW distance using the spectrogram and the high-level features from an Automatic Speech Recognition (ASR) model to cover both acoustic and linguistic information. Experiments on Thai TTS and the Blizzard Challenge datasets show that our method outperformed other baselines in both utterance- and system-level by a large margin in terms of correlation coefficients. Our metric also outperformed the best baseline by 9.58% when used in head-to-head utterance-level comparisons. Ablation studies suggest that the middle layers of the ASR model are most suitable for TTS evaluation when used in conjunction with spectral features.",
        "prism:coverDate": "2021-01-01",
        "prism:aggregationType": "Conference Proceeding",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85119205081",
        "dc:creator": {"author": [{
            "ce:given-name": "Thananchai",
            "preferred-name": {
                "ce:given-name": "Thananchai",
                "ce:initials": "T.",
                "ce:surname": "Kongthaworn",
                "ce:indexed-name": "Kongthaworn T."
            },
            "@seq": "1",
            "ce:initials": "T.",
            "@_fa": "true",
            "affiliation": {
                "@id": "60028190",
                "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60028190"
            },
            "ce:surname": "Kongthaworn",
            "@auid": "57219740937",
            "author-url": "https://api.elsevier.com/content/author/author_id/57219740937",
            "ce:indexed-name": "Kongthaworn T."
        }]},
        "link": [
            {
                "@_fa": "true",
                "@rel": "self",
                "@href": "https://api.elsevier.com/content/abstract/scopus_id/85119205081"
            },
            {
                "@_fa": "true",
                "@rel": "scopus",
                "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85119205081&origin=inward"
            },
            {
                "@_fa": "true",
                "@rel": "scopus-citedby",
                "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85119205081&origin=inward"
            }
        ],
        "prism:isbn": "9781713836902",
        "source-id": "21100212301",
        "citedby-count": "0",
        "prism:volume": "5",
        "subtype": "cp",
        "dc:title": "Spectral and latent speech representation distortion for TTS evaluation",
        "openaccess": "0",
        "prism:issn": "19909772 2308457X",
        "publishercopyright": "© 2021 ISCA",
        "subtypeDescription": "Conference Paper",
        "prism:publicationName": "Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH",
        "prism:pageRange": "3516-3520",
        "prism:endingPage": "3520",
        "openaccessFlag": "false",
        "prism:doi": "10.21437/Interspeech.2021-2258",
        "prism:startingPage": "3516",
        "dc:identifier": "SCOPUS_ID:85119205081",
        "dc:publisher": "International Speech Communication Association"
    },
    "idxterms": {"mainterm": [
        {
            "$": "Automatic speech recognition",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "Development process",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "Mean opinion scores",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "Number of peoples",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "Recent researches",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "Recognition models",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "Speech quality assessment",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "Text to speech",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "Text-to-speech evaluation",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "Text-to-speech system",
            "@weight": "b",
            "@candidate": "n"
        }
    ]},
    "language": {"@xml:lang": "eng"},
    "authkeywords": {"author-keyword": [
        {
            "@_fa": "true",
            "$": "Speech recognition"
        },
        {
            "@_fa": "true",
            "$": "Speech synthesis"
        },
        {
            "@_fa": "true",
            "$": "TTS evaluation"
        }
    ]},
    "subject-areas": {"subject-area": [
        {
            "@_fa": "true",
            "$": "Language and Linguistics",
            "@code": "1203",
            "@abbrev": "ARTS"
        },
        {
            "@_fa": "true",
            "$": "Human-Computer Interaction",
            "@code": "1709",
            "@abbrev": "COMP"
        },
        {
            "@_fa": "true",
            "$": "Signal Processing",
            "@code": "1711",
            "@abbrev": "COMP"
        },
        {
            "@_fa": "true",
            "$": "Software",
            "@code": "1712",
            "@abbrev": "COMP"
        },
        {
            "@_fa": "true",
            "$": "Modeling and Simulation",
            "@code": "2611",
            "@abbrev": "MATH"
        }
    ]},
    "authors": {"author": [
        {
            "ce:given-name": "Thananchai",
            "preferred-name": {
                "ce:given-name": "Thananchai",
                "ce:initials": "T.",
                "ce:surname": "Kongthaworn",
                "ce:indexed-name": "Kongthaworn T."
            },
            "@seq": "1",
            "ce:initials": "T.",
            "@_fa": "true",
            "affiliation": {
                "@id": "60028190",
                "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60028190"
            },
            "ce:surname": "Kongthaworn",
            "@auid": "57219740937",
            "author-url": "https://api.elsevier.com/content/author/author_id/57219740937",
            "ce:indexed-name": "Kongthaworn T."
        },
        {
            "ce:given-name": "Burin",
            "preferred-name": {
                "ce:given-name": "Burin",
                "ce:initials": "B.",
                "ce:surname": "Naowarat",
                "ce:indexed-name": "Naowarat B."
            },
            "@seq": "2",
            "ce:initials": "B.",
            "@_fa": "true",
            "affiliation": {
                "@id": "60028190",
                "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60028190"
            },
            "ce:surname": "Naowarat",
            "@auid": "57219732667",
            "author-url": "https://api.elsevier.com/content/author/author_id/57219732667",
            "ce:indexed-name": "Naowarat B."
        },
        {
            "ce:given-name": "Ekapol",
            "preferred-name": {
                "ce:given-name": "Ekapol",
                "ce:initials": "E.",
                "ce:surname": "Chuangsuwanich",
                "ce:indexed-name": "Chuangsuwanich E."
            },
            "@seq": "3",
            "ce:initials": "E.",
            "@_fa": "true",
            "affiliation": {
                "@id": "60028190",
                "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60028190"
            },
            "ce:surname": "Chuangsuwanich",
            "@auid": "36987854100",
            "author-url": "https://api.elsevier.com/content/author/author_id/36987854100",
            "ce:indexed-name": "Chuangsuwanich E."
        }
    ]}
}}