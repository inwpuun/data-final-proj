{"abstracts-retrieval-response": {
    "item": {
        "ait:process-info": {
            "ait:status": {
                "@state": "update",
                "@type": "core",
                "@stage": "S300"
            },
            "ait:date-delivered": {
                "@day": "05",
                "@timestamp": "2022-01-05T04:59:22.000022-05:00",
                "@year": "2022",
                "@month": "01"
            },
            "ait:date-sort": {
                "@day": "01",
                "@year": "2021",
                "@month": "01"
            }
        },
        "bibrecord": {
            "head": {
                "author-group": [
                    {
                        "affiliation": {
                            "country": "Thailand",
                            "@afid": "60028190",
                            "@country": "tha",
                            "organization": [
                                {"$": "Department of Computer Engineering"},
                                {"$": "Chulalongkorn University"}
                            ],
                            "affiliation-id": {
                                "@afid": "60028190",
                                "@dptid": "113891981"
                            },
                            "ce:source-text": "Department of Computer Engineering, Chulalongkorn University, Thailand",
                            "@dptid": "113891981"
                        },
                        "author": [
                            {
                                "ce:given-name": "Burin",
                                "preferred-name": {
                                    "ce:given-name": "Burin",
                                    "ce:initials": "B.",
                                    "ce:surname": "Naowarat",
                                    "ce:indexed-name": "Naowarat B."
                                },
                                "@seq": "1",
                                "ce:initials": "B.",
                                "@_fa": "true",
                                "@type": "auth",
                                "ce:surname": "Naowarat",
                                "@auid": "57219732667",
                                "ce:indexed-name": "Naowarat B."
                            },
                            {
                                "ce:given-name": "Thananchai",
                                "preferred-name": {
                                    "ce:given-name": "Thananchai",
                                    "ce:initials": "T.",
                                    "ce:surname": "Kongthaworn",
                                    "ce:indexed-name": "Kongthaworn T."
                                },
                                "@seq": "2",
                                "ce:initials": "T.",
                                "@_fa": "true",
                                "@type": "auth",
                                "ce:surname": "Kongthaworn",
                                "@auid": "57219740937",
                                "ce:indexed-name": "Kongthaworn T."
                            },
                            {
                                "ce:given-name": "Ekapol",
                                "preferred-name": {
                                    "ce:given-name": "Ekapol",
                                    "ce:initials": "E.",
                                    "ce:surname": "Chuangsuwanich",
                                    "ce:indexed-name": "Chuangsuwanich E."
                                },
                                "@seq": "5",
                                "ce:initials": "E.",
                                "@_fa": "true",
                                "@type": "auth",
                                "ce:surname": "Chuangsuwanich",
                                "@auid": "36987854100",
                                "ce:indexed-name": "Chuangsuwanich E."
                            }
                        ]
                    },
                    {
                        "affiliation": {
                            "country": "Switzerland",
                            "@afid": "60025858",
                            "@country": "che",
                            "organization": {"$": "Eth Zurich"},
                            "affiliation-id": {"@afid": "60025858"},
                            "ce:source-text": "ETH Zurich, Switzerland"
                        },
                        "author": [{
                            "ce:given-name": "Korrawe",
                            "preferred-name": {
                                "ce:given-name": "Korrawe",
                                "ce:initials": "K.",
                                "ce:surname": "Karunratanakul",
                                "ce:indexed-name": "Karunratanakul K."
                            },
                            "@seq": "3",
                            "ce:initials": "K.",
                            "@_fa": "true",
                            "@type": "auth",
                            "ce:surname": "Karunratanakul",
                            "@auid": "57212115515",
                            "ce:indexed-name": "Karunratanakul K."
                        }]
                    },
                    {
                        "affiliation": {
                            "country": "Taiwan",
                            "@afid": "126598061",
                            "@country": "twn",
                            "organization": {"$": "New Era Ai Robotics"},
                            "affiliation-id": {"@afid": "126598061"},
                            "ce:source-text": "New Era AI Robotics, Taiwan"
                        },
                        "author": [{
                            "ce:given-name": "Sheng Hui",
                            "preferred-name": {
                                "ce:given-name": "Sheng Hui",
                                "ce:initials": "S.H.",
                                "ce:surname": "Wu",
                                "ce:indexed-name": "Wu S.H."
                            },
                            "@seq": "4",
                            "ce:initials": "S.H.",
                            "@_fa": "true",
                            "@type": "auth",
                            "ce:surname": "Wu",
                            "@auid": "57219737932",
                            "ce:indexed-name": "Wu S.H."
                        }]
                    }
                ],
                "citation-title": "Reducing Spelling Inconsistencies in Code-Switching Asr Using Contextualized Ctc Loss",
                "abstracts": "Â©2021 IEEE.Code-Switching (CS) remains a challenge for Automatic Speech Recognition (ASR), especially character-based models. With the combined choice of characters from multiple languages, the outcome from character-based models suffers from phoneme duplication, resulting in language-inconsistent spellings. We propose Contextualized Connectionist Temporal Classification (CCTC) loss to encourage spelling consistencies of a character-based nonautoregressive ASR which allows for faster inference. The model trained by CCTC loss is aware of contexts since it learns to predict both center and surrounding letters in a multi-task manner. In contrast to existing CTC-based approaches, CCTC loss does not require frame-level alignments, since the context ground truth is obtained from the model's estimated path. Compared to the same model trained with regular CTC loss, our method consistently improved the ASR performance on both CS and monolingual corpora.",
                "citation-info": {
                    "author-keywords": {"author-keyword": [
                        {
                            "$": "Code-switching",
                            "@xml:lang": "eng",
                            "@original": "y"
                        },
                        {
                            "$": "Connectionist temporal classification",
                            "@xml:lang": "eng",
                            "@original": "y"
                        },
                        {
                            "$": "Context prediction",
                            "@xml:lang": "eng",
                            "@original": "y"
                        },
                        {
                            "$": "End-to-end speech recognition",
                            "@xml:lang": "eng",
                            "@original": "y"
                        }
                    ]},
                    "citation-type": {"@code": "cp"},
                    "citation-language": {
                        "@language": "English",
                        "@xml:lang": "eng"
                    },
                    "abstract-language": {
                        "@language": "English",
                        "@xml:lang": "eng"
                    }
                },
                "source": {
                    "translated-sourcetitle": {
                        "$": "ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings",
                        "@xml:lang": "eng"
                    },
                    "volisspag": {
                        "voliss": {"@volume": "2021-June"},
                        "pagerange": {
                            "@first": "6239",
                            "@last": "6243"
                        }
                    },
                    "@type": "p",
                    "additional-srcinfo": {"conferenceinfo": {
                        "confpublication": {"procpartno": "1 of 1"},
                        "confevent": {
                            "confname": "2021 IEEE International Conference on Acoustics, Speech, and Signal Processing, ICASSP 2021",
                            "confsponsors": {
                                "confsponsor": "The Institute of Electrical and Electronics Engineers Signal Processing Society",
                                "@complete": "n"
                            },
                            "confcatnumber": "CFP21ICA-ART",
                            "confseriestitle": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
                            "conflocation": {
                                "@country": "can",
                                "city": "Virtual, Toronto",
                                "state": "ON"
                            },
                            "confcode": "169955",
                            "confdate": {
                                "enddate": {
                                    "@day": "11",
                                    "@year": "2021",
                                    "@month": "06"
                                },
                                "startdate": {
                                    "@day": "06",
                                    "@year": "2021",
                                    "@month": "06"
                                }
                            }
                        }
                    }},
                    "sourcetitle": "ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings",
                    "publicationdate": {
                        "year": "2021",
                        "date-text": {
                            "@xfab-added": "true",
                            "$": "2021"
                        }
                    },
                    "codencode": "IPROD",
                    "sourcetitle-abbrev": "ICASSP IEEE Int Conf Acoust Speech Signal Process Proc",
                    "@country": "usa",
                    "issn": {
                        "$": "15206149",
                        "@type": "print"
                    },
                    "publicationyear": {"@first": "2021"},
                    "publisher": {"publishername": "Institute of Electrical and Electronics Engineers Inc."},
                    "@srcid": "110544"
                },
                "enhancement": {"classificationgroup": {"classifications": [
                    {
                        "@type": "CPXCLASS",
                        "classification": [
                            {
                                "classification-code": "716.1",
                                "classification-description": "Information Theory and Signal Processing"
                            },
                            {
                                "classification-code": "723.2",
                                "classification-description": "Data Processing and Image Processing"
                            },
                            {
                                "classification-code": "751.5",
                                "classification-description": "Speech"
                            }
                        ]
                    },
                    {
                        "@type": "FLXCLASS",
                        "classification": {
                            "classification-code": "902",
                            "classification-description": "FLUIDEX; Related Topics"
                        }
                    },
                    {
                        "@type": "ASJC",
                        "classification": [
                            {"$": "1712"},
                            {"$": "1711"},
                            {"$": "2208"}
                        ]
                    },
                    {
                        "@type": "SUBJABBR",
                        "classification": [
                            {"$": "COMP"},
                            {"$": "ENGI"}
                        ]
                    }
                ]}}
            },
            "item-info": {
                "copyright": {
                    "$": "Copyright 2021 Elsevier B.V., All rights reserved.",
                    "@type": "Elsevier"
                },
                "dbcollection": [
                    {"$": "CPX"},
                    {"$": "REAXYSCAR"},
                    {"$": "SCOPUS"},
                    {"$": "Scopusbase"}
                ],
                "history": {"date-created": {
                    "@day": "22",
                    "@timestamp": "BST 08:09:13",
                    "@year": "2021",
                    "@month": "09"
                }},
                "itemidlist": {
                    "itemid": [
                        {
                            "$": "635977493",
                            "@idtype": "PUI"
                        },
                        {
                            "$": "935605064",
                            "@idtype": "CAR-ID"
                        },
                        {
                            "$": "20213810922310",
                            "@idtype": "CPX"
                        },
                        {
                            "$": "20213383583",
                            "@idtype": "REAXYSCAR"
                        },
                        {
                            "$": "20213154505",
                            "@idtype": "SCOPUS"
                        },
                        {
                            "$": "85115158645",
                            "@idtype": "SCP"
                        },
                        {
                            "$": "85115158645",
                            "@idtype": "SGR"
                        }
                    ],
                    "ce:doi": "10.1109/ICASSP39728.2021.9413806"
                }
            },
            "tail": {"bibliography": {
                "@refcount": "29",
                "reference": [
                    {
                        "ref-fulltext": "Alex Graves, Santiago FerÅandez, Faustino Gomez, et al., \"Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks, \" in Proc. International Conference on Machine Learning (ICML), 2006, pp. 369-376.",
                        "@id": "1",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2006"},
                            "ref-title": {"ref-titletext": "Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural networks"},
                            "refd-itemidlist": {"itemid": {
                                "$": "34250704813",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "369",
                                "@last": "376"
                            }},
                            "ref-authors": {
                                "author": [
                                    {
                                        "@seq": "1",
                                        "ce:initials": "A.",
                                        "@_fa": "true",
                                        "ce:surname": "Graves",
                                        "ce:indexed-name": "Graves A."
                                    },
                                    {
                                        "@seq": "2",
                                        "ce:initials": "S.",
                                        "@_fa": "true",
                                        "ce:surname": "FerÅandez",
                                        "ce:indexed-name": "Fernandez S."
                                    },
                                    {
                                        "@seq": "3",
                                        "ce:initials": "F.",
                                        "@_fa": "true",
                                        "ce:surname": "Gomez",
                                        "ce:indexed-name": "Gomez F."
                                    }
                                ],
                                "et-al": null
                            },
                            "ref-sourcetitle": "Proc. International Conference on Machine Learning (ICML)"
                        },
                        "ce:source-text": "Alex Graves, Santiago FerÅandez, Faustino Gomez, et al., \"Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks, \" in Proc. International Conference on Machine Learning (ICML), 2006, pp. 369-376."
                    },
                    {
                        "ref-fulltext": "Markus Miiller, Sebastian Stiiker, and Alex Waibel, \"Multilingual adaptation of RNN based ASR systems, \" in Proc. International Conference on Acoustics Speech and Signal Processing (ICASSP). IEEE, 2018, pp. 5219-5223.",
                        "@id": "2",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2018"},
                            "ref-title": {"ref-titletext": "Multilingual adaptation of RNN based ASR systems"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85054220173",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "5219",
                                "@last": "5223"
                            }},
                            "ref-text": "IEEE",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "M.",
                                    "@_fa": "true",
                                    "ce:surname": "Miiller",
                                    "ce:indexed-name": "Miiller M."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Stiiker",
                                    "ce:indexed-name": "Stiiker S."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "A.",
                                    "@_fa": "true",
                                    "ce:surname": "Waibel",
                                    "ce:indexed-name": "Waibel A."
                                }
                            ]},
                            "ref-sourcetitle": "Proc. International Conference on Acoustics Speech and Signal Processing (ICASSP)"
                        },
                        "ce:source-text": "Markus Miiller, Sebastian Stiiker, and Alex Waibel, \"Multilingual adaptation of RNN based ASR systems, \" in Proc. International Conference on Acoustics Speech and Signal Processing (ICASSP). IEEE, 2018, pp. 5219-5223."
                    },
                    {
                        "ref-fulltext": "Sibo Tong, Philip N Garner, and Herve Bourlard, \"Crosslingual adaptation of a CTC-based multilingual acoustic model, \" Speech Communication, vol. 104, pp. 39-46, 2018.",
                        "@id": "3",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2018"},
                            "ref-title": {"ref-titletext": "Crosslingual adaptation of a CTC-based multilingual acoustic model"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85053551233",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {"@volume": "104"},
                                "pagerange": {
                                    "@first": "39",
                                    "@last": "46"
                                }
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Tong",
                                    "ce:indexed-name": "Tong S."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "P.N.",
                                    "@_fa": "true",
                                    "ce:surname": "Garner",
                                    "ce:indexed-name": "Garner P.N."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "H.",
                                    "@_fa": "true",
                                    "ce:surname": "Bourlard",
                                    "ce:indexed-name": "Bourlard H."
                                }
                            ]},
                            "ref-sourcetitle": "Speech Communication"
                        },
                        "ce:source-text": "Sibo Tong, Philip N Garner, and Herve Bourlard, \"Crosslingual adaptation of a CTC-based multilingual acoustic model, \" Speech Communication, vol. 104, pp. 39-46, 2018."
                    },
                    {
                        "ref-fulltext": "Dong Wang, Xiaodong Wang, and Shaohe Lv, \"End-to-End Mandarin Speech Recognition Combining CNN and BLSTM, \" Symmetry, vol. 11, no. 5, pp. 644, 2019.",
                        "@id": "4",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2019"},
                            "ref-title": {"ref-titletext": "End-to-End mandarin speech recognition combining CNN and BLSTM"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85066304108",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {
                                    "@volume": "11",
                                    "@issue": "5"
                                },
                                "pagerange": {"@first": "644"}
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "D.",
                                    "@_fa": "true",
                                    "ce:surname": "Wang",
                                    "ce:indexed-name": "Wang D."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "X.",
                                    "@_fa": "true",
                                    "ce:surname": "Wang",
                                    "ce:indexed-name": "Wang X."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Lv",
                                    "ce:indexed-name": "Lv S."
                                }
                            ]},
                            "ref-sourcetitle": "Symmetry"
                        },
                        "ce:source-text": "Dong Wang, Xiaodong Wang, and Shaohe Lv, \"End-to-End Mandarin Speech Recognition Combining CNN and BLSTM, \" Symmetry, vol. 11, no. 5, pp. 644, 2019."
                    },
                    {
                        "ref-fulltext": "Siddharth Dalmia, Xinjian Li, Florian Metze, et al., \"Domain robust feature extraction for rapid low resource ASR development, \" in Proc. IEEE Spoken Language Technology Workshop (SLT). IEEE, 2018, pp. 258-265.",
                        "@id": "5",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2018"},
                            "ref-title": {"ref-titletext": "Domain robust feature extraction for rapid low resource ASR development"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85063088164",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "258",
                                "@last": "265"
                            }},
                            "ref-text": "IEEE",
                            "ref-authors": {
                                "author": [
                                    {
                                        "@seq": "1",
                                        "ce:initials": "S.",
                                        "@_fa": "true",
                                        "ce:surname": "Dalmia",
                                        "ce:indexed-name": "Dalmia S."
                                    },
                                    {
                                        "@seq": "2",
                                        "ce:initials": "X.",
                                        "@_fa": "true",
                                        "ce:surname": "Li",
                                        "ce:indexed-name": "Li X."
                                    },
                                    {
                                        "@seq": "3",
                                        "ce:initials": "F.",
                                        "@_fa": "true",
                                        "ce:surname": "Metze",
                                        "ce:indexed-name": "Metze F."
                                    }
                                ],
                                "et-al": null
                            },
                            "ref-sourcetitle": "Proc. Ieee Spoken Language Technology Workshop (SLT)"
                        },
                        "ce:source-text": "Siddharth Dalmia, Xinjian Li, Florian Metze, et al., \"Domain robust feature extraction for rapid low resource ASR development, \" in Proc. IEEE Spoken Language Technology Workshop (SLT). IEEE, 2018, pp. 258-265."
                    },
                    {
                        "ref-fulltext": "Hitoshi Ito, Aiko Hagiwara, Manon Ichiki, et al., \"End-to-end speech recognition for languages with ideographic characters, \" in Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC). IEEE, 2017, pp. 1228-1232.",
                        "@id": "6",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2017"},
                            "ref-title": {"ref-titletext": "End-to-end speech recognition for languages with ideographic characters"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85050508749",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "1228",
                                "@last": "1232"
                            }},
                            "ref-text": "IEEE",
                            "ref-authors": {
                                "author": [
                                    {
                                        "@seq": "1",
                                        "ce:initials": "H.",
                                        "@_fa": "true",
                                        "ce:surname": "Ito",
                                        "ce:indexed-name": "Ito H."
                                    },
                                    {
                                        "@seq": "2",
                                        "ce:initials": "A.",
                                        "@_fa": "true",
                                        "ce:surname": "Hagiwara",
                                        "ce:indexed-name": "Hagiwara A."
                                    },
                                    {
                                        "@seq": "3",
                                        "ce:initials": "M.",
                                        "@_fa": "true",
                                        "ce:surname": "Ichiki",
                                        "ce:indexed-name": "Ichiki M."
                                    }
                                ],
                                "et-al": null
                            },
                            "ref-sourcetitle": "Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)"
                        },
                        "ce:source-text": "Hitoshi Ito, Aiko Hagiwara, Manon Ichiki, et al., \"End-to-end speech recognition for languages with ideographic characters, \" in Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC). IEEE, 2017, pp. 1228-1232."
                    },
                    {
                        "ref-fulltext": "Ke Li, Jinyu Li, Guoli Ye, et al., \"Towards Code-switching ASR for End-to-end CTC Models, \" in Proc. International Conference on Acoustics Speech and Signal Processing (ICASSP). IEEE, 2019, pp. 6076-6080.",
                        "@id": "7",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2019"},
                            "ref-title": {"ref-titletext": "Towards Code-switching ASR for End-to-end CTC Models"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85068977606",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "6076",
                                "@last": "6080"
                            }},
                            "ref-text": "IEEE",
                            "ref-authors": {
                                "author": [
                                    {
                                        "@seq": "1",
                                        "ce:initials": "K.",
                                        "@_fa": "true",
                                        "ce:surname": "Li",
                                        "ce:indexed-name": "Li K."
                                    },
                                    {
                                        "@seq": "2",
                                        "ce:initials": "J.",
                                        "@_fa": "true",
                                        "ce:surname": "Li",
                                        "ce:indexed-name": "Li J."
                                    },
                                    {
                                        "@seq": "3",
                                        "ce:initials": "G.",
                                        "@_fa": "true",
                                        "ce:surname": "Ye",
                                        "ce:indexed-name": "Ye G."
                                    }
                                ],
                                "et-al": null
                            },
                            "ref-sourcetitle": "Proc. International Conference on Acoustics Speech and Signal Processing (ICASSP)"
                        },
                        "ce:source-text": "Ke Li, Jinyu Li, Guoli Ye, et al., \"Towards Code-switching ASR for End-to-end CTC Models, \" in Proc. International Conference on Acoustics Speech and Signal Processing (ICASSP). IEEE, 2019, pp. 6076-6080."
                    },
                    {
                        "ref-fulltext": "Ganji Sreeram and Rohit Sinha, \"Exploration of end-to-end framework for code-switching speech recognition task: Challenges and enhancements, \" IEEE Access, vol. 8, pp. 68146- 68157, 2020.",
                        "@id": "8",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2020"},
                            "ref-title": {"ref-titletext": "Exploration of end-to-end framework for code-switching speech recognition task: Challenges and enhancements"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85083991928",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {"@volume": "8"},
                                "pagerange": {
                                    "@first": "68146",
                                    "@last": "68157"
                                }
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "G.",
                                    "@_fa": "true",
                                    "ce:surname": "Sreeram",
                                    "ce:indexed-name": "Sreeram G."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "R.",
                                    "@_fa": "true",
                                    "ce:surname": "Sinha",
                                    "ce:indexed-name": "Sinha R."
                                }
                            ]},
                            "ref-sourcetitle": "Ieee Access"
                        },
                        "ce:source-text": "Ganji Sreeram and Rohit Sinha, \"Exploration of end-to-end framework for code-switching speech recognition task: Challenges and enhancements, \" IEEE Access, vol. 8, pp. 68146- 68157, 2020."
                    },
                    {
                        "ref-fulltext": "Xianghu Yue, Grandee Lee, Emre Yilmaz, et al., \"End-toend code-switching asr for low-resourced language pairs, \" in Proc. IEEE Automatic Speech Recognition and Understanding Workshop (ASRU). IEEE, 2019, pp. 972-979.",
                        "@id": "9",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2019"},
                            "ref-title": {"ref-titletext": "End-toend code-switching asr for low-resourced language pairs"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85081586937",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "972",
                                "@last": "979"
                            }},
                            "ref-text": "IEEE",
                            "ref-authors": {
                                "author": [
                                    {
                                        "@seq": "1",
                                        "ce:initials": "X.",
                                        "@_fa": "true",
                                        "ce:surname": "Yue",
                                        "ce:indexed-name": "Yue X."
                                    },
                                    {
                                        "@seq": "2",
                                        "ce:initials": "G.",
                                        "@_fa": "true",
                                        "ce:surname": "Lee",
                                        "ce:indexed-name": "Lee G."
                                    },
                                    {
                                        "@seq": "3",
                                        "ce:initials": "E.",
                                        "@_fa": "true",
                                        "ce:surname": "Yilmaz",
                                        "ce:indexed-name": "Yilmaz E."
                                    }
                                ],
                                "et-al": null
                            },
                            "ref-sourcetitle": "Proc. Ieee Automatic Speech Recognition and Understanding Workshop (ASRU)"
                        },
                        "ce:source-text": "Xianghu Yue, Grandee Lee, Emre Yilmaz, et al., \"End-toend code-switching asr for low-resourced language pairs, \" in Proc. IEEE Automatic Speech Recognition and Understanding Workshop (ASRU). IEEE, 2019, pp. 972-979."
                    },
                    {
                        "ref-fulltext": "Jesse Emond, Bhuvana Ramabhadran, Brian Roark, et al., \"Transliteration based approaches to improve code-switched speech recognition performance, \" in Proc. IEEE Spoken Language Technology Workshop (SLT). IEEE, 2018, pp. 448-455.",
                        "@id": "10",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2018"},
                            "ref-title": {"ref-titletext": "Transliteration based approaches to improve code-switched speech recognition performance"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85063075657",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "448",
                                "@last": "455"
                            }},
                            "ref-text": "IEEE",
                            "ref-authors": {
                                "author": [
                                    {
                                        "@seq": "1",
                                        "ce:initials": "J.",
                                        "@_fa": "true",
                                        "ce:surname": "Emond",
                                        "ce:indexed-name": "Emond J."
                                    },
                                    {
                                        "@seq": "2",
                                        "ce:initials": "B.",
                                        "@_fa": "true",
                                        "ce:surname": "Ramabhadran",
                                        "ce:indexed-name": "Ramabhadran B."
                                    },
                                    {
                                        "@seq": "3",
                                        "ce:initials": "B.",
                                        "@_fa": "true",
                                        "ce:surname": "Roark",
                                        "ce:indexed-name": "Roark B."
                                    }
                                ],
                                "et-al": null
                            },
                            "ref-sourcetitle": "Proc. Ieee Spoken Language Technology Workshop (SLT)"
                        },
                        "ce:source-text": "Jesse Emond, Bhuvana Ramabhadran, Brian Roark, et al., \"Transliteration based approaches to improve code-switched speech recognition performance, \" in Proc. IEEE Spoken Language Technology Workshop (SLT). IEEE, 2018, pp. 448-455."
                    },
                    {
                        "ref-fulltext": "Ne Luo, Dongwei Jiang, Shuaijiang Zhao, et al., \"Towards end-to-end code-switching speech recognition, \" arXiv preprint arXiv:1810.13091, 2018.",
                        "@id": "11",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2018"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85074708266",
                                "@idtype": "SGR"
                            }},
                            "ref-text": "arXiv preprint arXiv:1810.13091",
                            "ref-authors": {
                                "author": [
                                    {
                                        "@seq": "1",
                                        "ce:initials": "N.",
                                        "@_fa": "true",
                                        "ce:surname": "Luo",
                                        "ce:indexed-name": "Luo N."
                                    },
                                    {
                                        "@seq": "2",
                                        "ce:initials": "D.",
                                        "@_fa": "true",
                                        "ce:surname": "Jiang",
                                        "ce:indexed-name": "Jiang D."
                                    },
                                    {
                                        "@seq": "3",
                                        "ce:initials": "S.",
                                        "@_fa": "true",
                                        "ce:surname": "Zhao",
                                        "ce:indexed-name": "Zhao S."
                                    }
                                ],
                                "et-al": null
                            },
                            "ref-sourcetitle": "Towards End-to-end Code-switching Speech Recognition"
                        },
                        "ce:source-text": "Ne Luo, Dongwei Jiang, Shuaijiang Zhao, et al., \"Towards end-to-end code-switching speech recognition, \" arXiv preprint arXiv:1810.13091, 2018."
                    },
                    {
                        "ref-fulltext": "Zhiping Zeng, Yerbolat Khassanov, Van Tung Pham, et al., \"On the End-to-End Solution to Mandarin-English Code- Switching Speech Recognition, \" in Proc. Annual Conference of International Speech Communication Association (INTERSPEECH), 2019, pp. 2165-2169.",
                        "@id": "12",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2019"},
                            "ref-title": {"ref-titletext": "On the end-to-end solution to mandarin-english code- switching speech recognition"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85074709839",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "2165",
                                "@last": "2169"
                            }},
                            "ref-authors": {
                                "author": [
                                    {
                                        "@seq": "1",
                                        "ce:initials": "Z.",
                                        "@_fa": "true",
                                        "ce:surname": "Zeng",
                                        "ce:indexed-name": "Zeng Z."
                                    },
                                    {
                                        "@seq": "2",
                                        "ce:initials": "Y.",
                                        "@_fa": "true",
                                        "ce:surname": "Khassanov",
                                        "ce:indexed-name": "Khassanov Y."
                                    },
                                    {
                                        "@seq": "3",
                                        "ce:initials": "V.T.",
                                        "@_fa": "true",
                                        "ce:surname": "Pham",
                                        "ce:indexed-name": "Pham V.T."
                                    }
                                ],
                                "et-al": null
                            },
                            "ref-sourcetitle": "Proc. Annual Conference of International Speech Communication Association (INTERSPEECH)"
                        },
                        "ce:source-text": "Zhiping Zeng, Yerbolat Khassanov, Van Tung Pham, et al., \"On the End-to-End Solution to Mandarin-English Code- Switching Speech Recognition, \" in Proc. Annual Conference of International Speech Communication Association (INTERSPEECH), 2019, pp. 2165-2169."
                    },
                    {
                        "ref-fulltext": "Changhao Shan, Chao Weng, Guangsen Wang, et al., \"Investigating end-to-end speech recognition for Mandarin-English code-switching, \" in Proc. International Conference on Acoustics Speech and Signal Processing (ICASSP). IEEE, 2019, pp. 6056-6060.",
                        "@id": "13",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2019"},
                            "ref-title": {"ref-titletext": "Investigating end-to-end speech recognition for Mandarin-English code-switching"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85068986115",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "6056",
                                "@last": "6060"
                            }},
                            "ref-text": "IEEE",
                            "ref-authors": {
                                "author": [
                                    {
                                        "@seq": "1",
                                        "ce:initials": "C.",
                                        "@_fa": "true",
                                        "ce:surname": "Shan",
                                        "ce:indexed-name": "Shan C."
                                    },
                                    {
                                        "@seq": "2",
                                        "ce:initials": "C.",
                                        "@_fa": "true",
                                        "ce:surname": "Weng",
                                        "ce:indexed-name": "Weng C."
                                    },
                                    {
                                        "@seq": "3",
                                        "ce:initials": "G.",
                                        "@_fa": "true",
                                        "ce:surname": "Wang",
                                        "ce:indexed-name": "Wang G."
                                    }
                                ],
                                "et-al": null
                            },
                            "ref-sourcetitle": "Proc. International Conference on Acoustics Speech and Signal Processing (ICASSP)"
                        },
                        "ce:source-text": "Changhao Shan, Chao Weng, Guangsen Wang, et al., \"Investigating end-to-end speech recognition for Mandarin-English code-switching, \" in Proc. International Conference on Acoustics Speech and Signal Processing (ICASSP). IEEE, 2019, pp. 6056-6060."
                    },
                    {
                        "ref-fulltext": "Navdeep Jaitly, Vincent Vanhoucke, and Geoffrey E. Hinton, \"Autoregressive product of multi-frame predictions can improve the accuracy of hybrid models, \" in Proc. Annual Conference of International Speech Communication Association (INTERSPEECH), 2014.",
                        "@id": "14",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2014"},
                            "ref-title": {"ref-titletext": "Autoregressive product of multi-frame predictions can improve the accuracy of hybrid models"},
                            "refd-itemidlist": {"itemid": {
                                "$": "84910071120",
                                "@idtype": "SGR"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "N.",
                                    "@_fa": "true",
                                    "ce:surname": "Jaitly",
                                    "ce:indexed-name": "Jaitly N."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "V.",
                                    "@_fa": "true",
                                    "ce:surname": "Vanhoucke",
                                    "ce:indexed-name": "Vanhoucke V."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "G.E.",
                                    "@_fa": "true",
                                    "ce:surname": "Hinton",
                                    "ce:indexed-name": "Hinton G.E."
                                }
                            ]},
                            "ref-sourcetitle": "Proc. Annual Conference of International Speech Communication Association (INTERSPEECH)"
                        },
                        "ce:source-text": "Navdeep Jaitly, Vincent Vanhoucke, and Geoffrey E. Hinton, \"Autoregressive product of multi-frame predictions can improve the accuracy of hybrid models, \" in Proc. Annual Conference of International Speech Communication Association (INTERSPEECH), 2014."
                    },
                    {
                        "ref-fulltext": "Yu Zhang, Dong Yu, Michael L Seltzer, et al., \"Speech recognition with prediction-adaptation-correction recurrent neural networks, \" in Proc. International Conference on Acoustics Speech and Signal Processing (ICASSP). IEEE, 2015, pp. 5004-5008.",
                        "@id": "15",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2015"},
                            "ref-title": {"ref-titletext": "Speech recognition with prediction-adaptation-correction recurrent neural networks"},
                            "refd-itemidlist": {"itemid": {
                                "$": "84946042568",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "5004",
                                "@last": "5008"
                            }},
                            "ref-text": "IEEE",
                            "ref-authors": {
                                "author": [
                                    {
                                        "@seq": "1",
                                        "ce:initials": "Y.",
                                        "@_fa": "true",
                                        "ce:surname": "Zhang",
                                        "ce:indexed-name": "Zhang Y."
                                    },
                                    {
                                        "@seq": "2",
                                        "ce:initials": "D.",
                                        "@_fa": "true",
                                        "ce:surname": "Yu",
                                        "ce:indexed-name": "Yu D."
                                    },
                                    {
                                        "@seq": "3",
                                        "ce:initials": "M.L.",
                                        "@_fa": "true",
                                        "ce:surname": "Seltzer",
                                        "ce:indexed-name": "Seltzer M.L."
                                    }
                                ],
                                "et-al": null
                            },
                            "ref-sourcetitle": "Proc. International Conference on Acoustics Speech and Signal Processing (ICASSP)"
                        },
                        "ce:source-text": "Yu Zhang, Dong Yu, Michael L Seltzer, et al., \"Speech recognition with prediction-adaptation-correction recurrent neural networks, \" in Proc. International Conference on Acoustics Speech and Signal Processing (ICASSP). IEEE, 2015, pp. 5004-5008."
                    },
                    {
                        "ref-fulltext": "Yu Zhang, Ekapol Chuangsuwanich, James Glass, et al., \"Prediction-adaptation-correction recurrent neural networks for low-resource language speech recognition, \" in Proc. International Conference on Acoustics Speech and Signal Processing (ICASSP). IEEE, 2016, pp. 5415-5419.",
                        "@id": "16",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2016"},
                            "ref-title": {"ref-titletext": "Prediction-adaptation-correction recurrent neural networks for low-resource language speech recognition"},
                            "refd-itemidlist": {"itemid": {
                                "$": "84973279480",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "5415",
                                "@last": "5419"
                            }},
                            "ref-text": "IEEE",
                            "ref-authors": {
                                "author": [
                                    {
                                        "@seq": "1",
                                        "ce:initials": "Y.",
                                        "@_fa": "true",
                                        "ce:surname": "Zhang",
                                        "ce:indexed-name": "Zhang Y."
                                    },
                                    {
                                        "@seq": "2",
                                        "ce:initials": "E.",
                                        "@_fa": "true",
                                        "ce:surname": "Chuangsuwanich",
                                        "ce:indexed-name": "Chuangsuwanich E."
                                    },
                                    {
                                        "@seq": "3",
                                        "ce:initials": "J.",
                                        "@_fa": "true",
                                        "ce:surname": "Glass",
                                        "ce:indexed-name": "Glass J."
                                    }
                                ],
                                "et-al": null
                            },
                            "ref-sourcetitle": "Proc. International Conference on Acoustics Speech and Signal Processing (ICASSP)"
                        },
                        "ce:source-text": "Yu Zhang, Ekapol Chuangsuwanich, James Glass, et al., \"Prediction-adaptation-correction recurrent neural networks for low-resource language speech recognition, \" in Proc. International Conference on Acoustics Speech and Signal Processing (ICASSP). IEEE, 2016, pp. 5415-5419."
                    },
                    {
                        "ref-fulltext": "Jan Chorowski, Adrian LÃ¡ncucki, Bartosz Kostka, et al., \"Towards Using Context-Dependent Symbols in CTC Without State-Tying Decision Trees, \" in Proc. Annual Conference of International Speech Communication Association (INTERSPEECH), 2019, pp. 4385-4389.",
                        "@id": "17",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2019"},
                            "ref-title": {"ref-titletext": "Towards using context-dependent symbols in CTC without state-tying decision trees"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85074703124",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "4385",
                                "@last": "4389"
                            }},
                            "ref-authors": {
                                "author": [
                                    {
                                        "@seq": "1",
                                        "ce:initials": "J.",
                                        "@_fa": "true",
                                        "ce:surname": "Chorowski",
                                        "ce:indexed-name": "Chorowski J."
                                    },
                                    {
                                        "@seq": "2",
                                        "ce:initials": "A.",
                                        "@_fa": "true",
                                        "ce:surname": "LÃ¡ncucki",
                                        "ce:indexed-name": "Lancucki A."
                                    },
                                    {
                                        "@seq": "3",
                                        "ce:initials": "B.",
                                        "@_fa": "true",
                                        "ce:surname": "Kostka",
                                        "ce:indexed-name": "Kostka B."
                                    }
                                ],
                                "et-al": null
                            },
                            "ref-sourcetitle": "Proc. Annual Conference of International Speech Communication Association (INTERSPEECH)"
                        },
                        "ce:source-text": "Jan Chorowski, Adrian LÃ¡ncucki, Bartosz Kostka, et al., \"Towards Using Context-Dependent Symbols in CTC Without State-Tying Decision Trees, \" in Proc. Annual Conference of International Speech Communication Association (INTERSPEECH), 2019, pp. 4385-4389."
                    },
                    {
                        "ref-fulltext": "Oleksii Kuchaiev, Boris Ginsburg, Igor Gitman, et al., \"Mixed- Precision Training for NLP and Speech Recognition with OpenSeq2Seq, \" arXiv preprint arXiv:1805.10387, 2018.",
                        "@id": "18",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2018"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85068994305",
                                "@idtype": "SGR"
                            }},
                            "ref-text": "arXiv preprint arXiv:1805.10387",
                            "ref-authors": {
                                "author": [
                                    {
                                        "@seq": "1",
                                        "ce:initials": "O.",
                                        "@_fa": "true",
                                        "ce:surname": "Kuchaiev",
                                        "ce:indexed-name": "Kuchaiev O."
                                    },
                                    {
                                        "@seq": "2",
                                        "ce:initials": "B.",
                                        "@_fa": "true",
                                        "ce:surname": "Ginsburg",
                                        "ce:indexed-name": "Ginsburg B."
                                    },
                                    {
                                        "@seq": "3",
                                        "ce:initials": "I.",
                                        "@_fa": "true",
                                        "ce:surname": "Gitman",
                                        "ce:indexed-name": "Gitman I."
                                    }
                                ],
                                "et-al": null
                            },
                            "ref-sourcetitle": "Mixed- Precision Training for Nlp and Speech Recognition with OpenSeq2Seq"
                        },
                        "ce:source-text": "Oleksii Kuchaiev, Boris Ginsburg, Igor Gitman, et al., \"Mixed- Precision Training for NLP and Speech Recognition with OpenSeq2Seq, \" arXiv preprint arXiv:1805.10387, 2018."
                    },
                    {
                        "ref-fulltext": "Ronan Collobert, Christian Puhrsch, and Gabriel Synnaeve, \"Wav2letter: an end-to-end convnet-based speech recognition system, \" arXiv preprint arXiv:1609.03193, 2016.",
                        "@id": "19",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2016"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85041759100",
                                "@idtype": "SGR"
                            }},
                            "ref-text": "arXiv preprint arXiv:1609.03193",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "R.",
                                    "@_fa": "true",
                                    "ce:surname": "Collobert",
                                    "ce:indexed-name": "Collobert R."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "C.",
                                    "@_fa": "true",
                                    "ce:surname": "Puhrsch",
                                    "ce:indexed-name": "Puhrsch C."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "G.",
                                    "@_fa": "true",
                                    "ce:surname": "Synnaeve",
                                    "ce:indexed-name": "Synnaeve G."
                                }
                            ]},
                            "ref-sourcetitle": "Wav2letter: An End-to-end Convnet-based Speech Recognition System"
                        },
                        "ce:source-text": "Ronan Collobert, Christian Puhrsch, and Gabriel Synnaeve, \"Wav2letter: an end-to-end convnet-based speech recognition system, \" arXiv preprint arXiv:1609.03193, 2016."
                    },
                    {
                        "ref-fulltext": "Vitaliy Liptchinsky, Gabriel Synnaeve, and Ronan Collobert, \"Letter-based speech recognition with gated ConvNets, \" arXiv preprint arXiv:1712.09444, 2017.",
                        "@id": "20",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2017"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85054989680",
                                "@idtype": "SGR"
                            }},
                            "ref-text": "arXiv preprint arXiv:1712.09444",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "V.",
                                    "@_fa": "true",
                                    "ce:surname": "Liptchinsky",
                                    "ce:indexed-name": "Liptchinsky V."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "G.",
                                    "@_fa": "true",
                                    "ce:surname": "Synnaeve",
                                    "ce:indexed-name": "Synnaeve G."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "R.",
                                    "@_fa": "true",
                                    "ce:surname": "Collobert",
                                    "ce:indexed-name": "Collobert R."
                                }
                            ]},
                            "ref-sourcetitle": "Letter-based Speech Recognition with Gated ConvNets"
                        },
                        "ce:source-text": "Vitaliy Liptchinsky, Gabriel Synnaeve, and Ronan Collobert, \"Letter-based speech recognition with gated ConvNets, \" arXiv preprint arXiv:1712.09444, 2017."
                    },
                    {
                        "ref-fulltext": "Diederik P. Kingma and Jimmy Ba, \"Adam: A method for stochastic optimization, \" in Proc. International Conference on Learning Representations (ICLR), 2015.",
                        "@id": "21",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2015"},
                            "ref-title": {"ref-titletext": "Adam: A method for stochastic optimization"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85083951076",
                                "@idtype": "SGR"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "D.P.",
                                    "@_fa": "true",
                                    "ce:surname": "Kingma",
                                    "ce:indexed-name": "Kingma D.P."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "J.",
                                    "@_fa": "true",
                                    "ce:surname": "Ba",
                                    "ce:indexed-name": "Ba J."
                                }
                            ]},
                            "ref-sourcetitle": "Proc. International Conference on Learning Representations (ICLR)"
                        },
                        "ce:source-text": "Diederik P. Kingma and Jimmy Ba, \"Adam: A method for stochastic optimization, \" in Proc. International Conference on Learning Representations (ICLR), 2015."
                    },
                    {
                        "ref-fulltext": "Yang You, Igor Gitman, and Boris Ginsburg, \"Large batch training of convolutional networks, \" arXiv preprint arXiv:1708.03888, 2017.",
                        "@id": "22",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2017"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85055698500",
                                "@idtype": "SGR"
                            }},
                            "ref-text": "arXiv preprint arXiv:1708.03888",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "You",
                                    "ce:indexed-name": "You Y."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "I.",
                                    "@_fa": "true",
                                    "ce:surname": "Gitman",
                                    "ce:indexed-name": "Gitman I."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "B.",
                                    "@_fa": "true",
                                    "ce:surname": "Ginsburg",
                                    "ce:indexed-name": "Ginsburg B."
                                }
                            ]},
                            "ref-sourcetitle": "Large Batch Training of Convolutional Networks"
                        },
                        "ce:source-text": "Yang You, Igor Gitman, and Boris Ginsburg, \"Large batch training of convolutional networks, \" arXiv preprint arXiv:1708.03888, 2017."
                    },
                    {
                        "ref-fulltext": "Rakpong Kittinaradorn, Titipat Achakulvisut, Korakot Chaovavanich, et al., \"DeepCut: A Thai word tokenization library using Deep Neural Network, \" Sept. 2019.",
                        "@id": "23",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2019"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85089176242",
                                "@idtype": "SGR"
                            }},
                            "ref-text": "Sept",
                            "ref-authors": {
                                "author": [
                                    {
                                        "@seq": "1",
                                        "ce:initials": "R.",
                                        "@_fa": "true",
                                        "ce:surname": "Kittinaradorn",
                                        "ce:indexed-name": "Kittinaradorn R."
                                    },
                                    {
                                        "@seq": "2",
                                        "ce:initials": "T.",
                                        "@_fa": "true",
                                        "ce:surname": "Achakulvisut",
                                        "ce:indexed-name": "Achakulvisut T."
                                    },
                                    {
                                        "@seq": "3",
                                        "ce:initials": "K.",
                                        "@_fa": "true",
                                        "ce:surname": "Chaovavanich",
                                        "ce:indexed-name": "Chaovavanich K."
                                    }
                                ],
                                "et-al": null
                            },
                            "ref-sourcetitle": "DeepCut: a Thai Word Tokenization Library Using Deep Neural Network"
                        },
                        "ce:source-text": "Rakpong Kittinaradorn, Titipat Achakulvisut, Korakot Chaovavanich, et al., \"DeepCut: A Thai word tokenization library using Deep Neural Network, \" Sept. 2019."
                    },
                    {
                        "ref-fulltext": "Kenneth Heafield, \"KenLM: Faster and smaller language model queries, \" in Proceedings of the sixth workshop on statistical machine translation, 2011, pp. 187-197.",
                        "@id": "24",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2011"},
                            "ref-title": {"ref-titletext": "KenLM: Faster and smaller language model queries"},
                            "refd-itemidlist": {"itemid": {
                                "$": "84982842007",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "187",
                                "@last": "197"
                            }},
                            "ref-authors": {"author": [{
                                "@seq": "1",
                                "ce:initials": "K.",
                                "@_fa": "true",
                                "ce:surname": "Heafield",
                                "ce:indexed-name": "Heafield K."
                            }]},
                            "ref-sourcetitle": "Proceedings of the Sixth Workshop on Statistical Machine Translation"
                        },
                        "ce:source-text": "Kenneth Heafield, \"KenLM: Faster and smaller language model queries, \" in Proceedings of the sixth workshop on statistical machine translation, 2011, pp. 187-197."
                    },
                    {
                        "ref-fulltext": "William Chan, Navdeep Jaitly, Quoc Le, et al., \"Listen, attend and spell: A neural network for large vocabulary conversational speech recognition, \" in Proc. International Conference on Acoustics Speech and Signal Processing (ICASSP), 2016, pp. 4960-4964.",
                        "@id": "25",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2016"},
                            "ref-title": {"ref-titletext": "Listen, attend and spell: A neural network for large vocabulary conversational speech recognition"},
                            "refd-itemidlist": {"itemid": {
                                "$": "84973351869",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "4960",
                                "@last": "4964"
                            }},
                            "ref-authors": {
                                "author": [
                                    {
                                        "@seq": "1",
                                        "ce:initials": "W.",
                                        "@_fa": "true",
                                        "ce:surname": "Chan",
                                        "ce:indexed-name": "Chan W."
                                    },
                                    {
                                        "@seq": "2",
                                        "ce:initials": "N.",
                                        "@_fa": "true",
                                        "ce:surname": "Jaitly",
                                        "ce:indexed-name": "Jaitly N."
                                    },
                                    {
                                        "@seq": "3",
                                        "ce:initials": "Q.",
                                        "@_fa": "true",
                                        "ce:surname": "Le",
                                        "ce:indexed-name": "Le Q."
                                    }
                                ],
                                "et-al": null
                            },
                            "ref-sourcetitle": "Proc. International Conference on Acoustics Speech and Signal Processing (ICASSP)"
                        },
                        "ce:source-text": "William Chan, Navdeep Jaitly, Quoc Le, et al., \"Listen, attend and spell: A neural network for large vocabulary conversational speech recognition, \" in Proc. International Conference on Acoustics Speech and Signal Processing (ICASSP), 2016, pp. 4960-4964."
                    },
                    {
                        "ref-fulltext": "Alexander H Liu, Tzu-Wei Sung, Shun-Po Chuang, et al., \"Sequence-to-Sequence Automatic Speech Recognition with Word Embedding Regularization and Fused Decoding, \" in Proc. International Conference on Acoustics Speech and Signal Processing (ICASSP). IEEE, 2020, pp. 7879-7883.",
                        "@id": "26",
                        "ref-info": {
                            "ref-title": {"ref-titletext": "Sequence-to-sequence automatic speech recognition with word embedding regularization and fused decoding"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85089242359",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "7879",
                                "@last": "7883"
                            }},
                            "ref-text": "IEEE, 2020",
                            "ref-authors": {
                                "author": [
                                    {
                                        "@seq": "1",
                                        "ce:initials": "A.H.",
                                        "@_fa": "true",
                                        "ce:surname": "Liu",
                                        "ce:indexed-name": "Liu A.H."
                                    },
                                    {
                                        "@seq": "2",
                                        "ce:initials": "T.-W.",
                                        "@_fa": "true",
                                        "ce:surname": "Sung",
                                        "ce:indexed-name": "Sung T.-W."
                                    },
                                    {
                                        "@seq": "3",
                                        "ce:initials": "S.-P.",
                                        "@_fa": "true",
                                        "ce:surname": "Chuang",
                                        "ce:indexed-name": "Chuang S.-P."
                                    }
                                ],
                                "et-al": null
                            },
                            "ref-sourcetitle": "Proc. International Conference on Acoustics Speech and Signal Processing (ICASSP)"
                        },
                        "ce:source-text": "Alexander H Liu, Tzu-Wei Sung, Shun-Po Chuang, et al., \"Sequence-to-Sequence Automatic Speech Recognition with Word Embedding Regularization and Fused Decoding, \" in Proc. International Conference on Acoustics Speech and Signal Processing (ICASSP). IEEE, 2020, pp. 7879-7883."
                    },
                    {
                        "ref-fulltext": "Shinji Watanabe, Takaaki Hori, Suyoun Kim, et al., \"Hybrid CTC/attention architecture for end-to-end speech recognition, \" IEEE Journal of Selected Topics in Signal Processing, vol. 11, no. 8, pp. 1240-1253, 2017.",
                        "@id": "27",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2017"},
                            "ref-title": {"ref-titletext": "Hybrid CTC/attention architecture for end-to-end speech recognition"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85041777531",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {
                                    "@volume": "11",
                                    "@issue": "8"
                                },
                                "pagerange": {
                                    "@first": "1240",
                                    "@last": "1253"
                                }
                            },
                            "ref-authors": {
                                "author": [
                                    {
                                        "@seq": "1",
                                        "ce:initials": "S.",
                                        "@_fa": "true",
                                        "ce:surname": "Watanabe",
                                        "ce:indexed-name": "Watanabe S."
                                    },
                                    {
                                        "@seq": "2",
                                        "ce:initials": "T.",
                                        "@_fa": "true",
                                        "ce:surname": "Hori",
                                        "ce:indexed-name": "Hori T."
                                    },
                                    {
                                        "@seq": "3",
                                        "ce:initials": "S.",
                                        "@_fa": "true",
                                        "ce:surname": "Kim",
                                        "ce:indexed-name": "Kim S."
                                    }
                                ],
                                "et-al": null
                            },
                            "ref-sourcetitle": "Ieee Journal of Selected Topics in Signal Processing"
                        },
                        "ce:source-text": "Shinji Watanabe, Takaaki Hori, Suyoun Kim, et al., \"Hybrid CTC/attention architecture for end-to-end speech recognition, \" IEEE Journal of Selected Topics in Signal Processing, vol. 11, no. 8, pp. 1240-1253, 2017."
                    },
                    {
                        "ref-fulltext": "Vassil Panayotov, Guoguo Chen, Daniel Povey, et al., \"Librispeech: an ASR corpus based on public domain audio books, \" in Proc. International Conference on Acoustics Speech and Signal Processing (ICASSP). IEEE, 2015, pp. 5206-5210.",
                        "@id": "28",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2015"},
                            "ref-title": {"ref-titletext": "Librispeech: An ASR corpus based on public domain audio books"},
                            "refd-itemidlist": {"itemid": {
                                "$": "84946015916",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "5206",
                                "@last": "5210"
                            }},
                            "ref-text": "IEEE",
                            "ref-authors": {
                                "author": [
                                    {
                                        "@seq": "1",
                                        "ce:initials": "V.",
                                        "@_fa": "true",
                                        "ce:surname": "Panayotov",
                                        "ce:indexed-name": "Panayotov V."
                                    },
                                    {
                                        "@seq": "2",
                                        "ce:initials": "G.",
                                        "@_fa": "true",
                                        "ce:surname": "Chen",
                                        "ce:indexed-name": "Chen G."
                                    },
                                    {
                                        "@seq": "3",
                                        "ce:initials": "D.",
                                        "@_fa": "true",
                                        "ce:surname": "Povey",
                                        "ce:indexed-name": "Povey D."
                                    }
                                ],
                                "et-al": null
                            },
                            "ref-sourcetitle": "Proc. International Conference on Acoustics Speech and Signal Processing (ICASSP)"
                        },
                        "ce:source-text": "Vassil Panayotov, Guoguo Chen, Daniel Povey, et al., \"Librispeech: an ASR corpus based on public domain audio books, \" in Proc. International Conference on Acoustics Speech and Signal Processing (ICASSP). IEEE, 2015, pp. 5206-5210."
                    },
                    {
                        "ref-fulltext": "Vineel Pratap, Awni Hannun, Qiantong Xu, et al., \"Wav2letter++: A fast open-source speech recognition system, \" in Proc. International Conference on Acoustics Speech and Signal Processing (ICASSP). IEEE, 2019, pp. 6460-6464.",
                        "@id": "29",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2019"},
                            "ref-title": {"ref-titletext": "Wav2letter++: A fast open-source speech recognition system"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85068981938",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "6460",
                                "@last": "6464"
                            }},
                            "ref-text": "IEEE",
                            "ref-authors": {
                                "author": [
                                    {
                                        "@seq": "1",
                                        "ce:initials": "V.",
                                        "@_fa": "true",
                                        "ce:surname": "Pratap",
                                        "ce:indexed-name": "Pratap V."
                                    },
                                    {
                                        "@seq": "2",
                                        "ce:initials": "A.",
                                        "@_fa": "true",
                                        "ce:surname": "Hannun",
                                        "ce:indexed-name": "Hannun A."
                                    },
                                    {
                                        "@seq": "3",
                                        "ce:initials": "Q.",
                                        "@_fa": "true",
                                        "ce:surname": "Xu",
                                        "ce:indexed-name": "Xu Q."
                                    }
                                ],
                                "et-al": null
                            },
                            "ref-sourcetitle": "Proc. International Conference on Acoustics Speech and Signal Processing (ICASSP)"
                        },
                        "ce:source-text": "Vineel Pratap, Awni Hannun, Qiantong Xu, et al., \"Wav2letter++: A fast open-source speech recognition system, \" in Proc. International Conference on Acoustics Speech and Signal Processing (ICASSP). IEEE, 2019, pp. 6460-6464."
                    }
                ]
            }}
        }
    },
    "affiliation": [
        {
            "affiliation-city": "Bangkok",
            "@id": "60028190",
            "affilname": "Chulalongkorn University",
            "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60028190",
            "affiliation-country": "Thailand"
        },
        {
            "affiliation-city": "Zurich ZH,",
            "@id": "60025858",
            "affilname": "ETH ZÃ¼rich",
            "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60025858",
            "affiliation-country": "Switzerland"
        },
        {
            "affiliation-city": null,
            "@id": "126598061",
            "affilname": "New Era Ai Robotics",
            "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/126598061",
            "affiliation-country": "Taiwan"
        }
    ],
    "coredata": {
        "srctype": "p",
        "eid": "2-s2.0-85115158645",
        "dc:description": "Code-Switching (CS) remains a challenge for Automatic Speech Recognition (ASR), especially character-based models. With the combined choice of characters from multiple languages, the outcome from character-based models suffers from phoneme duplication, resulting in language-inconsistent spellings. We propose Contextualized Connectionist Temporal Classification (CCTC) loss to encourage spelling consistencies of a character-based nonautoregressive ASR which allows for faster inference. The model trained by CCTC loss is aware of contexts since it learns to predict both center and surrounding letters in a multi-task manner. In contrast to existing CTC-based approaches, CCTC loss does not require frame-level alignments, since the context ground truth is obtained from the model's estimated path. Compared to the same model trained with regular CTC loss, our method consistently improved the ASR performance on both CS and monolingual corpora.",
        "prism:coverDate": "2021-01-01",
        "prism:aggregationType": "Conference Proceeding",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85115158645",
        "dc:creator": {"author": [{
            "ce:given-name": "Burin",
            "preferred-name": {
                "ce:given-name": "Burin",
                "ce:initials": "B.",
                "ce:surname": "Naowarat",
                "ce:indexed-name": "Naowarat B."
            },
            "@seq": "1",
            "ce:initials": "B.",
            "@_fa": "true",
            "affiliation": {
                "@id": "60028190",
                "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60028190"
            },
            "ce:surname": "Naowarat",
            "@auid": "57219732667",
            "author-url": "https://api.elsevier.com/content/author/author_id/57219732667",
            "ce:indexed-name": "Naowarat B."
        }]},
        "link": [
            {
                "@_fa": "true",
                "@rel": "self",
                "@href": "https://api.elsevier.com/content/abstract/scopus_id/85115158645"
            },
            {
                "@_fa": "true",
                "@rel": "scopus",
                "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85115158645&origin=inward"
            },
            {
                "@_fa": "true",
                "@rel": "scopus-citedby",
                "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85115158645&origin=inward"
            }
        ],
        "source-id": "110544",
        "citedby-count": "4",
        "prism:volume": "2021-June",
        "subtype": "cp",
        "dc:title": "Reducing Spelling Inconsistencies in Code-Switching Asr Using Contextualized Ctc Loss",
        "openaccess": "2",
        "prism:issn": "15206149",
        "publishercopyright": "Â©2021 IEEE.",
        "subtypeDescription": "Conference Paper",
        "prism:publicationName": "ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings",
        "prism:pageRange": "6239-6243",
        "prism:endingPage": "6243",
        "openaccessFlag": null,
        "prism:doi": "10.1109/ICASSP39728.2021.9413806",
        "prism:startingPage": "6239",
        "dc:identifier": "SCOPUS_ID:85115158645",
        "dc:publisher": "Institute of Electrical and Electronics Engineers Inc."
    },
    "idxterms": {"mainterm": [
        {
            "$": "Automatic speech recognition",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "Character-based models",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "Code-switching",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "Ground truth",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "Multiple languages",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "Temporal classification",
            "@weight": "b",
            "@candidate": "n"
        }
    ]},
    "language": {"@xml:lang": "eng"},
    "authkeywords": {"author-keyword": [
        {
            "@_fa": "true",
            "$": "Code-switching"
        },
        {
            "@_fa": "true",
            "$": "Connectionist temporal classification"
        },
        {
            "@_fa": "true",
            "$": "Context prediction"
        },
        {
            "@_fa": "true",
            "$": "End-to-end speech recognition"
        }
    ]},
    "subject-areas": {"subject-area": [
        {
            "@_fa": "true",
            "$": "Software",
            "@code": "1712",
            "@abbrev": "COMP"
        },
        {
            "@_fa": "true",
            "$": "Signal Processing",
            "@code": "1711",
            "@abbrev": "COMP"
        },
        {
            "@_fa": "true",
            "$": "Electrical and Electronic Engineering",
            "@code": "2208",
            "@abbrev": "ENGI"
        }
    ]},
    "authors": {"author": [
        {
            "ce:given-name": "Burin",
            "preferred-name": {
                "ce:given-name": "Burin",
                "ce:initials": "B.",
                "ce:surname": "Naowarat",
                "ce:indexed-name": "Naowarat B."
            },
            "@seq": "1",
            "ce:initials": "B.",
            "@_fa": "true",
            "affiliation": {
                "@id": "60028190",
                "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60028190"
            },
            "ce:surname": "Naowarat",
            "@auid": "57219732667",
            "author-url": "https://api.elsevier.com/content/author/author_id/57219732667",
            "ce:indexed-name": "Naowarat B."
        },
        {
            "ce:given-name": "Thananchai",
            "preferred-name": {
                "ce:given-name": "Thananchai",
                "ce:initials": "T.",
                "ce:surname": "Kongthaworn",
                "ce:indexed-name": "Kongthaworn T."
            },
            "@seq": "2",
            "ce:initials": "T.",
            "@_fa": "true",
            "affiliation": {
                "@id": "60028190",
                "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60028190"
            },
            "ce:surname": "Kongthaworn",
            "@auid": "57219740937",
            "author-url": "https://api.elsevier.com/content/author/author_id/57219740937",
            "ce:indexed-name": "Kongthaworn T."
        },
        {
            "ce:given-name": "Korrawe",
            "preferred-name": {
                "ce:given-name": "Korrawe",
                "ce:initials": "K.",
                "ce:surname": "Karunratanakul",
                "ce:indexed-name": "Karunratanakul K."
            },
            "@seq": "3",
            "ce:initials": "K.",
            "@_fa": "true",
            "affiliation": {
                "@id": "60025858",
                "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60025858"
            },
            "ce:surname": "Karunratanakul",
            "@auid": "57212115515",
            "author-url": "https://api.elsevier.com/content/author/author_id/57212115515",
            "ce:indexed-name": "Karunratanakul K."
        },
        {
            "ce:given-name": "Sheng Hui",
            "preferred-name": {
                "ce:given-name": "Sheng Hui",
                "ce:initials": "S.H.",
                "ce:surname": "Wu",
                "ce:indexed-name": "Wu S.H."
            },
            "@seq": "4",
            "ce:initials": "S.H.",
            "@_fa": "true",
            "affiliation": {
                "@id": "126598061",
                "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/126598061"
            },
            "ce:surname": "Wu",
            "@auid": "57219737932",
            "author-url": "https://api.elsevier.com/content/author/author_id/57219737932",
            "ce:indexed-name": "Wu S.H."
        },
        {
            "ce:given-name": "Ekapol",
            "preferred-name": {
                "ce:given-name": "Ekapol",
                "ce:initials": "E.",
                "ce:surname": "Chuangsuwanich",
                "ce:indexed-name": "Chuangsuwanich E."
            },
            "@seq": "5",
            "ce:initials": "E.",
            "@_fa": "true",
            "affiliation": {
                "@id": "60028190",
                "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60028190"
            },
            "ce:surname": "Chuangsuwanich",
            "@auid": "36987854100",
            "author-url": "https://api.elsevier.com/content/author/author_id/36987854100",
            "ce:indexed-name": "Chuangsuwanich E."
        }
    ]}
}}