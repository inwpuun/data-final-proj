{"abstracts-retrieval-response": {
    "item": {
        "ait:process-info": {
            "ait:status": {
                "@state": "update",
                "@type": "core",
                "@stage": "S300"
            },
            "ait:date-delivered": {
                "@day": "27",
                "@timestamp": "2022-09-27T07:29:17.000017-04:00",
                "@year": "2022",
                "@month": "09"
            },
            "ait:date-sort": {
                "@day": "01",
                "@year": "2022",
                "@month": "01"
            }
        },
        "bibrecord": {
            "head": {
                "author-group": {
                    "affiliation": {
                        "country": "Thailand",
                        "@afid": "60028190",
                        "@country": "tha",
                        "city": "Bangkok",
                        "organization": [
                            {"$": "Chulalongkorn University"},
                            {"$": "Department of Computer Engineering"}
                        ],
                        "affiliation-id": {
                            "@afid": "60028190",
                            "@dptid": "113891981"
                        },
                        "ce:source-text": "Chulalongkorn University, Department of Computer Engineering, Bangkok, Thailand",
                        "@dptid": "113891981"
                    },
                    "author": [
                        {
                            "ce:given-name": "Nun",
                            "preferred-name": {
                                "ce:given-name": "Nun",
                                "ce:initials": "N.",
                                "ce:surname": "Vanichkul",
                                "ce:indexed-name": "Vanichkul N."
                            },
                            "@seq": "1",
                            "ce:initials": "N.",
                            "@_fa": "true",
                            "@type": "auth",
                            "ce:surname": "Vanichkul",
                            "@auid": "57883757300",
                            "ce:indexed-name": "Vanichkul N."
                        },
                        {
                            "ce:given-name": "Thananop",
                            "preferred-name": {
                                "ce:given-name": "Thananop",
                                "ce:initials": "T.",
                                "ce:surname": "Kobchaisawat",
                                "ce:indexed-name": "Kobchaisawat T."
                            },
                            "@seq": "2",
                            "ce:initials": "T.",
                            "@_fa": "true",
                            "@type": "auth",
                            "ce:surname": "Kobchaisawat",
                            "@auid": "56623114700",
                            "ce:indexed-name": "Kobchaisawat T."
                        },
                        {
                            "ce:given-name": "Thanarat",
                            "preferred-name": {
                                "ce:given-name": "Thanarat",
                                "ce:initials": "T.",
                                "ce:surname": "Chalidabhongse",
                                "ce:indexed-name": "Chalidabhongse T."
                            },
                            "@seq": "3",
                            "ce:initials": "T.",
                            "@_fa": "true",
                            "@type": "auth",
                            "ce:surname": "Chalidabhongse",
                            "@auid": "8943602100",
                            "ce:indexed-name": "Chalidabhongse T."
                        }
                    ]
                },
                "citation-title": "Visual-based Confusion Detection using a Cooperative Spatio-Temporal Deep Neural Networks",
                "abstracts": "Â© 2022 IEEE.Confusion is one of the most frequently observed emotions in daily life and can greatly affect the effectiveness and efficiency of communication. Especially in education, detecting learners' confusion and resolving it timely is crucial for effective teaching. Most research on facial expression recognition has only focused on detecting six basic emotions that do not include confusion. Even though the problem of detecting confusion has recently received more attention from researchers, analysis of both the spatial and temporal information with sufficient data is still short. In this study, we present a spatial-temporal network for detecting confusion in video images that was trained on the BAUM-1 database that collected by Zhalehpour et al. in 2017, which is, as far as we know, the largest public video dataset of labelled confusion images. The model includes the ResNet-18 Convolutional Neural Network for learning spatial information from facial images, and a Long-Short Term Memory (LSTM) recurrent neural network (RNN) for learning temporal information. By cascading two deep learning structures, our method reaches a more accurate result (73%) on the BAUM-1a database than the baseline LSTM network (67%). We also tested with our CUPIC-Confusion video dataset, which was collected from recording 15 participants' faces while they were watching a confusing video in an uncontrolled environment. The proposed model predicted one instance from 30 consecutive facial images within 0.04 sec. with 66% accuracy, while the baseline model took 0.02 sec. with 47%. Our method can be applied to any task that gains benefit from the automatic detection of confusion, such as supporting teachers or speakers to recognize confusion in their audience without manually observing them, improving human-machine interaction tasks, and supporting those who have difficulties with confusion perception.",
                "citation-info": {
                    "author-keywords": {"author-keyword": [
                        {
                            "$": "Confusion Detection",
                            "@xml:lang": "eng",
                            "@original": "y"
                        },
                        {
                            "$": "Deep Neural Network",
                            "@xml:lang": "eng",
                            "@original": "y"
                        },
                        {
                            "$": "Emotion",
                            "@xml:lang": "eng",
                            "@original": "y"
                        },
                        {
                            "$": "Facial Expression",
                            "@xml:lang": "eng",
                            "@original": "y"
                        }
                    ]},
                    "citation-type": {"@code": "cp"},
                    "citation-language": {
                        "@language": "English",
                        "@xml:lang": "eng"
                    },
                    "abstract-language": {
                        "@language": "English",
                        "@xml:lang": "eng"
                    }
                },
                "source": {
                    "website": {"ce:e-address": {
                        "$": "http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=9849160",
                        "@type": "email"
                    }},
                    "translated-sourcetitle": {
                        "$": "International Conference on Digital Government Technology and Innovation, DGTi-Con 2022 - Proceedings",
                        "@xml:lang": "eng"
                    },
                    "volisspag": {"pagerange": {
                        "@first": "80",
                        "@last": "85"
                    }},
                    "@type": "p",
                    "isbn": {
                        "@level": "volume",
                        "$": "9786168001226",
                        "@type": "electronic",
                        "@length": "13"
                    },
                    "additional-srcinfo": {"conferenceinfo": {
                        "confpublication": {"procpartno": "1 of 1"},
                        "confevent": {
                            "confname": "1st International Conference on Digital Government Technology and Innovation, DGTi-Con 2022",
                            "confnumber": "1",
                            "conforganization": "Digital Government Development Agency",
                            "confcatnumber": "CFP22BF0-ART",
                            "confseriestitle": "International Conference on Digital Government Technology and Innovation",
                            "conflocation": {
                                "@country": "tha",
                                "city": "Bangkok"
                            },
                            "confcode": "182153",
                            "confdate": {
                                "enddate": {
                                    "@day": "25",
                                    "@year": "2022",
                                    "@month": "03"
                                },
                                "startdate": {
                                    "@day": "24",
                                    "@year": "2022",
                                    "@month": "03"
                                }
                            }
                        }
                    }},
                    "sourcetitle": "International Conference on Digital Government Technology and Innovation, DGTi-Con 2022 - Proceedings",
                    "publicationdate": {
                        "year": "2022",
                        "date-text": {
                            "@xfab-added": "true",
                            "$": "2022"
                        }
                    },
                    "sourcetitle-abbrev": "Int. Conf. Digit. Gov. Technol. Innov., DGTi-Con - Proc.",
                    "@country": "usa",
                    "issuetitle": "International Conference on Digital Government Technology and Innovation, DGTi-Con 2022 - Proceedings",
                    "publicationyear": {"@first": "2022"},
                    "publisher": {"publishername": "Institute of Electrical and Electronics Engineers Inc."},
                    "@srcid": "21101107123"
                },
                "enhancement": {"classificationgroup": {"classifications": [
                    {
                        "@type": "ASJC",
                        "classification": [
                            {"$": "1706"},
                            {"$": "1707"},
                            {"$": "1710"},
                            {"$": "1802"},
                            {"$": "2718"},
                            {"$": "3313"},
                            {"$": "3321"}
                        ]
                    },
                    {
                        "@type": "CPXCLASS",
                        "classification": [
                            {
                                "classification-code": "461.4",
                                "classification-description": "Ergonomics and Human Factors Engineering"
                            },
                            {
                                "classification-code": "723.2",
                                "classification-description": "Data Processing and Image Processing"
                            },
                            {
                                "classification-code": "723.5",
                                "classification-description": "Computer Applications"
                            },
                            {
                                "classification-code": "741.2",
                                "classification-description": "Vision"
                            }
                        ]
                    },
                    {
                        "@type": "FLXCLASS",
                        "classification": {
                            "classification-code": "902",
                            "classification-description": "FLUIDEX; Related Topics"
                        }
                    },
                    {
                        "@type": "SUBJABBR",
                        "classification": [
                            {"$": "COMP"},
                            {"$": "DECI"},
                            {"$": "MEDI"},
                            {"$": "SOCI"}
                        ]
                    }
                ]}}
            },
            "item-info": {
                "copyright": {
                    "$": "Copyright 2022 Elsevier B.V., All rights reserved.",
                    "@type": "Elsevier"
                },
                "dbcollection": [
                    {"$": "CPX"},
                    {"$": "SCOPUS"},
                    {"$": "Scopusbase"}
                ],
                "history": {"date-created": {
                    "@day": "15",
                    "@timestamp": "BST 17:01:17",
                    "@year": "2022",
                    "@month": "09"
                }},
                "itemidlist": {
                    "itemid": [
                        {
                            "$": "638995024",
                            "@idtype": "PUI"
                        },
                        {
                            "$": "942836357",
                            "@idtype": "CAR-ID"
                        },
                        {
                            "$": "20223712737288",
                            "@idtype": "CPX"
                        },
                        {
                            "$": "20223186337",
                            "@idtype": "SCOPUS"
                        },
                        {
                            "$": "85137707004",
                            "@idtype": "SCP"
                        },
                        {
                            "$": "85137707004",
                            "@idtype": "SGR"
                        }
                    ],
                    "ce:doi": "10.1109/DGTi-CON53875.2022.9849192"
                }
            },
            "tail": {"bibliography": {
                "@refcount": "18",
                "reference": [
                    {
                        "ref-fulltext": "H. Wang, Y. Li, X. Hu, Y. Yang, Z. Meng, and K.-m. Chang, \"Using eeg to improve massive open online courses feedback interaction.\" in AIED Workshops, 2013.",
                        "@id": "1",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2013"},
                            "ref-title": {"ref-titletext": "Using eeg to improve massive open online courses feedback interaction"},
                            "refd-itemidlist": {"itemid": {
                                "$": "84924995273",
                                "@idtype": "SGR"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "H.",
                                    "@_fa": "true",
                                    "ce:surname": "Wang",
                                    "ce:indexed-name": "Wang H."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Li",
                                    "ce:indexed-name": "Li Y."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "X.",
                                    "@_fa": "true",
                                    "ce:surname": "Hu",
                                    "ce:indexed-name": "Hu X."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Yang",
                                    "ce:indexed-name": "Yang Y."
                                },
                                {
                                    "@seq": "5",
                                    "ce:initials": "Z.",
                                    "@_fa": "true",
                                    "ce:surname": "Meng",
                                    "ce:indexed-name": "Meng Z."
                                },
                                {
                                    "@seq": "6",
                                    "ce:initials": "K.-M.",
                                    "@_fa": "true",
                                    "ce:surname": "Chang",
                                    "ce:indexed-name": "Chang K.-M."
                                }
                            ]},
                            "ref-sourcetitle": "AIED Workshops"
                        },
                        "ce:source-text": "H. Wang, Y. Li, X. Hu, Y. Yang, Z. Meng, and K.-m. Chang, \"Using eeg to improve massive open online courses feedback interaction.\" in AIED Workshops, 2013."
                    },
                    {
                        "ref-fulltext": "F. T. Dursok, K. M. Geldbach, and P. Corballis, \"Detection confusion using facial electromyography,\" Human factors, vol. 54, no. 1, pp. 60-69, 2012.",
                        "@id": "2",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2012"},
                            "ref-title": {"ref-titletext": "Detection confusion using facial electromyography"},
                            "refd-itemidlist": {"itemid": {
                                "$": "84856460311",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {
                                    "@volume": "54",
                                    "@issue": "1"
                                },
                                "pagerange": {
                                    "@first": "60",
                                    "@last": "69"
                                }
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "F.T.",
                                    "@_fa": "true",
                                    "ce:surname": "Dursok",
                                    "ce:indexed-name": "Dursok F.T."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "K.M.",
                                    "@_fa": "true",
                                    "ce:surname": "Geldbach",
                                    "ce:indexed-name": "Geldbach K.M."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "P.",
                                    "@_fa": "true",
                                    "ce:surname": "Corballis",
                                    "ce:indexed-name": "Corballis P."
                                }
                            ]},
                            "ref-sourcetitle": "Human Factors"
                        },
                        "ce:source-text": "F. T. Dursok, K. M. Geldbach, and P. Corballis, \"Detection confusion using facial electromyography,\" Human factors, vol. 54, no. 1, pp. 60-69, 2012."
                    },
                    {
                        "ref-fulltext": "P. Ekman and W. V. Friesen, \"Constants across cultures in the face and emotion.\" Journal of personality and social psychology, vol. 17, no. 2, P. 124, 1971.",
                        "@id": "3",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "1971"},
                            "ref-title": {"ref-titletext": "Constants across cultures in the face and emotion"},
                            "refd-itemidlist": {"itemid": {
                                "$": "0015014687",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {
                                    "@volume": "17",
                                    "@issue": "2"
                                },
                                "pagerange": {"@first": "124"}
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "P.",
                                    "@_fa": "true",
                                    "ce:surname": "Ekman",
                                    "ce:indexed-name": "Ekman P."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "W.V.",
                                    "@_fa": "true",
                                    "ce:surname": "Friesen",
                                    "ce:indexed-name": "Friesen W.V."
                                }
                            ]},
                            "ref-sourcetitle": "Journal of Personality and Social Psychology"
                        },
                        "ce:source-text": "P. Ekman and W. V. Friesen, \"Constants across cultures in the face and emotion.\" Journal of personality and social psychology, vol. 17, no. 2, P. 124, 1971."
                    },
                    {
                        "ref-fulltext": "H. Jung, S. Lee, J. Yim, S. Park, and J. Kim, \"Joint fine-tuning in deep neural networks for facial expression recognition,\" in 2015 IEEE International Conference on Computer Vision (ICCV), 2015, pp. 2983-2991.",
                        "@id": "4",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2015"},
                            "ref-title": {"ref-titletext": "Joint fine-tuning in deep neural networks for facial expression recognition"},
                            "refd-itemidlist": {"itemid": {
                                "$": "84973917824",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "2983",
                                "@last": "2991"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "H.",
                                    "@_fa": "true",
                                    "ce:surname": "Jung",
                                    "ce:indexed-name": "Jung H."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Lee",
                                    "ce:indexed-name": "Lee S."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "J.",
                                    "@_fa": "true",
                                    "ce:surname": "Yim",
                                    "ce:indexed-name": "Yim J."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Park",
                                    "ce:indexed-name": "Park S."
                                },
                                {
                                    "@seq": "5",
                                    "ce:initials": "J.",
                                    "@_fa": "true",
                                    "ce:surname": "Kim",
                                    "ce:indexed-name": "Kim J."
                                }
                            ]},
                            "ref-sourcetitle": "2015 IEEE International Conference on Computer Vision (ICCV)"
                        },
                        "ce:source-text": "H. Jung, S. Lee, J. Yim, S. Park, and J. Kim, \"Joint fine-tuning in deep neural networks for facial expression recognition,\" in 2015 IEEE International Conference on Computer Vision (ICCV), 2015, pp. 2983-2991."
                    },
                    {
                        "ref-fulltext": "P. Lucey, J. F. Cohn, T. Kanade, J. Saragih, Z. Ambadar, and I. Matthews, \"The extended cohn-kanade dataset (ck+): A complete dataset for action unit and emotion-specified expression,\" in 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition-Workshops, 2010, pp. 94-101.",
                        "@id": "5",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2010"},
                            "ref-title": {"ref-titletext": "The extended cohn-kanade dataset (ck+): A complete dataset for action unit and emotion-specified expression"},
                            "refd-itemidlist": {"itemid": {
                                "$": "77956509035",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "94",
                                "@last": "101"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "P.",
                                    "@_fa": "true",
                                    "ce:surname": "Lucey",
                                    "ce:indexed-name": "Lucey P."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "J.F.",
                                    "@_fa": "true",
                                    "ce:surname": "Cohn",
                                    "ce:indexed-name": "Cohn J.F."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "T.",
                                    "@_fa": "true",
                                    "ce:surname": "Kanade",
                                    "ce:indexed-name": "Kanade T."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "J.",
                                    "@_fa": "true",
                                    "ce:surname": "Saragih",
                                    "ce:indexed-name": "Saragih J."
                                },
                                {
                                    "@seq": "5",
                                    "ce:initials": "Z.",
                                    "@_fa": "true",
                                    "ce:surname": "Ambadar",
                                    "ce:indexed-name": "Ambadar Z."
                                },
                                {
                                    "@seq": "6",
                                    "ce:initials": "I.",
                                    "@_fa": "true",
                                    "ce:surname": "Matthews",
                                    "ce:indexed-name": "Matthews I."
                                }
                            ]},
                            "ref-sourcetitle": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition-Workshops"
                        },
                        "ce:source-text": "P. Lucey, J. F. Cohn, T. Kanade, J. Saragih, Z. Ambadar, and I. Matthews, \"The extended cohn-kanade dataset (ck+): A complete dataset for action unit and emotion-specified expression,\" in 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition-Workshops, 2010, pp. 94-101."
                    },
                    {
                        "ref-fulltext": "M. Taini, G. Zhao, S. Z. Li, and M. Pietikainen, \"Facial expression recognition from near-infrared video sequences,\" in 2008 19th international Conference on Pattern Recognition, 2008, pp. 1-4.",
                        "@id": "6",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2008"},
                            "ref-title": {"ref-titletext": "Facial expression recognition from near-infrared video sequences"},
                            "refd-itemidlist": {"itemid": {
                                "$": "77957964718",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "1",
                                "@last": "4"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "M.",
                                    "@_fa": "true",
                                    "ce:surname": "Taini",
                                    "ce:indexed-name": "Taini M."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "G.",
                                    "@_fa": "true",
                                    "ce:surname": "Zhao",
                                    "ce:indexed-name": "Zhao G."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "S.Z.",
                                    "@_fa": "true",
                                    "ce:surname": "Li",
                                    "ce:indexed-name": "Li S.Z."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "M.",
                                    "@_fa": "true",
                                    "ce:surname": "Pietikainen",
                                    "ce:indexed-name": "Pietikainen M."
                                }
                            ]},
                            "ref-sourcetitle": "2008 19th international Conference on Pattern Recognition"
                        },
                        "ce:source-text": "M. Taini, G. Zhao, S. Z. Li, and M. Pietikainen, \"Facial expression recognition from near-infrared video sequences,\" in 2008 19th international Conference on Pattern Recognition, 2008, pp. 1-4."
                    },
                    {
                        "ref-fulltext": "M. Valstar, M. Pantic et al., \"Induced disgust, happiness and surprise: an addition to the mmi facial expression database,\" in Proc. 3rd Intern. Workshop on EMOTION (satellite of LREC): Corpora for Research on Emotion and Affect. Paris, France., 2010, P. 65.",
                        "@id": "7",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2010"},
                            "ref-title": {"ref-titletext": "Induced disgust, happiness and surprise: an addition to the mmi facial expression database"},
                            "refd-itemidlist": {"itemid": {
                                "$": "78650799805",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {"@first": "65"}},
                            "ref-authors": {
                                "author": [
                                    {
                                        "@seq": "1",
                                        "ce:initials": "M.",
                                        "@_fa": "true",
                                        "ce:surname": "Valstar",
                                        "ce:indexed-name": "Valstar M."
                                    },
                                    {
                                        "@seq": "2",
                                        "ce:initials": "M.",
                                        "@_fa": "true",
                                        "ce:surname": "Pantic",
                                        "ce:indexed-name": "Pantic M."
                                    }
                                ],
                                "et-al": null
                            },
                            "ref-sourcetitle": "Proc. 3rd Intern. Workshop on EMOTION (satellite of LREC): Corpora for Research on Emotion and Affect. Paris, France"
                        },
                        "ce:source-text": "M. Valstar, M. Pantic et al., \"Induced disgust, happiness and surprise: an addition to the mmi facial expression database,\" in Proc. 3rd Intern. Workshop on EMOTION (satellite of LREC): Corpora for Research on Emotion and Affect. Paris, France., 2010, P. 65."
                    },
                    {
                        "ref-fulltext": "K. Zhang, Y. Huang, Y. Du, and L. Wang, \"Facial expression recognition based on deep evolutional spatial-temporal networks,\" IEEE Transactions on Image Processing, vol. 26, no. 9, pp. 4193-4203, 2017.",
                        "@id": "8",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2017"},
                            "ref-title": {"ref-titletext": "Facial expression recognition based on deep evolutional spatial-temporal networks"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85027517303",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {
                                    "@volume": "26",
                                    "@issue": "9"
                                },
                                "pagerange": {
                                    "@first": "4193",
                                    "@last": "4203"
                                }
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "K.",
                                    "@_fa": "true",
                                    "ce:surname": "Zhang",
                                    "ce:indexed-name": "Zhang K."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Huang",
                                    "ce:indexed-name": "Huang Y."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Du",
                                    "ce:indexed-name": "Du Y."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "L.",
                                    "@_fa": "true",
                                    "ce:surname": "Wang",
                                    "ce:indexed-name": "Wang L."
                                }
                            ]},
                            "ref-sourcetitle": "IEEE Transactions on Image Processing"
                        },
                        "ce:source-text": "K. Zhang, Y. Huang, Y. Du, and L. Wang, \"Facial expression recognition based on deep evolutional spatial-temporal networks,\" IEEE Transactions on Image Processing, vol. 26, no. 9, pp. 4193-4203, 2017."
                    },
                    {
                        "ref-fulltext": "S. Zhalehpour, O. Onder, Z. Akhtar, and C. E. Erdem, \"Baum-1: A spontaneous audio-visual face database of affective and mental states,\" IEEE Transactions on Affective Computing, vol. 8, no. 3, pp. 300-313, 2017.",
                        "@id": "9",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2017"},
                            "ref-title": {"ref-titletext": "Baum-1: A spontaneous audio-visual face database of affective and mental states"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85029943602",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {
                                    "@volume": "8",
                                    "@issue": "3"
                                },
                                "pagerange": {
                                    "@first": "300",
                                    "@last": "313"
                                }
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Zhalehpour",
                                    "ce:indexed-name": "Zhalehpour S."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "O.",
                                    "@_fa": "true",
                                    "ce:surname": "Onder",
                                    "ce:indexed-name": "Onder O."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "Z.",
                                    "@_fa": "true",
                                    "ce:surname": "Akhtar",
                                    "ce:indexed-name": "Akhtar Z."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "C.E.",
                                    "@_fa": "true",
                                    "ce:surname": "Erdem",
                                    "ce:indexed-name": "Erdem C.E."
                                }
                            ]},
                            "ref-sourcetitle": "IEEE Transactions on Affective Computing"
                        },
                        "ce:source-text": "S. Zhalehpour, O. Onder, Z. Akhtar, and C. E. Erdem, \"Baum-1: A spontaneous audio-visual face database of affective and mental states,\" IEEE Transactions on Affective Computing, vol. 8, no. 3, pp. 300-313, 2017."
                    },
                    {
                        "ref-fulltext": "Z. Shi, Y. Zhang, C. Bian, and W. Lu, \"Automatic academic confusion recognition in online learning based on facial expression,\" in 2019 14th International Conference on Computer Science Education (ICCSE), 2019, pp.528-532.",
                        "@id": "10",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2019"},
                            "ref-title": {"ref-titletext": "Automatic academic confusion recognition in online learning based on facial expression"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85073252761",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "528",
                                "@last": "532"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "Z.",
                                    "@_fa": "true",
                                    "ce:surname": "Shi",
                                    "ce:indexed-name": "Shi Z."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Zhang",
                                    "ce:indexed-name": "Zhang Y."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "C.",
                                    "@_fa": "true",
                                    "ce:surname": "Bian",
                                    "ce:indexed-name": "Bian C."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "W.",
                                    "@_fa": "true",
                                    "ce:surname": "Lu",
                                    "ce:indexed-name": "Lu W."
                                }
                            ]},
                            "ref-sourcetitle": "2019 14th International Conference on Computer Science Education (ICCSE)"
                        },
                        "ce:source-text": "Z. Shi, Y. Zhang, C. Bian, and W. Lu, \"Automatic academic confusion recognition in online learning based on facial expression,\" in 2019 14th International Conference on Computer Science Education (ICCSE), 2019, pp.528-532."
                    },
                    {
                        "ref-fulltext": "K. Simonyan and A. Zisserman, \"Very deep convolutional networks for large-scale image recognition,\" 2015.",
                        "@id": "11",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2015"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85083953063",
                                "@idtype": "SGR"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "K.",
                                    "@_fa": "true",
                                    "ce:surname": "Simonyan",
                                    "ce:indexed-name": "Simonyan K."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "A.",
                                    "@_fa": "true",
                                    "ce:surname": "Zisserman",
                                    "ce:indexed-name": "Zisserman A."
                                }
                            ]},
                            "ref-sourcetitle": "Very Deep Convolutional Networks For Large-Scale Image Recognition"
                        },
                        "ce:source-text": "K. Simonyan and A. Zisserman, \"Very deep convolutional networks for large-scale image recognition,\" 2015."
                    },
                    {
                        "ref-fulltext": "N. Borges, L. Lindblom, B. Clarke, A. Gander, and R. Lowe, \"Classifying confusion: Autodetection of communicative misunderstandings using facial action units,\" in 2019 8th International Conference on Affective Computing and Intelligent interaction Workshops and Demos (ACIIW), 2019, pp. 401-406.",
                        "@id": "12",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2019"},
                            "ref-title": {"ref-titletext": "Classifying confusion: Autodetection of communicative misunderstandings using facial action units"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85077817795",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "401",
                                "@last": "406"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "N.",
                                    "@_fa": "true",
                                    "ce:surname": "Borges",
                                    "ce:indexed-name": "Borges N."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "L.",
                                    "@_fa": "true",
                                    "ce:surname": "Lindblom",
                                    "ce:indexed-name": "Lindblom L."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "B.",
                                    "@_fa": "true",
                                    "ce:surname": "Clarke",
                                    "ce:indexed-name": "Clarke B."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "A.",
                                    "@_fa": "true",
                                    "ce:surname": "Gander",
                                    "ce:indexed-name": "Gander A."
                                },
                                {
                                    "@seq": "5",
                                    "ce:initials": "R.",
                                    "@_fa": "true",
                                    "ce:surname": "Lowe",
                                    "ce:indexed-name": "Lowe R."
                                }
                            ]},
                            "ref-sourcetitle": "2019 8th International Conference on Affective Computing and Intelligent interaction Workshops and Demos (ACIIW)"
                        },
                        "ce:source-text": "N. Borges, L. Lindblom, B. Clarke, A. Gander, and R. Lowe, \"Classifying confusion: Autodetection of communicative misunderstandings using facial action units,\" in 2019 8th International Conference on Affective Computing and Intelligent interaction Workshops and Demos (ACIIW), 2019, pp. 401-406."
                    },
                    {
                        "ref-fulltext": "P. Ekman and E. L. Rosenberg, What the Face Reveals: Basic and Applied Studies of Spontaneous Expression Using the Facial Action Coding System (FACS). Oxford University Press, 2005.",
                        "@id": "13",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2005"},
                            "refd-itemidlist": {"itemid": {
                                "$": "84921599912",
                                "@idtype": "SGR"
                            }},
                            "ref-text": "Oxford University Press",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "P.",
                                    "@_fa": "true",
                                    "ce:surname": "Ekman",
                                    "ce:indexed-name": "Ekman P."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "E.L.",
                                    "@_fa": "true",
                                    "ce:surname": "Rosenberg",
                                    "ce:indexed-name": "Rosenberg E.L."
                                }
                            ]},
                            "ref-sourcetitle": "What the Face Reveals: Basic and Applied Studies of Spontaneous Expression Using the Facial Action Coding System (FACS)"
                        },
                        "ce:source-text": "P. Ekman and E. L. Rosenberg, What the Face Reveals: Basic and Applied Studies of Spontaneous Expression Using the Facial Action Coding System (FACS). Oxford University Press, 2005."
                    },
                    {
                        "ref-fulltext": "C. Busso, M. Bulut, C.-C. Lee, A. Kazemzadeh, E. Mower, S. Kim, J. N. Chang, S. Lee, and S. S. Narayanan, \"Iemocap: Interactive emotional dyadic motion capture database,\" Language resource and evaluation, vol. 42, no. 4, pp. 335-359, 2008.",
                        "@id": "14",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2008"},
                            "ref-title": {"ref-titletext": "Iemocap: Interactive emotional dyadic motion capture database"},
                            "refd-itemidlist": {"itemid": {
                                "$": "59849093076",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {
                                    "@volume": "42",
                                    "@issue": "4"
                                },
                                "pagerange": {
                                    "@first": "335",
                                    "@last": "359"
                                }
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "C.",
                                    "@_fa": "true",
                                    "ce:surname": "Busso",
                                    "ce:indexed-name": "Busso C."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "M.",
                                    "@_fa": "true",
                                    "ce:surname": "Bulut",
                                    "ce:indexed-name": "Bulut M."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "C.-C.",
                                    "@_fa": "true",
                                    "ce:surname": "Lee",
                                    "ce:indexed-name": "Lee C.-C."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "A.",
                                    "@_fa": "true",
                                    "ce:surname": "Kazemzadeh",
                                    "ce:indexed-name": "Kazemzadeh A."
                                },
                                {
                                    "@seq": "5",
                                    "ce:initials": "E.",
                                    "@_fa": "true",
                                    "ce:surname": "Mower",
                                    "ce:indexed-name": "Mower E."
                                },
                                {
                                    "@seq": "6",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Kim",
                                    "ce:indexed-name": "Kim S."
                                },
                                {
                                    "@seq": "7",
                                    "ce:initials": "J.N.",
                                    "@_fa": "true",
                                    "ce:surname": "Chang",
                                    "ce:indexed-name": "Chang J.N."
                                },
                                {
                                    "@seq": "8",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Lee",
                                    "ce:indexed-name": "Lee S."
                                },
                                {
                                    "@seq": "9",
                                    "ce:initials": "S.S.",
                                    "@_fa": "true",
                                    "ce:surname": "Narayanan",
                                    "ce:indexed-name": "Narayanan S.S."
                                }
                            ]},
                            "ref-sourcetitle": "Language Resource and Evaluation"
                        },
                        "ce:source-text": "C. Busso, M. Bulut, C.-C. Lee, A. Kazemzadeh, E. Mower, S. Kim, J. N. Chang, S. Lee, and S. S. Narayanan, \"Iemocap: Interactive emotional dyadic motion capture database,\" Language resource and evaluation, vol. 42, no. 4, pp. 335-359, 2008."
                    },
                    {
                        "ref-fulltext": "L. Cai, J. Dong, and M. Wei, \"Multi-modal emotion recognition from speech and facial expression based on deep learning,\" in 2020 Chinese Automation Congress (CAG), 2020, pp. 5726-5729.",
                        "@id": "15",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2020"},
                            "ref-title": {"ref-titletext": "Multi-modal emotion recognition from speech and facial expression based on deep learning"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85100935114",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "5726",
                                "@last": "5729"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "L.",
                                    "@_fa": "true",
                                    "ce:surname": "Cai",
                                    "ce:indexed-name": "Cai L."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "J.",
                                    "@_fa": "true",
                                    "ce:surname": "Dong",
                                    "ce:indexed-name": "Dong J."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "M.",
                                    "@_fa": "true",
                                    "ce:surname": "Wei",
                                    "ce:indexed-name": "Wei M."
                                }
                            ]},
                            "ref-sourcetitle": "2020 Chinese Automation Congress (CAG)"
                        },
                        "ce:source-text": "L. Cai, J. Dong, and M. Wei, \"Multi-modal emotion recognition from speech and facial expression based on deep learning,\" in 2020 Chinese Automation Congress (CAG), 2020, pp. 5726-5729."
                    },
                    {
                        "ref-fulltext": "M. Hucko, R. Moro, and M. Bielikova, \"Confusion detection dataset of mouse and eye movements,\" in Adjunct Publication of the 28th ACM Conference on User Modeling, Adaptation and Personalization, 2020, pp. 281-286.",
                        "@id": "16",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2020"},
                            "ref-title": {"ref-titletext": "Confusion detection dataset of mouse and eye movements"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85089269836",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "281",
                                "@last": "286"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "M.",
                                    "@_fa": "true",
                                    "ce:surname": "Hucko",
                                    "ce:indexed-name": "Hucko M."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "R.",
                                    "@_fa": "true",
                                    "ce:surname": "Moro",
                                    "ce:indexed-name": "Moro R."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "M.",
                                    "@_fa": "true",
                                    "ce:surname": "Bielikova",
                                    "ce:indexed-name": "Bielikova M."
                                }
                            ]},
                            "ref-sourcetitle": "Adjunct Publication of the 28th ACM Conference on User Modeling, Adaptation and Personalization"
                        },
                        "ce:source-text": "M. Hucko, R. Moro, and M. Bielikova, \"Confusion detection dataset of mouse and eye movements,\" in Adjunct Publication of the 28th ACM Conference on User Modeling, Adaptation and Personalization, 2020, pp. 281-286."
                    },
                    {
                        "ref-fulltext": "X. Zhou, D. Wang, and P. KrÃ¤henbÃ¼hl, \"Objects as points,\" 2019.",
                        "@id": "17",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2019"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85074698994",
                                "@idtype": "SGR"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "X.",
                                    "@_fa": "true",
                                    "ce:surname": "Zhou",
                                    "ce:indexed-name": "Zhou X."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "D.",
                                    "@_fa": "true",
                                    "ce:surname": "Wang",
                                    "ce:indexed-name": "Wang D."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "P.",
                                    "@_fa": "true",
                                    "ce:surname": "KrÃ¤henbÃ¼hl",
                                    "ce:indexed-name": "Krahenbuhl P."
                                }
                            ]},
                            "ref-sourcetitle": "Objects As Points"
                        },
                        "ce:source-text": "X. Zhou, D. Wang, and P. KrÃ¤henbÃ¼hl, \"Objects as points,\" 2019."
                    },
                    {
                        "ref-fulltext": "T. Baltrusaitis, A. Zadeh, Y. C. Lim, and L.-P. Morency, \"Openface 2.0: Facial behavior analysis toolkit,\" in 2018 13th IEEE International Conference on Automatic Face Gesture Recognition (FG 2018), 2018, pp. 59-66.",
                        "@id": "18",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2018"},
                            "ref-title": {"ref-titletext": "Openface 2.0: Facial behavior analysis toolkit"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85049395496",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "59",
                                "@last": "66"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "T.",
                                    "@_fa": "true",
                                    "ce:surname": "Baltrusaitis",
                                    "ce:indexed-name": "Baltrusaitis T."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "A.",
                                    "@_fa": "true",
                                    "ce:surname": "Zadeh",
                                    "ce:indexed-name": "Zadeh A."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "Y.C.",
                                    "@_fa": "true",
                                    "ce:surname": "Lim",
                                    "ce:indexed-name": "Lim Y.C."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "L.-P.",
                                    "@_fa": "true",
                                    "ce:surname": "Morency",
                                    "ce:indexed-name": "Morency L.-P."
                                }
                            ]},
                            "ref-sourcetitle": "2018 13th IEEE International Conference on Automatic Face Gesture Recognition (FG 2018)"
                        },
                        "ce:source-text": "T. Baltrusaitis, A. Zadeh, Y. C. Lim, and L.-P. Morency, \"Openface 2.0: Facial behavior analysis toolkit,\" in 2018 13th IEEE International Conference on Automatic Face Gesture Recognition (FG 2018), 2018, pp. 59-66."
                    }
                ]
            }}
        }
    },
    "affiliation": {
        "affiliation-city": "Bangkok",
        "@id": "60028190",
        "affilname": "Chulalongkorn University",
        "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60028190",
        "affiliation-country": "Thailand"
    },
    "coredata": {
        "srctype": "p",
        "eid": "2-s2.0-85137707004",
        "dc:description": "Confusion is one of the most frequently observed emotions in daily life and can greatly affect the effectiveness and efficiency of communication. Especially in education, detecting learners' confusion and resolving it timely is crucial for effective teaching. Most research on facial expression recognition has only focused on detecting six basic emotions that do not include confusion. Even though the problem of detecting confusion has recently received more attention from researchers, analysis of both the spatial and temporal information with sufficient data is still short. In this study, we present a spatial-temporal network for detecting confusion in video images that was trained on the BAUM-1 database that collected by Zhalehpour et al. in 2017, which is, as far as we know, the largest public video dataset of labelled confusion images. The model includes the ResNet-18 Convolutional Neural Network for learning spatial information from facial images, and a Long-Short Term Memory (LSTM) recurrent neural network (RNN) for learning temporal information. By cascading two deep learning structures, our method reaches a more accurate result (73%) on the BAUM-1a database than the baseline LSTM network (67%). We also tested with our CUPIC-Confusion video dataset, which was collected from recording 15 participants' faces while they were watching a confusing video in an uncontrolled environment. The proposed model predicted one instance from 30 consecutive facial images within 0.04 sec. with 66% accuracy, while the baseline model took 0.02 sec. with 47%. Our method can be applied to any task that gains benefit from the automatic detection of confusion, such as supporting teachers or speakers to recognize confusion in their audience without manually observing them, improving human-machine interaction tasks, and supporting those who have difficulties with confusion perception.",
        "prism:coverDate": "2022-01-01",
        "prism:aggregationType": "Conference Proceeding",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85137707004",
        "subtypeDescription": "Conference Paper",
        "dc:creator": {"author": [{
            "ce:given-name": "Nun",
            "preferred-name": {
                "ce:given-name": "Nun",
                "ce:initials": "N.",
                "ce:surname": "Vanichkul",
                "ce:indexed-name": "Vanichkul N."
            },
            "@seq": "1",
            "ce:initials": "N.",
            "@_fa": "true",
            "affiliation": {
                "@id": "60028190",
                "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60028190"
            },
            "ce:surname": "Vanichkul",
            "@auid": "57883757300",
            "author-url": "https://api.elsevier.com/content/author/author_id/57883757300",
            "ce:indexed-name": "Vanichkul N."
        }]},
        "link": [
            {
                "@_fa": "true",
                "@rel": "self",
                "@href": "https://api.elsevier.com/content/abstract/scopus_id/85137707004"
            },
            {
                "@_fa": "true",
                "@rel": "scopus",
                "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85137707004&origin=inward"
            },
            {
                "@_fa": "true",
                "@rel": "scopus-citedby",
                "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85137707004&origin=inward"
            }
        ],
        "prism:isbn": "9786168001226",
        "prism:publicationName": "International Conference on Digital Government Technology and Innovation, DGTi-Con 2022 - Proceedings",
        "source-id": "21101107123",
        "citedby-count": "0",
        "subtype": "cp",
        "prism:pageRange": "80-85",
        "dc:title": "Visual-based Confusion Detection using a Cooperative Spatio-Temporal Deep Neural Networks",
        "prism:endingPage": "85",
        "openaccess": "0",
        "openaccessFlag": "false",
        "prism:doi": "10.1109/DGTi-CON53875.2022.9849192",
        "prism:startingPage": "80",
        "publishercopyright": "Â© 2022 IEEE.",
        "dc:identifier": "SCOPUS_ID:85137707004",
        "dc:publisher": "Institute of Electrical and Electronics Engineers Inc."
    },
    "idxterms": {"mainterm": [
        {
            "$": "Confusion detection",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "Daily lives",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "Effectiveness and efficiencies",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "Emotion",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "Facial Expressions",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "Facial images",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "Spatial informations",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "Spatio-temporal",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "Temporal information",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "Video dataset",
            "@weight": "b",
            "@candidate": "n"
        }
    ]},
    "language": {"@xml:lang": "eng"},
    "authkeywords": {"author-keyword": [
        {
            "@_fa": "true",
            "$": "Confusion Detection"
        },
        {
            "@_fa": "true",
            "$": "Deep Neural Network"
        },
        {
            "@_fa": "true",
            "$": "Emotion"
        },
        {
            "@_fa": "true",
            "$": "Facial Expression"
        }
    ]},
    "subject-areas": {"subject-area": [
        {
            "@_fa": "true",
            "$": "Computer Science Applications",
            "@code": "1706",
            "@abbrev": "COMP"
        },
        {
            "@_fa": "true",
            "$": "Computer Vision and Pattern Recognition",
            "@code": "1707",
            "@abbrev": "COMP"
        },
        {
            "@_fa": "true",
            "$": "Information Systems",
            "@code": "1710",
            "@abbrev": "COMP"
        },
        {
            "@_fa": "true",
            "$": "Information Systems and Management",
            "@code": "1802",
            "@abbrev": "DECI"
        },
        {
            "@_fa": "true",
            "$": "Health Informatics",
            "@code": "2718",
            "@abbrev": "MEDI"
        },
        {
            "@_fa": "true",
            "$": "Transportation",
            "@code": "3313",
            "@abbrev": "SOCI"
        },
        {
            "@_fa": "true",
            "$": "Public Administration",
            "@code": "3321",
            "@abbrev": "SOCI"
        }
    ]},
    "authors": {"author": [
        {
            "ce:given-name": "Nun",
            "preferred-name": {
                "ce:given-name": "Nun",
                "ce:initials": "N.",
                "ce:surname": "Vanichkul",
                "ce:indexed-name": "Vanichkul N."
            },
            "@seq": "1",
            "ce:initials": "N.",
            "@_fa": "true",
            "affiliation": {
                "@id": "60028190",
                "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60028190"
            },
            "ce:surname": "Vanichkul",
            "@auid": "57883757300",
            "author-url": "https://api.elsevier.com/content/author/author_id/57883757300",
            "ce:indexed-name": "Vanichkul N."
        },
        {
            "ce:given-name": "Thananop",
            "preferred-name": {
                "ce:given-name": "Thananop",
                "ce:initials": "T.",
                "ce:surname": "Kobchaisawat",
                "ce:indexed-name": "Kobchaisawat T."
            },
            "@seq": "2",
            "ce:initials": "T.",
            "@_fa": "true",
            "affiliation": {
                "@id": "60028190",
                "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60028190"
            },
            "ce:surname": "Kobchaisawat",
            "@auid": "56623114700",
            "author-url": "https://api.elsevier.com/content/author/author_id/56623114700",
            "ce:indexed-name": "Kobchaisawat T."
        },
        {
            "ce:given-name": "Thanarat",
            "preferred-name": {
                "ce:given-name": "Thanarat",
                "ce:initials": "T.",
                "ce:surname": "Chalidabhongse",
                "ce:indexed-name": "Chalidabhongse T."
            },
            "@seq": "3",
            "ce:initials": "T.",
            "@_fa": "true",
            "affiliation": {
                "@id": "60028190",
                "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60028190"
            },
            "ce:surname": "Chalidabhongse",
            "@auid": "8943602100",
            "author-url": "https://api.elsevier.com/content/author/author_id/8943602100",
            "ce:indexed-name": "Chalidabhongse T."
        }
    ]}
}}