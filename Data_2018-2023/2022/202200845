{"abstracts-retrieval-response": {
    "item": {
        "ait:process-info": {
            "ait:status": {
                "@state": "update",
                "@type": "core",
                "@stage": "S300"
            },
            "ait:date-delivered": {
                "@day": "27",
                "@timestamp": "2023-05-27T08:29:15.000015-04:00",
                "@year": "2023",
                "@month": "05"
            },
            "ait:date-sort": {
                "@day": "01",
                "@year": "2022",
                "@month": "10"
            }
        },
        "xocs:meta": {"xocs:funding-list": {
            "@pui-match": "primary",
            "@has-funding-info": "1",
            "xocs:funding": [
                {"xocs:funding-agency-matched-string": "Second Century Fund"},
                {
                    "xocs:funding-agency-matched-string": "Thailand Science Research and Innovation Fund Chulalongkorn University",
                    "xocs:funding-id": "SOC66210008"
                },
                {
                    "xocs:funding-agency-matched-string": "Chulalongkorn University",
                    "xocs:funding-agency-acronym": "CU",
                    "xocs:funding-agency": "Chulalongkorn University",
                    "xocs:funding-agency-id": "http://data.elsevier.com/vocabulary/SciValFunders/501100002873",
                    "xocs:funding-agency-country": "http://sws.geonames.org/1605651/"
                }
            ],
            "xocs:funding-addon-generated-timestamp": "2023-03-26T02:58:46.732Z",
            "xocs:funding-text": "Funding: This Research project is supported by the Second Century Fund (C2F), Chulalongkorn University. This Research is also funded by the Thailand Science Research and Innovation Fund Chulalongkorn University (SOC66210008).",
            "xocs:funding-addon-type": "http://vtw.elsevier.com/data/voc/AddOnTypes/50.7/aggregated-refined"
        }},
        "bibrecord": {
            "head": {
                "author-group": [
                    {
                        "affiliation": {
                            "country": "Thailand",
                            "postal-code": "10330",
                            "@afid": "60028190",
                            "@country": "tha",
                            "city": "Bangkok",
                            "organization": [
                                {"$": "Wireless Communication Ecosystem Research Unit"},
                                {"$": "Department of Electrical Engineering"},
                                {"$": "Chulalongkorn University"}
                            ],
                            "affiliation-id": {
                                "@afid": "60028190",
                                "@dptid": "113845132"
                            },
                            "@affiliation-instance-id": "OB2BibRecID-946940425-34b87b37a7d4d92b4b2a1b8317e4852c-1",
                            "ce:source-text": "Wireless Communication Ecosystem Research Unit, Department of Electrical Engineering, Chulalongkorn University, Bangkok, 10330, Thailand",
                            "@dptid": "113845132"
                        },
                        "author": [
                            {
                                "ce:given-name": "Rizwan",
                                "preferred-name": {
                                    "ce:given-name": "Rizwan",
                                    "ce:initials": "R.",
                                    "ce:surname": "Ullah",
                                    "ce:indexed-name": "Ullah R."
                                },
                                "@author-instance-id": "OB2BibRecID-946940425-64f03cdb81016841f9644f30e8b430d0-1",
                                "@seq": "1",
                                "ce:initials": "R.",
                                "@_fa": "true",
                                "@type": "auth",
                                "ce:surname": "Ullah",
                                "@auid": "58256620500",
                                "ce:indexed-name": "Ullah R."
                            },
                            {
                                "ce:given-name": "Lunchakorn",
                                "preferred-name": {
                                    "ce:given-name": "Lunchakorn",
                                    "ce:initials": "L.",
                                    "ce:surname": "Wuttisittikulkij",
                                    "ce:indexed-name": "Wuttisittikulkij L."
                                },
                                "@author-instance-id": "OB2BibRecID-946940425-77099c2251815471c00f97b6aaba7d9f-1",
                                "@seq": "2",
                                "ce:initials": "L.",
                                "@_fa": "true",
                                "@type": "auth",
                                "ce:surname": "Wuttisittikulkij",
                                "@auid": "6701827990",
                                "ce:indexed-name": "Wuttisittikulkij L."
                            },
                            {
                                "ce:given-name": "Sushank",
                                "preferred-name": {
                                    "ce:given-name": "Sushank",
                                    "ce:initials": "S.",
                                    "ce:surname": "Chaudhary",
                                    "ce:indexed-name": "Chaudhary S."
                                },
                                "@author-instance-id": "OB2BibRecID-946940425-895ec6517db2b0092b2141f4c859319b-1",
                                "@seq": "3",
                                "ce:initials": "S.",
                                "@_fa": "true",
                                "@type": "auth",
                                "ce:surname": "Chaudhary",
                                "@auid": "56243987800",
                                "ce:indexed-name": "Chaudhary S."
                            },
                            {
                                "ce:given-name": "Amir",
                                "preferred-name": {
                                    "ce:given-name": "Amir",
                                    "ce:initials": "A.",
                                    "ce:surname": "Parnianifard",
                                    "ce:indexed-name": "Parnianifard A."
                                },
                                "@author-instance-id": "OB2BibRecID-946940425-820ee92635b56c4b625f5d2c3f6a81fc-1",
                                "@seq": "4",
                                "ce:initials": "A.",
                                "@_fa": "true",
                                "@type": "auth",
                                "ce:surname": "Parnianifard",
                                "@auid": "57240218700",
                                "ce:indexed-name": "Parnianifard A."
                            },
                            {
                                "ce:given-name": "Shashi",
                                "preferred-name": {
                                    "ce:given-name": "Shashi",
                                    "ce:initials": "S.",
                                    "ce:surname": "Shah",
                                    "ce:indexed-name": "Shah S."
                                },
                                "@author-instance-id": "OB2BibRecID-946940425-d5a9c1f97c907be314faa83b01363071-1",
                                "@seq": "5",
                                "ce:initials": "S.",
                                "@_fa": "true",
                                "@type": "auth",
                                "ce:surname": "Shah",
                                "@auid": "56890141600",
                                "ce:indexed-name": "Shah S."
                            }
                        ]
                    },
                    {
                        "affiliation": {
                            "country": "Pakistan",
                            "postal-code": "25000",
                            "@afid": "60106555",
                            "@country": "pak",
                            "city": "Peshawar",
                            "organization": [
                                {"$": "Department of Physics"},
                                {"$": "Islamia College Peshawar"}
                            ],
                            "affiliation-id": {
                                "@afid": "60106555",
                                "@dptid": "116971095"
                            },
                            "@affiliation-instance-id": "OB2BibRecID-946940425-11babeed5e2121414469c04b25c0ac6b-1",
                            "ce:source-text": "Department of Physics, Islamia College Peshawar, Peshawar, 25000, Pakistan",
                            "@dptid": "116971095"
                        },
                        "author": [{
                            "ce:given-name": "Muhammad",
                            "preferred-name": {
                                "ce:given-name": "Muhammad",
                                "ce:initials": "M.",
                                "ce:surname": "Ibrar",
                                "ce:indexed-name": "Ibrar M."
                            },
                            "@author-instance-id": "OB2BibRecID-946940425-d514a0832694c5052f33bcc720fbd053-1",
                            "@seq": "6",
                            "ce:initials": "M.",
                            "@_fa": "true",
                            "@type": "auth",
                            "ce:surname": "Ibrar",
                            "@auid": "7801542125",
                            "ce:indexed-name": "Ibrar M."
                        }]
                    },
                    {
                        "affiliation": {
                            "country": "China",
                            "postal-code": "230026",
                            "@afid": "60133708",
                            "@country": "chn",
                            "city": "Hefei",
                            "organization": [
                                {"$": "National Engineering Laboratory for Speech and Language Information Processing"},
                                {"$": "University of Science and Technology of China"}
                            ],
                            "affiliation-id": [
                                {"@afid": "60133708"},
                                {"@afid": "60019118"}
                            ],
                            "@affiliation-instance-id": "OB2BibRecID-946940425-ce40c66d6e1699c7f11842787548b72c-1",
                            "ce:source-text": "National Engineering Laboratory for Speech and Language Information Processing, University of Science and Technology of China, Hefei, 230026, China"
                        },
                        "author": [{
                            "ce:given-name": "Fazal-E",
                            "preferred-name": {
                                "ce:given-name": "Fazal E.",
                                "ce:initials": "F.E.",
                                "ce:surname": "Wahab",
                                "ce:indexed-name": "Wahab F.E."
                            },
                            "@author-instance-id": "OB2BibRecID-946940425-011d1916e0a71e35b73a8d23992f633c-1",
                            "@seq": "7",
                            "ce:initials": "F.-E.",
                            "@_fa": "true",
                            "@type": "auth",
                            "ce:surname": "Wahab",
                            "@auid": "25226056000",
                            "ce:indexed-name": "Wahab F.-E."
                        }]
                    }
                ],
                "citation-title": "End-to-End Deep Convolutional Recurrent Models for Noise Robust Waveform Speech Enhancement",
                "abstracts": "© 2022 by the authors.Because of their simple design structure, end-to-end deep learning (E2E-DL) models have gained a lot of attention for speech enhancement. A number of DL models have achieved excellent results in eliminating the background noise and enhancing the quality as well as the intelligibility of noisy speech. Designing resource-efficient and compact models during real-time processing is still a key challenge. In order to enhance the accomplishment of E2E models, the sequential and local characteristics of speech signal should be efficiently taken into consideration while modeling. In this paper, we present resource-efficient and compact neural models for end-to-end noise-robust waveform-based speech enhancement. Combining the Convolutional Encode-Decoder (CED) and Recurrent Neural Networks (RNNs) in the Convolutional Recurrent Network (CRN) framework, we have aimed at different speech enhancement systems. Different noise types and speakers are used to train and test the proposed models. With LibriSpeech and the DEMAND dataset, the experiments show that the proposed models lead to improved quality and intelligibility with fewer trainable parameters, notably reduced model complexity, and inference time than existing recurrent and convolutional models. The quality and intelligibility are improved by 31.61% and 17.18% over the noisy speech. We further performed cross corpus analysis to demonstrate the generalization of the proposed E2E SE models across different speech datasets.",
                "correspondence": [
                    {
                        "affiliation": {
                            "country": "Thailand",
                            "postal-code": "10330",
                            "@country": "tha",
                            "city": "Bangkok",
                            "organization": [
                                {"$": "Wireless Communication Ecosystem Research Unit"},
                                {"$": "Department of Electrical Engineering"},
                                {"$": "Chulalongkorn University"}
                            ],
                            "@affiliation-instance-id": "OB2BibRecID-946940425-34b87b37a7d4d92b4b2a1b8317e4852c-1",
                            "ce:source-text": "Wireless Communication Ecosystem Research Unit, Department of Electrical Engineering, Chulalongkorn University, Bangkok, 10330, Thailand"
                        },
                        "person": {
                            "ce:given-name": "Rizwan",
                            "@author-instance-id": "OB2BibRecID-946940425-f29f4d1d15e95ddd9140a896e7631484-1",
                            "ce:initials": "R.",
                            "ce:surname": "Ullah",
                            "ce:indexed-name": "Ullah R."
                        }
                    },
                    {
                        "affiliation": {
                            "country": "Thailand",
                            "postal-code": "10330",
                            "@country": "tha",
                            "city": "Bangkok",
                            "organization": [
                                {"$": "Wireless Communication Ecosystem Research Unit"},
                                {"$": "Department of Electrical Engineering"},
                                {"$": "Chulalongkorn University"}
                            ],
                            "@affiliation-instance-id": "OB2BibRecID-946940425-d9438b96dd645418bc10315d8642f004-1",
                            "ce:source-text": "Wireless Communication Ecosystem Research Unit, Department of Electrical Engineering, Chulalongkorn University, Bangkok, 10330, Thailand"
                        },
                        "person": {
                            "ce:given-name": "Lunchakorn",
                            "@author-instance-id": "OB2BibRecID-946940425-8fe85ed2fae635b220dfaa20c63611e6-1",
                            "ce:initials": "L.",
                            "ce:surname": "Wuttisittikulkij",
                            "ce:indexed-name": "Wuttisittikulkij L."
                        }
                    }
                ],
                "citation-info": {
                    "author-keywords": {"author-keyword": [
                        {
                            "$": "Convolutional Encode-Decoder",
                            "@xml:lang": "eng",
                            "@original": "y"
                        },
                        {
                            "$": "Convolutional Recurrent Network",
                            "@xml:lang": "eng",
                            "@original": "y"
                        },
                        {
                            "$": "E2E speech processing",
                            "@xml:lang": "eng",
                            "@original": "y"
                        },
                        {
                            "$": "intelligibility",
                            "@xml:lang": "eng",
                            "@original": "y"
                        },
                        {
                            "$": "speech quality",
                            "@xml:lang": "eng",
                            "@original": "y"
                        }
                    ]},
                    "citation-type": {"@code": "ar"},
                    "citation-language": {
                        "@language": "English",
                        "@xml:lang": "eng"
                    },
                    "abstract-language": {
                        "@language": "English",
                        "@xml:lang": "eng"
                    }
                },
                "source": {
                    "website": {"ce:e-address": {
                        "$": "http://www.mdpi.com/journal/sensors",
                        "@type": "email"
                    }},
                    "translated-sourcetitle": {
                        "$": "Sensors",
                        "@xml:lang": "eng"
                    },
                    "volisspag": {"voliss": {
                        "@volume": "22",
                        "@issue": "20"
                    }},
                    "@type": "j",
                    "sourcetitle": "Sensors",
                    "publicationdate": {
                        "month": "10",
                        "year": "2022",
                        "date-text": "October-2 2022",
                        "day": "01"
                    },
                    "sourcetitle-abbrev": "Sensors",
                    "@country": "che",
                    "issn": {
                        "$": "14248220",
                        "@type": "print"
                    },
                    "publicationyear": {"@first": "2022"},
                    "publisher": {"publishername": "MDPI"},
                    "article-number": "7782",
                    "@srcid": "130124"
                },
                "enhancement": {"classificationgroup": {"classifications": [
                    {
                        "@type": "CPXCLASS",
                        "classification": [
                            {
                                "classification-code": "716.1",
                                "classification-description": "Information Theory and Signal Processing"
                            },
                            {
                                "classification-code": "723.2",
                                "classification-description": "Data Processing and Image Processing"
                            },
                            {
                                "classification-code": "751.5",
                                "classification-description": "Speech"
                            }
                        ]
                    },
                    {
                        "@type": "FLXCLASS",
                        "classification": {
                            "classification-code": "902",
                            "classification-description": "FLUIDEX; Related Topics"
                        }
                    },
                    {
                        "@type": "ASJC",
                        "classification": [
                            {"$": "1602"},
                            {"$": "1710"},
                            {"$": "3107"},
                            {"$": "1303"},
                            {"$": "3105"},
                            {"$": "2208"}
                        ]
                    },
                    {
                        "@type": "SUBJABBR",
                        "classification": [
                            {"$": "CHEM"},
                            {"$": "COMP"},
                            {"$": "PHYS"},
                            {"$": "BIOC"},
                            {"$": "ENGI"}
                        ]
                    }
                ]}},
                "grantlist": {
                    "@complete": "y",
                    "grant-text": {
                        "$": "This Research project is supported by the Second Century Fund (C2F), Chulalongkorn University. This Research is also funded by the Thailand Science Research and Innovation Fund Chulalongkorn University (SOC66210008).",
                        "@xml:lang": "eng"
                    },
                    "grant": {
                        "grant-acronym": "CU",
                        "grant-agency": {
                            "@iso-code": "tha",
                            "$": "Chulalongkorn University"
                        },
                        "grant-agency-id": "501100002873"
                    }
                }
            },
            "item-info": {
                "copyright": {
                    "$": "Copyright 2023 Elsevier B.V., All rights reserved.",
                    "@type": "Elsevier"
                },
                "dbcollection": [
                    {"$": "CPX"},
                    {"$": "REAXYSCAR"},
                    {"$": "SCOPUS"},
                    {"$": "Scopusbase"},
                    {"$": "MEDL"}
                ],
                "history": {"date-created": {
                    "@day": "25",
                    "@timestamp": "BST 07:09:01",
                    "@year": "2023",
                    "@month": "03"
                }},
                "itemidlist": {
                    "itemid": [
                        {
                            "$": "2023095813",
                            "@idtype": "PUI"
                        },
                        {
                            "$": "946940425",
                            "@idtype": "CAR-ID"
                        },
                        {
                            "$": "20231213791879",
                            "@idtype": "CPX"
                        },
                        {
                            "$": "20230775634",
                            "@idtype": "REAXYSCAR"
                        },
                        {
                            "$": "20231057351",
                            "@idtype": "SCOPUS"
                        },
                        {
                            "$": "20239002109384",
                            "@idtype": "TPA-ID"
                        },
                        {
                            "$": "85140933315",
                            "@idtype": "SCP"
                        },
                        {
                            "$": "85140933315",
                            "@idtype": "SGR"
                        },
                        {
                            "$": "639382641",
                            "@idtype": "PUIsecondary"
                        },
                        {
                            "$": "36298131",
                            "@idtype": "MEDL"
                        },
                        {
                            "$": "78324399",
                            "@idtype": "OSIN"
                        }
                    ],
                    "ce:doi": "10.3390/s22207782"
                }
            },
            "tail": {"bibliography": {
                "@refcount": "57",
                "reference": [
                    {
                        "ref-fulltext": "Gnanamanickam, J.; Natarajan, Y.; KR, S.P. A hybrid speech enhancement algorithm for voice assistance application. Sensors 2021, 21, 7025. [CrossRef] [PubMed]",
                        "@reference-instance-id": "OB2BibRecID-946940425-51765a6b605735808a248166584d5b75-1",
                        "@id": "1",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2021"},
                            "ref-title": {"ref-titletext": "A hybrid speech enhancement algorithm for voice assistance application"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85117486075",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {"@volume": "21"},
                                "pagerange": {"@first": "7025"}
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "J.",
                                    "@_fa": "true",
                                    "ce:surname": "Gnanamanickam",
                                    "ce:indexed-name": "Gnanamanickam J."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Natarajan",
                                    "ce:indexed-name": "Natarajan Y."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "S.P.",
                                    "@_fa": "true",
                                    "ce:surname": "Kr",
                                    "ce:indexed-name": "Kr S.P."
                                }
                            ]},
                            "ref-sourcetitle": "Sensors"
                        },
                        "ce:source-text": "Gnanamanickam, J.; Natarajan, Y.; KR, S.P. A hybrid speech enhancement algorithm for voice assistance application. Sensors 2021, 21, 7025. [CrossRef] [PubMed]"
                    },
                    {
                        "ref-fulltext": "Saleem, N.; Khattak, M.I.; Verdu, E. On Improvement of Speech Intelligibility and Quality: A Survey of Unsupervised Single Channel Speech Enhancement Algorithms. Int. J. Interact. Multimed. Artif. Intell. 2020, 6, 78\u201390.",
                        "@reference-instance-id": "OB2BibRecID-946940425-b82214d6a7b43e7993671ed7d5a3fdcc-2",
                        "@id": "2",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2020"},
                            "ref-title": {"ref-titletext": "On Improvement of Speech Intelligibility and Quality: A Survey of Unsupervised Single Channel Speech Enhancement Algorithms"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85111801818",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {"@volume": "6"},
                                "pagerange": {
                                    "@first": "78",
                                    "@last": "90"
                                }
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "N.",
                                    "@_fa": "true",
                                    "ce:surname": "Saleem",
                                    "ce:indexed-name": "Saleem N."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "M.I.",
                                    "@_fa": "true",
                                    "ce:surname": "Khattak",
                                    "ce:indexed-name": "Khattak M.I."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "E.",
                                    "@_fa": "true",
                                    "ce:surname": "Verdu",
                                    "ce:indexed-name": "Verdu E."
                                }
                            ]},
                            "ref-sourcetitle": "Int. J. Interact. Multimed. Artif. Intell."
                        },
                        "ce:source-text": "Saleem, N.; Khattak, M.I.; Verdu, E. On Improvement of Speech Intelligibility and Quality: A Survey of Unsupervised Single Channel Speech Enhancement Algorithms. Int. J. Interact. Multimed. Artif. Intell. 2020, 6, 78\u201390."
                    },
                    {
                        "ref-fulltext": "Sivapatham, S.; Kar, A.; Christensen, M.G. Gammatone Filter Bank-Deep Neural Network-based Monaural speech enhancement for unseen conditions. Appl. Acoust. 2022, 194, 108784. [CrossRef]",
                        "@reference-instance-id": "OB2BibRecID-946940425-06257fdc132b615ab729267b6c438538-3",
                        "@id": "3",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2022"},
                            "ref-title": {"ref-titletext": "Gammatone Filter Bank-Deep Neural Network-based Monaural speech enhancement for unseen conditions"},
                            "refd-itemidlist": {"itemid": [
                                {
                                    "$": "108784",
                                    "@idtype": "ARTNUM"
                                },
                                {
                                    "$": "85129334500",
                                    "@idtype": "SGR"
                                }
                            ]},
                            "ref-volisspag": {"voliss": {"@volume": "194"}},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Sivapatham",
                                    "ce:indexed-name": "Sivapatham S."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "A.",
                                    "@_fa": "true",
                                    "ce:surname": "Kar",
                                    "ce:indexed-name": "Kar A."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "M.G.",
                                    "@_fa": "true",
                                    "ce:surname": "Christensen",
                                    "ce:indexed-name": "Christensen M.G."
                                }
                            ]},
                            "ref-sourcetitle": "Appl. Acoust."
                        },
                        "ce:source-text": "Sivapatham, S.; Kar, A.; Christensen, M.G. Gammatone Filter Bank-Deep Neural Network-based Monaural speech enhancement for unseen conditions. Appl. Acoust. 2022, 194, 108784. [CrossRef]"
                    },
                    {
                        "ref-fulltext": "Das, N.; Chakraborty, S.; Chaki, J.; Padhy, N.; Dey, N. Fundamentals, present and future perspectives of speech enhancement. Int. J. Speech Technol. 2021, 24, 883\u2013901. [CrossRef]",
                        "@reference-instance-id": "OB2BibRecID-946940425-a4133efda11b35f0bf0b7017278b3e6e-4",
                        "@id": "4",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2021"},
                            "ref-title": {"ref-titletext": "Fundamentals, present and future perspectives of speech enhancement"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85078339365",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {"@volume": "24"},
                                "pagerange": {
                                    "@first": "883",
                                    "@last": "901"
                                }
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "N.",
                                    "@_fa": "true",
                                    "ce:surname": "Das",
                                    "ce:indexed-name": "Das N."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Chakraborty",
                                    "ce:indexed-name": "Chakraborty S."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "J.",
                                    "@_fa": "true",
                                    "ce:surname": "Chaki",
                                    "ce:indexed-name": "Chaki J."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "N.",
                                    "@_fa": "true",
                                    "ce:surname": "Padhy",
                                    "ce:indexed-name": "Padhy N."
                                },
                                {
                                    "@seq": "5",
                                    "ce:initials": "N.",
                                    "@_fa": "true",
                                    "ce:surname": "Dey",
                                    "ce:indexed-name": "Dey N."
                                }
                            ]},
                            "ref-sourcetitle": "Int. J. Speech Technol."
                        },
                        "ce:source-text": "Das, N.; Chakraborty, S.; Chaki, J.; Padhy, N.; Dey, N. Fundamentals, present and future perspectives of speech enhancement. Int. J. Speech Technol. 2021, 24, 883\u2013901. [CrossRef]"
                    },
                    {
                        "ref-fulltext": "Tan, K.; Wang, D. Learning complex spectral mapping with gated convolutional recurrent networks for monaural speech enhancement. IEEE/Acm Trans. Audio Speech Lang. Process. 2019, 28, 380\u2013390. [CrossRef]",
                        "@reference-instance-id": "OB2BibRecID-946940425-4d21509e25d489dc40442fa54c1894c9-5",
                        "@id": "5",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2019"},
                            "ref-title": {"ref-titletext": "Learning complex spectral mapping with gated convolutional recurrent networks for monaural speech enhancement"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85075670117",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {"@volume": "28"},
                                "pagerange": {
                                    "@first": "380",
                                    "@last": "390"
                                }
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "K.",
                                    "@_fa": "true",
                                    "ce:surname": "Tan",
                                    "ce:indexed-name": "Tan K."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "D.",
                                    "@_fa": "true",
                                    "ce:surname": "Wang",
                                    "ce:indexed-name": "Wang D."
                                }
                            ]},
                            "ref-sourcetitle": "Ieee/Acm Trans. Audio Speech Lang. Process."
                        },
                        "ce:source-text": "Tan, K.; Wang, D. Learning complex spectral mapping with gated convolutional recurrent networks for monaural speech enhancement. IEEE/Acm Trans. Audio Speech Lang. Process. 2019, 28, 380\u2013390. [CrossRef]"
                    },
                    {
                        "ref-fulltext": "Xu, Y.; Du, J.; Dai, L.R.; Lee, C.H. A regression approach to speech enhancement based on deep neural networks. IEEE/ACM Trans. Audio Speech Lang. Process. 2014, 23, 7\u201319. [CrossRef]",
                        "@reference-instance-id": "OB2BibRecID-946940425-7cad20435f608c96bdbc73b9d0c48b31-6",
                        "@id": "6",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2014"},
                            "ref-title": {"ref-titletext": "A regression approach to speech enhancement based on deep neural networks"},
                            "refd-itemidlist": {"itemid": {
                                "$": "84923289508",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {"@volume": "23"},
                                "pagerange": {
                                    "@first": "7",
                                    "@last": "19"
                                }
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Xu",
                                    "ce:indexed-name": "Xu Y."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "J.",
                                    "@_fa": "true",
                                    "ce:surname": "Du",
                                    "ce:indexed-name": "Du J."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "L.R.",
                                    "@_fa": "true",
                                    "ce:surname": "Dai",
                                    "ce:indexed-name": "Dai L.R."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "C.H.",
                                    "@_fa": "true",
                                    "ce:surname": "Lee",
                                    "ce:indexed-name": "Lee C.H."
                                }
                            ]},
                            "ref-sourcetitle": "IEEE/ACM Trans. Audio Speech Lang. Process."
                        },
                        "ce:source-text": "Xu, Y.; Du, J.; Dai, L.R.; Lee, C.H. A regression approach to speech enhancement based on deep neural networks. IEEE/ACM Trans. Audio Speech Lang. Process. 2014, 23, 7\u201319. [CrossRef]"
                    },
                    {
                        "ref-fulltext": "Xu, Y.; Du, J.; Dai, L.R.; Lee, C.H. An experimental study on speech enhancement based on deep neural networks. IEEE Signal Process. Lett. 2013, 21, 65\u201368. [CrossRef]",
                        "@reference-instance-id": "OB2BibRecID-946940425-765dfef5bdbc401909d88537be3c96f5-7",
                        "@id": "7",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2013"},
                            "ref-title": {"ref-titletext": "An experimental study on speech enhancement based on deep neural networks"},
                            "refd-itemidlist": {"itemid": {
                                "$": "84889257121",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {"@volume": "21"},
                                "pagerange": {
                                    "@first": "65",
                                    "@last": "68"
                                }
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Xu",
                                    "ce:indexed-name": "Xu Y."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "J.",
                                    "@_fa": "true",
                                    "ce:surname": "Du",
                                    "ce:indexed-name": "Du J."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "L.R.",
                                    "@_fa": "true",
                                    "ce:surname": "Dai",
                                    "ce:indexed-name": "Dai L.R."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "C.H.",
                                    "@_fa": "true",
                                    "ce:surname": "Lee",
                                    "ce:indexed-name": "Lee C.H."
                                }
                            ]},
                            "ref-sourcetitle": "IEEE Signal Process. Lett."
                        },
                        "ce:source-text": "Xu, Y.; Du, J.; Dai, L.R.; Lee, C.H. An experimental study on speech enhancement based on deep neural networks. IEEE Signal Process. Lett. 2013, 21, 65\u201368. [CrossRef]"
                    },
                    {
                        "ref-fulltext": "Strake, M.; Defraene, B.; Fluyt, K.; Tirry, W.; Fingscheidt, T. Speech enhancement by LSTM-based noise suppression followed by CNN-based speech restoration. Eurasip J. Adv. Signal Process. 2020, 2020, 49. [CrossRef]",
                        "@reference-instance-id": "OB2BibRecID-946940425-1aa8cb779987dc55cd5ad50d7cf7e305-8",
                        "@id": "8",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2020"},
                            "ref-title": {"ref-titletext": "Speech enhancement by LSTM-based noise suppression followed by CNN-based speech restoration"},
                            "refd-itemidlist": {"itemid": [
                                {
                                    "$": "49",
                                    "@idtype": "ARTNUM"
                                },
                                {
                                    "$": "85097379056",
                                    "@idtype": "SGR"
                                }
                            ]},
                            "ref-volisspag": {"voliss": {"@volume": "2020"}},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "M.",
                                    "@_fa": "true",
                                    "ce:surname": "Strake",
                                    "ce:indexed-name": "Strake M."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "B.",
                                    "@_fa": "true",
                                    "ce:surname": "Defraene",
                                    "ce:indexed-name": "Defraene B."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "K.",
                                    "@_fa": "true",
                                    "ce:surname": "Fluyt",
                                    "ce:indexed-name": "Fluyt K."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "W.",
                                    "@_fa": "true",
                                    "ce:surname": "Tirry",
                                    "ce:indexed-name": "Tirry W."
                                },
                                {
                                    "@seq": "5",
                                    "ce:initials": "T.",
                                    "@_fa": "true",
                                    "ce:surname": "Fingscheidt",
                                    "ce:indexed-name": "Fingscheidt T."
                                }
                            ]},
                            "ref-sourcetitle": "Eurasip J. Adv. Signal Process."
                        },
                        "ce:source-text": "Strake, M.; Defraene, B.; Fluyt, K.; Tirry, W.; Fingscheidt, T. Speech enhancement by LSTM-based noise suppression followed by CNN-based speech restoration. Eurasip J. Adv. Signal Process. 2020, 2020, 49. [CrossRef]"
                    },
                    {
                        "ref-fulltext": "Xia, B.; Bao, C. Wiener filtering based speech enhancement with weighted denoising auto-encoder and noise classification. Speech Commun. 2014, 60, 13\u201329. [CrossRef]",
                        "@reference-instance-id": "OB2BibRecID-946940425-c2ad8a665f75909137bbee9ba2caba00-9",
                        "@id": "9",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2014"},
                            "ref-title": {"ref-titletext": "Wiener filtering based speech enhancement with weighted denoising auto-encoder and noise classification"},
                            "refd-itemidlist": {"itemid": {
                                "$": "84896537574",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {"@volume": "60"},
                                "pagerange": {
                                    "@first": "13",
                                    "@last": "29"
                                }
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "B.",
                                    "@_fa": "true",
                                    "ce:surname": "Xia",
                                    "ce:indexed-name": "Xia B."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "C.",
                                    "@_fa": "true",
                                    "ce:surname": "Bao",
                                    "ce:indexed-name": "Bao C."
                                }
                            ]},
                            "ref-sourcetitle": "Speech Commun"
                        },
                        "ce:source-text": "Xia, B.; Bao, C. Wiener filtering based speech enhancement with weighted denoising auto-encoder and noise classification. Speech Commun. 2014, 60, 13\u201329. [CrossRef]"
                    },
                    {
                        "ref-fulltext": "Pandey, A.; Wang, D. A new framework for CNN-based speech enhancement in the time domain. IEEE/ACM Trans. Audio Speech Lang. Process. 2019, 27, 1179\u20131188. [CrossRef]",
                        "@reference-instance-id": "OB2BibRecID-946940425-bdb0b1ebd13937f93aabb9915d5770bb-10",
                        "@id": "10",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2019"},
                            "ref-title": {"ref-titletext": "A new framework for CNN-based speech enhancement in the time domain"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85065584304",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {"@volume": "27"},
                                "pagerange": {
                                    "@first": "1179",
                                    "@last": "1188"
                                }
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "A.",
                                    "@_fa": "true",
                                    "ce:surname": "Pandey",
                                    "ce:indexed-name": "Pandey A."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "D.",
                                    "@_fa": "true",
                                    "ce:surname": "Wang",
                                    "ce:indexed-name": "Wang D."
                                }
                            ]},
                            "ref-sourcetitle": "IEEE/ACM Trans. Audio Speech Lang. Process."
                        },
                        "ce:source-text": "Pandey, A.; Wang, D. A new framework for CNN-based speech enhancement in the time domain. IEEE/ACM Trans. Audio Speech Lang. Process. 2019, 27, 1179\u20131188. [CrossRef]"
                    },
                    {
                        "ref-fulltext": "Pandey, A.; Wang, D. Self-attending RNN for speech enhancement to improve cross-corpus generalization. Ieee/Acm Trans. Audio Speech Lang. Process. 2022, 30, 1374\u20131385. [CrossRef]",
                        "@reference-instance-id": "OB2BibRecID-946940425-1099b6d08067f865a32a3c5adfd584d3-11",
                        "@id": "11",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2022"},
                            "ref-title": {"ref-titletext": "Self-attending RNN for speech enhancement to improve cross-corpus generalization"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85127046679",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {"@volume": "30"},
                                "pagerange": {
                                    "@first": "1374",
                                    "@last": "1385"
                                }
                            },
                            "ref-text": "[CrossRef]",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "A.",
                                    "@_fa": "true",
                                    "ce:surname": "Pandey",
                                    "ce:indexed-name": "Pandey A."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "D.",
                                    "@_fa": "true",
                                    "ce:surname": "Wang",
                                    "ce:indexed-name": "Wang D."
                                }
                            ]},
                            "ref-sourcetitle": "Ieee/Acm Trans. Audio Speech Lang. Process."
                        },
                        "ce:source-text": "Pandey, A.; Wang, D. Self-attending RNN for speech enhancement to improve cross-corpus generalization. Ieee/Acm Trans. Audio Speech Lang. Process. 2022, 30, 1374\u20131385. [CrossRef]"
                    },
                    {
                        "ref-fulltext": "El-Moneim, S.A.; Nassar, M.A.; Dessouky, M.I.; Ismail, N.A.; El-Fishawy, A.S.; El-Samie, A.; Fathi, E. Text-independent speaker recognition using LSTM-RNN and speech enhancement. Multimed. Tools Appl. 2020, 79, 24013\u201324028. [CrossRef]",
                        "@reference-instance-id": "OB2BibRecID-946940425-580f46babb5c0e02ee64154ab2e4ca08-12",
                        "@id": "12",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2020"},
                            "ref-title": {"ref-titletext": "Text-independent speaker recognition using LSTM-RNN and speech enhancement"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85086880085",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {"@volume": "79"},
                                "pagerange": {
                                    "@first": "24013",
                                    "@last": "24028"
                                }
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "S.A.",
                                    "@_fa": "true",
                                    "ce:surname": "El-Moneim",
                                    "ce:indexed-name": "El-Moneim S.A."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "M.A.",
                                    "@_fa": "true",
                                    "ce:surname": "Nassar",
                                    "ce:indexed-name": "Nassar M.A."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "M.I.",
                                    "@_fa": "true",
                                    "ce:surname": "Dessouky",
                                    "ce:indexed-name": "Dessouky M.I."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "N.A.",
                                    "@_fa": "true",
                                    "ce:surname": "Ismail",
                                    "ce:indexed-name": "Ismail N.A."
                                },
                                {
                                    "@seq": "5",
                                    "ce:initials": "A.S.",
                                    "@_fa": "true",
                                    "ce:surname": "El-Fishawy",
                                    "ce:indexed-name": "El-Fishawy A.S."
                                },
                                {
                                    "@seq": "6",
                                    "ce:initials": "A.",
                                    "@_fa": "true",
                                    "ce:surname": "El-Samie",
                                    "ce:indexed-name": "El-Samie A."
                                },
                                {
                                    "@seq": "7",
                                    "ce:initials": "E.",
                                    "@_fa": "true",
                                    "ce:surname": "Fathi",
                                    "ce:indexed-name": "Fathi E."
                                }
                            ]},
                            "ref-sourcetitle": "Multimed. Tools Appl."
                        },
                        "ce:source-text": "El-Moneim, S.A.; Nassar, M.A.; Dessouky, M.I.; Ismail, N.A.; El-Fishawy, A.S.; El-Samie, A.; Fathi, E. Text-independent speaker recognition using LSTM-RNN and speech enhancement. Multimed. Tools Appl. 2020, 79, 24013\u201324028. [CrossRef]"
                    },
                    {
                        "ref-fulltext": "Saleem, N.; Khattak, M.I.; Al-Hasan, M.A.; Jan, A. Multi-objective long-short term memory recurrent neural networks for speech enhancement. J. Ambient. Intell. Humaniz. Comput. 2021, 12, 9037\u20139052. [CrossRef]",
                        "@reference-instance-id": "OB2BibRecID-946940425-b64d17b27a4995277322f2b6c2b70ec4-13",
                        "@id": "13",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2021"},
                            "ref-title": {"ref-titletext": "Multi-objective long-short term memory recurrent neural networks for speech enhancement"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85092589977",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {"@volume": "12"},
                                "pagerange": {
                                    "@first": "9037",
                                    "@last": "9052"
                                }
                            },
                            "ref-text": "[CrossRef]",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "N.",
                                    "@_fa": "true",
                                    "ce:surname": "Saleem",
                                    "ce:indexed-name": "Saleem N."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "M.I.",
                                    "@_fa": "true",
                                    "ce:surname": "Khattak",
                                    "ce:indexed-name": "Khattak M.I."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "M.A.",
                                    "@_fa": "true",
                                    "ce:surname": "Al-Hasan",
                                    "ce:indexed-name": "Al-Hasan M.A."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "A.",
                                    "@_fa": "true",
                                    "ce:surname": "Jan",
                                    "ce:indexed-name": "Jan A."
                                }
                            ]},
                            "ref-sourcetitle": "J. Ambient. Intell. Humaniz. Comput."
                        },
                        "ce:source-text": "Saleem, N.; Khattak, M.I.; Al-Hasan, M.A.; Jan, A. Multi-objective long-short term memory recurrent neural networks for speech enhancement. J. Ambient. Intell. Humaniz. Comput. 2021, 12, 9037\u20139052. [CrossRef]"
                    },
                    {
                        "ref-fulltext": "Pandey, A.; Wang, D. Learning Complex Spectral Mapping for Speech Enhancement with Improved Cross-Corpus Generalization. In Proceedings of the Interspeech, Shanghai, China, 25\u201329 October 2020; pp. 4511\u20134515. [CrossRef]",
                        "@reference-instance-id": "OB2BibRecID-946940425-f2986dd6b75fe4bcee6130da79619779-14",
                        "@id": "14",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2020"},
                            "ref-title": {"ref-titletext": "Learning Complex Spectral Mapping for Speech Enhancement with Improved Cross-Corpus Generalization"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85097842454",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "4511",
                                "@last": "4515"
                            }},
                            "ref-text": "25\u201329 October, [CrossRef]",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "A.",
                                    "@_fa": "true",
                                    "ce:surname": "Pandey",
                                    "ce:indexed-name": "Pandey A."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "D.",
                                    "@_fa": "true",
                                    "ce:surname": "Wang",
                                    "ce:indexed-name": "Wang D."
                                }
                            ]},
                            "ref-sourcetitle": "Proceedings of the Interspeech, Shanghai, China"
                        },
                        "ce:source-text": "Pandey, A.; Wang, D. Learning Complex Spectral Mapping for Speech Enhancement with Improved Cross-Corpus Generalization. In Proceedings of the Interspeech, Shanghai, China, 25\u201329 October 2020; pp. 4511\u20134515. [CrossRef]"
                    },
                    {
                        "ref-fulltext": "Li, A.; Yuan, M.; Zheng, C.; Li, X. Speech enhancement using progressive learning-based convolutional recurrent neural network. Appl. Acoust. 2020, 166, 107347. [CrossRef]",
                        "@reference-instance-id": "OB2BibRecID-946940425-684adb23f17da1864f992065f067ddf5-15",
                        "@id": "15",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2020"},
                            "ref-title": {"ref-titletext": "Speech enhancement using progressive learning-based convolutional recurrent neural network"},
                            "refd-itemidlist": {"itemid": [
                                {
                                    "$": "107347",
                                    "@idtype": "ARTNUM"
                                },
                                {
                                    "$": "85083030289",
                                    "@idtype": "SGR"
                                }
                            ]},
                            "ref-volisspag": {"voliss": {"@volume": "166"}},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "A.",
                                    "@_fa": "true",
                                    "ce:surname": "Li",
                                    "ce:indexed-name": "Li A."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "M.",
                                    "@_fa": "true",
                                    "ce:surname": "Yuan",
                                    "ce:indexed-name": "Yuan M."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "C.",
                                    "@_fa": "true",
                                    "ce:surname": "Zheng",
                                    "ce:indexed-name": "Zheng C."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "X.",
                                    "@_fa": "true",
                                    "ce:surname": "Li",
                                    "ce:indexed-name": "Li X."
                                }
                            ]},
                            "ref-sourcetitle": "Appl. Acoust."
                        },
                        "ce:source-text": "Li, A.; Yuan, M.; Zheng, C.; Li, X. Speech enhancement using progressive learning-based convolutional recurrent neural network. Appl. Acoust. 2020, 166, 107347. [CrossRef]"
                    },
                    {
                        "ref-fulltext": "Cui, X.; Chen, Z.; Yin, F. Speech enhancement based on simple recurrent unit network. Appl. Acoust. 2020, 157, 107019. [CrossRef]",
                        "@reference-instance-id": "OB2BibRecID-946940425-64c96027965f5048a094ad597fd6f144-16",
                        "@id": "16",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2020"},
                            "ref-title": {"ref-titletext": "Speech enhancement based on simple recurrent unit network"},
                            "refd-itemidlist": {"itemid": [
                                {
                                    "$": "107019",
                                    "@idtype": "ARTNUM"
                                },
                                {
                                    "$": "85072177645",
                                    "@idtype": "SGR"
                                }
                            ]},
                            "ref-volisspag": {"voliss": {"@volume": "157"}},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "X.",
                                    "@_fa": "true",
                                    "ce:surname": "Cui",
                                    "ce:indexed-name": "Cui X."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "Z.",
                                    "@_fa": "true",
                                    "ce:surname": "Chen",
                                    "ce:indexed-name": "Chen Z."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "F.",
                                    "@_fa": "true",
                                    "ce:surname": "Yin",
                                    "ce:indexed-name": "Yin F."
                                }
                            ]},
                            "ref-sourcetitle": "Appl. Acoust."
                        },
                        "ce:source-text": "Cui, X.; Chen, Z.; Yin, F. Speech enhancement based on simple recurrent unit network. Appl. Acoust. 2020, 157, 107019. [CrossRef]"
                    },
                    {
                        "ref-fulltext": "Lei, T.; Zhang, Y.; Wang, S.I.; Dai, H.; Artzi, Y. Simple recurrent units for highly parallelizable recurrence. arXiv 2017, arXiv:1709.02755.",
                        "@reference-instance-id": "OB2BibRecID-946940425-0496b5ea31d35fbf0d6bbaee7d0aa85f-17",
                        "@id": "17",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2017"},
                            "refd-itemidlist": {"itemid": [
                                {
                                    "$": "2017",
                                    "@idtype": "ARXIV"
                                },
                                {
                                    "$": "85063019197",
                                    "@idtype": "SGR"
                                }
                            ]},
                            "ref-text": "arXiv",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "T.",
                                    "@_fa": "true",
                                    "ce:surname": "Lei",
                                    "ce:indexed-name": "Lei T."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Zhang",
                                    "ce:indexed-name": "Zhang Y."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "S.I.",
                                    "@_fa": "true",
                                    "ce:surname": "Wang",
                                    "ce:indexed-name": "Wang S.I."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "H.",
                                    "@_fa": "true",
                                    "ce:surname": "Dai",
                                    "ce:indexed-name": "Dai H."
                                },
                                {
                                    "@seq": "5",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Artzi",
                                    "ce:indexed-name": "Artzi Y."
                                }
                            ]},
                            "ref-sourcetitle": "Simple Recurrent Units for Highly Parallelizable Recurrence"
                        },
                        "ce:source-text": "Lei, T.; Zhang, Y.; Wang, S.I.; Dai, H.; Artzi, Y. Simple recurrent units for highly parallelizable recurrence. arXiv 2017, arXiv:1709.02755."
                    },
                    {
                        "ref-fulltext": "Hasannezhad, M.; Yu, H.; Zhu, W.P.; Champagne, B. PACDNN: A phase-aware composite deep neural network for speech enhancement. Speech Commun. 2022, 136, 1\u201313. [CrossRef]",
                        "@reference-instance-id": "OB2BibRecID-946940425-7ff596a32c6661503cc054c003edb1d8-18",
                        "@id": "18",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2022"},
                            "ref-title": {"ref-titletext": "PACDNN: A phase-aware composite deep neural network for speech enhancement"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85150485927",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {"@volume": "1-13"},
                                "pagerange": {"@first": "136"}
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "M.",
                                    "@_fa": "true",
                                    "ce:surname": "Hasannezhad",
                                    "ce:indexed-name": "Hasannezhad M."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "H.",
                                    "@_fa": "true",
                                    "ce:surname": "Yu",
                                    "ce:indexed-name": "Yu H."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "W.P.",
                                    "@_fa": "true",
                                    "ce:surname": "Zhu",
                                    "ce:indexed-name": "Zhu W.P."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "B.",
                                    "@_fa": "true",
                                    "ce:surname": "Champagne",
                                    "ce:indexed-name": "Champagne B."
                                }
                            ]},
                            "ref-sourcetitle": "Speech Commun"
                        },
                        "ce:source-text": "Hasannezhad, M.; Yu, H.; Zhu, W.P.; Champagne, B. PACDNN: A phase-aware composite deep neural network for speech enhancement. Speech Commun. 2022, 136, 1\u201313. [CrossRef]"
                    },
                    {
                        "ref-fulltext": "Lv, S.; Hu, Y.; Zhang, S.; Xie, L. Dccrn+: Channel-wise subband dccrn with snr estimation for speech enhancement. arXiv 2021, arXiv:2106.08672.",
                        "@reference-instance-id": "OB2BibRecID-946940425-322b0470bc5168ed0f8af5c07f0c0ab9-19",
                        "@id": "19",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2021"},
                            "refd-itemidlist": {"itemid": [
                                {
                                    "$": "2021",
                                    "@idtype": "ARXIV"
                                },
                                {
                                    "$": "85117798696",
                                    "@idtype": "SGR"
                                }
                            ]},
                            "ref-text": "arXiv",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Lv",
                                    "ce:indexed-name": "Lv S."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Hu",
                                    "ce:indexed-name": "Hu Y."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Zhang",
                                    "ce:indexed-name": "Zhang S."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "L.",
                                    "@_fa": "true",
                                    "ce:surname": "Xie",
                                    "ce:indexed-name": "Xie L."
                                }
                            ]},
                            "ref-sourcetitle": "Dccrn+: Channel-Wise Subband Dccrn with Snr Estimation for Speech Enhancement"
                        },
                        "ce:source-text": "Lv, S.; Hu, Y.; Zhang, S.; Xie, L. Dccrn+: Channel-wise subband dccrn with snr estimation for speech enhancement. arXiv 2021, arXiv:2106.08672."
                    },
                    {
                        "ref-fulltext": "Takahashi, N.; Agrawal, P.; Goswami, N.; Mitsufuji, Y. PhaseNet: Discretized Phase Modeling with Deep Neural Networks for Audio Source Separation. In Proceedings of the Interspeech 2018, Hyderabad, India, 2\u20136 September 2018; pp. 2713\u20132717.",
                        "@reference-instance-id": "OB2BibRecID-946940425-1cb8914e94ea7fe6c1ae843c8cb28b2a-20",
                        "@id": "20",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2018"},
                            "ref-title": {"ref-titletext": "PhaseNet: Discretized Phase Modeling with Deep Neural Networks for Audio Source Separation"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85054989346",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "2713",
                                "@last": "2717"
                            }},
                            "ref-text": "2\u20136 September",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "N.",
                                    "@_fa": "true",
                                    "ce:surname": "Takahashi",
                                    "ce:indexed-name": "Takahashi N."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "P.",
                                    "@_fa": "true",
                                    "ce:surname": "Agrawal",
                                    "ce:indexed-name": "Agrawal P."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "N.",
                                    "@_fa": "true",
                                    "ce:surname": "Goswami",
                                    "ce:indexed-name": "Goswami N."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Mitsufuji",
                                    "ce:indexed-name": "Mitsufuji Y."
                                }
                            ]},
                            "ref-sourcetitle": "Proceedings of the Interspeech 2018, Hyderabad, India"
                        },
                        "ce:source-text": "Takahashi, N.; Agrawal, P.; Goswami, N.; Mitsufuji, Y. PhaseNet: Discretized Phase Modeling with Deep Neural Networks for Audio Source Separation. In Proceedings of the Interspeech 2018, Hyderabad, India, 2\u20136 September 2018; pp. 2713\u20132717."
                    },
                    {
                        "ref-fulltext": "Fu, S.W.; Tsao, Y.; Lu, X.; Kawai, H. Raw waveform-based speech enhancement by fully convolutional networks. In Proceedings of the Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC), Kuala Lumpur, Malaysia, 12\u201315 December 2017; pp. 6\u201312.",
                        "@reference-instance-id": "OB2BibRecID-946940425-99ae3f1de2e0027109960bd34d506205-21",
                        "@id": "21",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2017"},
                            "ref-title": {"ref-titletext": "Raw waveform-based speech enhancement by fully convolutional networks"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85047946680",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "6",
                                "@last": "12"
                            }},
                            "ref-text": "Malaysia, 12\u201315 December",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "S.W.",
                                    "@_fa": "true",
                                    "ce:surname": "Fu",
                                    "ce:indexed-name": "Fu S.W."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Tsao",
                                    "ce:indexed-name": "Tsao Y."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "X.",
                                    "@_fa": "true",
                                    "ce:surname": "Lu",
                                    "ce:indexed-name": "Lu X."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "H.",
                                    "@_fa": "true",
                                    "ce:surname": "Kawai",
                                    "ce:indexed-name": "Kawai H."
                                }
                            ]},
                            "ref-sourcetitle": "Proceedings of the Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC), Kuala Lumpur"
                        },
                        "ce:source-text": "Fu, S.W.; Tsao, Y.; Lu, X.; Kawai, H. Raw waveform-based speech enhancement by fully convolutional networks. In Proceedings of the Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC), Kuala Lumpur, Malaysia, 12\u201315 December 2017; pp. 6\u201312."
                    },
                    {
                        "ref-fulltext": "Li, J.; Zhang, H.; Zhang, X.; Li, C. Single channel speech enhancement using temporal convolutional recurrent neural networks. In Proceedings of the Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC), Lanzhou, China, 18\u201321 November 2019; pp. 896\u2013900.",
                        "@reference-instance-id": "OB2BibRecID-946940425-d99f282d36245559caaf67e53d382613-22",
                        "@id": "22",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2019"},
                            "ref-title": {"ref-titletext": "Single channel speech enhancement using temporal convolutional recurrent neural networks"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85082392395",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "896",
                                "@last": "900"
                            }},
                            "ref-text": "Lanzhou, China, 18\u201321 November",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "J.",
                                    "@_fa": "true",
                                    "ce:surname": "Li",
                                    "ce:indexed-name": "Li J."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "H.",
                                    "@_fa": "true",
                                    "ce:surname": "Zhang",
                                    "ce:indexed-name": "Zhang H."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "X.",
                                    "@_fa": "true",
                                    "ce:surname": "Zhang",
                                    "ce:indexed-name": "Zhang X."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "C.",
                                    "@_fa": "true",
                                    "ce:surname": "Li",
                                    "ce:indexed-name": "Li C."
                                }
                            ]},
                            "ref-sourcetitle": "Proceedings of the Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)"
                        },
                        "ce:source-text": "Li, J.; Zhang, H.; Zhang, X.; Li, C. Single channel speech enhancement using temporal convolutional recurrent neural networks. In Proceedings of the Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC), Lanzhou, China, 18\u201321 November 2019; pp. 896\u2013900."
                    },
                    {
                        "ref-fulltext": "Fu, S.W.; Wang, T.W.; Tsao, Y.; Lu, X.; Kawai, H. End-to-end waveform utterance enhancement for direct evaluation metrics optimization by fully convolutional neural networks. IEEE/ACM Trans. Audio Speech Lang. Process. 2018, 26, 1570\u20131584. [CrossRef]",
                        "@reference-instance-id": "OB2BibRecID-946940425-80852fb142bae6d6e969ae635aae7d1e-23",
                        "@id": "23",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2018"},
                            "ref-title": {"ref-titletext": "End-to-end waveform utterance enhancement for direct evaluation metrics optimization by fully convolutional neural networks"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85045194883",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {"@volume": "26"},
                                "pagerange": {
                                    "@first": "1570",
                                    "@last": "1584"
                                }
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "S.W.",
                                    "@_fa": "true",
                                    "ce:surname": "Fu",
                                    "ce:indexed-name": "Fu S.W."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "T.W.",
                                    "@_fa": "true",
                                    "ce:surname": "Wang",
                                    "ce:indexed-name": "Wang T.W."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Tsao",
                                    "ce:indexed-name": "Tsao Y."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "X.",
                                    "@_fa": "true",
                                    "ce:surname": "Lu",
                                    "ce:indexed-name": "Lu X."
                                },
                                {
                                    "@seq": "5",
                                    "ce:initials": "H.",
                                    "@_fa": "true",
                                    "ce:surname": "Kawai",
                                    "ce:indexed-name": "Kawai H."
                                }
                            ]},
                            "ref-sourcetitle": "IEEE/ACM Trans. Audio Speech Lang. Process."
                        },
                        "ce:source-text": "Fu, S.W.; Wang, T.W.; Tsao, Y.; Lu, X.; Kawai, H. End-to-end waveform utterance enhancement for direct evaluation metrics optimization by fully convolutional neural networks. IEEE/ACM Trans. Audio Speech Lang. Process. 2018, 26, 1570\u20131584. [CrossRef]"
                    },
                    {
                        "ref-fulltext": "Sainath, T.; Weiss, R.J.; Wilson, K.; Senior, A.W.; Vinyals, O. Learning the speech front-end with raw waveform CLDNNs. Available online: https://storage.googleapis.com/pub-tools-public-publication-data/pdf/43960.pdf (accessed on 1 October 2022).",
                        "@reference-instance-id": "OB2BibRecID-946940425-a2ad93e1c69d7fe2dc981354b3f4daa6-24",
                        "@id": "24",
                        "ref-info": {
                            "ref-website": {"ce:e-address": {
                                "$": "https://storage.googleapis.com/pub-tools-public-publication-data/pdf/43960.pdf",
                                "@type": "email"
                            }},
                            "refd-itemidlist": {"itemid": {
                                "$": "85035084740",
                                "@idtype": "SGR"
                            }},
                            "ref-text": "accessed on 1 October 2022",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "T.",
                                    "@_fa": "true",
                                    "ce:surname": "Sainath",
                                    "ce:indexed-name": "Sainath T."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "R.J.",
                                    "@_fa": "true",
                                    "ce:surname": "Weiss",
                                    "ce:indexed-name": "Weiss R.J."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "K.",
                                    "@_fa": "true",
                                    "ce:surname": "Wilson",
                                    "ce:indexed-name": "Wilson K."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "A.W.",
                                    "@_fa": "true",
                                    "ce:surname": "Senior",
                                    "ce:indexed-name": "Senior A.W."
                                },
                                {
                                    "@seq": "5",
                                    "ce:initials": "O.",
                                    "@_fa": "true",
                                    "ce:surname": "Vinyals",
                                    "ce:indexed-name": "Vinyals O."
                                }
                            ]},
                            "ref-sourcetitle": "Learning the Speech Front-End with Raw Waveform Cldnns"
                        },
                        "ce:source-text": "Sainath, T.; Weiss, R.J.; Wilson, K.; Senior, A.W.; Vinyals, O. Learning the speech front-end with raw waveform CLDNNs. Available online: https://storage.googleapis.com/pub-tools-public-publication-data/pdf/43960.pdf (accessed on 1 October 2022)."
                    },
                    {
                        "ref-fulltext": "Giri, R.; Isik, U.; Krishnaswamy, A. Attention wave-u-net for speech enhancement. In Proceedings of the IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA), New Paltz, NY, USA, 20\u201323 October 2019.",
                        "@reference-instance-id": "OB2BibRecID-946940425-dbd180aa55f92db7f411dfd5989fe792-25",
                        "@id": "25",
                        "ref-info": {
                            "ref-title": {"ref-titletext": "Attention wave-u-net for speech enhancement"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85078071114",
                                "@idtype": "SGR"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "R.",
                                    "@_fa": "true",
                                    "ce:surname": "Giri",
                                    "ce:indexed-name": "Giri R."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "U.",
                                    "@_fa": "true",
                                    "ce:surname": "Isik",
                                    "ce:indexed-name": "Isik U."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "A.",
                                    "@_fa": "true",
                                    "ce:surname": "Krishnaswamy",
                                    "ce:indexed-name": "Krishnaswamy A."
                                }
                            ]},
                            "ref-sourcetitle": "Proceedings of the IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA), New Paltz, NY, USA, 20\u201323 October 2019"
                        },
                        "ce:source-text": "Giri, R.; Isik, U.; Krishnaswamy, A. Attention wave-u-net for speech enhancement. In Proceedings of the IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA), New Paltz, NY, USA, 20\u201323 October 2019."
                    },
                    {
                        "ref-fulltext": "Rethage, D.; Pons, J.; Serra, X. A wavenet for speech denoising. In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Florence, Italy, 4\u20139 May 2014; pp. 5069\u20135073.",
                        "@reference-instance-id": "OB2BibRecID-946940425-2db74018ebab93bc1f462f37a6bbe651-26",
                        "@id": "26",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2014"},
                            "ref-title": {"ref-titletext": "A wavenet for speech denoising"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85054257597",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "5069",
                                "@last": "5073"
                            }},
                            "ref-text": "Florence, Italy, 4\u20139 May",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "D.",
                                    "@_fa": "true",
                                    "ce:surname": "Rethage",
                                    "ce:indexed-name": "Rethage D."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "J.",
                                    "@_fa": "true",
                                    "ce:surname": "Pons",
                                    "ce:indexed-name": "Pons J."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "X.",
                                    "@_fa": "true",
                                    "ce:surname": "Serra",
                                    "ce:indexed-name": "Serra X."
                                }
                            ]},
                            "ref-sourcetitle": "Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"
                        },
                        "ce:source-text": "Rethage, D.; Pons, J.; Serra, X. A wavenet for speech denoising. In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Florence, Italy, 4\u20139 May 2014; pp. 5069\u20135073."
                    },
                    {
                        "ref-fulltext": "Pascual, S.; Serra, J.; Bonafonte, A. Time-domain speech enhancement using generative adversarial networks. Speech Commun. 2019, 114, 10\u201321. [CrossRef]",
                        "@reference-instance-id": "OB2BibRecID-946940425-8032f96fc528273712b66a234054464f-27",
                        "@id": "27",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2019"},
                            "ref-title": {"ref-titletext": "Time-domain speech enhancement using generative adversarial networks"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85072579630",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {"@volume": "114"},
                                "pagerange": {
                                    "@first": "10",
                                    "@last": "21"
                                }
                            },
                            "ref-text": "[CrossRef]",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Pascual",
                                    "ce:indexed-name": "Pascual S."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "J.",
                                    "@_fa": "true",
                                    "ce:surname": "Serra",
                                    "ce:indexed-name": "Serra J."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "A.",
                                    "@_fa": "true",
                                    "ce:surname": "Bonafonte",
                                    "ce:indexed-name": "Bonafonte A."
                                }
                            ]},
                            "ref-sourcetitle": "Speech Commun"
                        },
                        "ce:source-text": "Pascual, S.; Serra, J.; Bonafonte, A. Time-domain speech enhancement using generative adversarial networks. Speech Commun. 2019, 114, 10\u201321. [CrossRef]"
                    },
                    {
                        "ref-fulltext": "Yuan, W. A time\u2013frequency smoothing neural network for speech enhancement. Speech Commun. 2020, 124, 75\u201384. [CrossRef]",
                        "@reference-instance-id": "OB2BibRecID-946940425-69cf800f17cdf3dbd8e4f0583125368e-28",
                        "@id": "28",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2020"},
                            "ref-title": {"ref-titletext": "A time\u2013frequency smoothing neural network for speech enhancement"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85091244716",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {"@volume": "124"},
                                "pagerange": {
                                    "@first": "75",
                                    "@last": "84"
                                }
                            },
                            "ref-text": "[CrossRef]",
                            "ref-authors": {"author": [{
                                "@seq": "1",
                                "ce:initials": "W.",
                                "@_fa": "true",
                                "ce:surname": "Yuan",
                                "ce:indexed-name": "Yuan W."
                            }]},
                            "ref-sourcetitle": "Speech Commun"
                        },
                        "ce:source-text": "Yuan, W. A time\u2013frequency smoothing neural network for speech enhancement. Speech Commun. 2020, 124, 75\u201384. [CrossRef]"
                    },
                    {
                        "ref-fulltext": "Saleem, N.; Khattak, M.I. Multi-scale decomposition based supervised single channel deep speech enhancement. Appl. Soft Comput. 2020, 95, 106666. [CrossRef]",
                        "@reference-instance-id": "OB2BibRecID-946940425-79e70e31350d4bd833b967937fe08f04-29",
                        "@id": "29",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2020"},
                            "ref-title": {"ref-titletext": "Multi-scale decomposition based supervised single channel deep speech enhancement"},
                            "refd-itemidlist": {"itemid": [
                                {
                                    "$": "106666",
                                    "@idtype": "ARTNUM"
                                },
                                {
                                    "$": "85090300476",
                                    "@idtype": "SGR"
                                }
                            ]},
                            "ref-volisspag": {"voliss": {"@volume": "95"}},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "N.",
                                    "@_fa": "true",
                                    "ce:surname": "Saleem",
                                    "ce:indexed-name": "Saleem N."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "M.I.",
                                    "@_fa": "true",
                                    "ce:surname": "Khattak",
                                    "ce:indexed-name": "Khattak M.I."
                                }
                            ]},
                            "ref-sourcetitle": "Appl. Soft Comput."
                        },
                        "ce:source-text": "Saleem, N.; Khattak, M.I. Multi-scale decomposition based supervised single channel deep speech enhancement. Appl. Soft Comput. 2020, 95, 106666. [CrossRef]"
                    },
                    {
                        "ref-fulltext": "Saleem, N.; Khattak, M.I.; Al-Hasan, M.; Qazi, A.B. On learning spectral masking for single channel speech enhancement using feedforward and recurrent neural networks. IEEE Access 2020, 8, 160581\u2013160595. [CrossRef]",
                        "@reference-instance-id": "OB2BibRecID-946940425-5e74af20da5043b2733c8efb074b4602-30",
                        "@id": "30",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2020"},
                            "ref-title": {"ref-titletext": "On learning spectral masking for single channel speech enhancement using feedforward and recurrent neural networks"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85091299031",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {"@volume": "8"},
                                "pagerange": {
                                    "@first": "160581",
                                    "@last": "160595"
                                }
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "N.",
                                    "@_fa": "true",
                                    "ce:surname": "Saleem",
                                    "ce:indexed-name": "Saleem N."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "M.I.",
                                    "@_fa": "true",
                                    "ce:surname": "Khattak",
                                    "ce:indexed-name": "Khattak M.I."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "M.",
                                    "@_fa": "true",
                                    "ce:surname": "Al-Hasan",
                                    "ce:indexed-name": "Al-Hasan M."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "A.B.",
                                    "@_fa": "true",
                                    "ce:surname": "Qazi",
                                    "ce:indexed-name": "Qazi A.B."
                                }
                            ]},
                            "ref-sourcetitle": "IEEE Access"
                        },
                        "ce:source-text": "Saleem, N.; Khattak, M.I.; Al-Hasan, M.; Qazi, A.B. On learning spectral masking for single channel speech enhancement using feedforward and recurrent neural networks. IEEE Access 2020, 8, 160581\u2013160595. [CrossRef]"
                    },
                    {
                        "ref-fulltext": "Abdulbaqi, J.; Gu, Y.; Chen, S.; Marsic, I. Residual recurrent neural network for speech enhancement. In Proceedings of the ICASSP 2020\u20132020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Barcelona, Spain, 4\u20138 May 2020; pp. 6659\u20136663.",
                        "@reference-instance-id": "OB2BibRecID-946940425-d03499bf638e1b56890a6fe4b0ba243b-31",
                        "@id": "31",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2020"},
                            "ref-title": {"ref-titletext": "Residual recurrent neural network for speech enhancement"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85089244257",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "6659",
                                "@last": "6663"
                            }},
                            "ref-text": "Barcelona, Spain, 4\u20138 May",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "J.",
                                    "@_fa": "true",
                                    "ce:surname": "Abdulbaqi",
                                    "ce:indexed-name": "Abdulbaqi J."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Gu",
                                    "ce:indexed-name": "Gu Y."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Chen",
                                    "ce:indexed-name": "Chen S."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "I.",
                                    "@_fa": "true",
                                    "ce:surname": "Marsic",
                                    "ce:indexed-name": "Marsic I."
                                }
                            ]},
                            "ref-sourcetitle": "Proceedings of the ICASSP 2020\u20132020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"
                        },
                        "ce:source-text": "Abdulbaqi, J.; Gu, Y.; Chen, S.; Marsic, I. Residual recurrent neural network for speech enhancement. In Proceedings of the ICASSP 2020\u20132020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Barcelona, Spain, 4\u20138 May 2020; pp. 6659\u20136663."
                    },
                    {
                        "ref-fulltext": "Hsieh, T.A.; Wang, H.M.; Lu, X.; Tsao, Y. Wavecrn: An efficient convolutional recurrent neural network for end-to-end speech enhancement. IEEE Signal Process. Lett. 2020, 27, 2149\u20132153. [CrossRef]",
                        "@reference-instance-id": "OB2BibRecID-946940425-7d802376d93aab7c9078d44ebf41410b-32",
                        "@id": "32",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2020"},
                            "ref-title": {"ref-titletext": "Wavecrn: An efficient convolutional recurrent neural network for end-to-end speech enhancement"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85097411759",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {"@volume": "27"},
                                "pagerange": {
                                    "@first": "2149",
                                    "@last": "2153"
                                }
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "T.A.",
                                    "@_fa": "true",
                                    "ce:surname": "Hsieh",
                                    "ce:indexed-name": "Hsieh T.A."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "H.M.",
                                    "@_fa": "true",
                                    "ce:surname": "Wang",
                                    "ce:indexed-name": "Wang H.M."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "X.",
                                    "@_fa": "true",
                                    "ce:surname": "Lu",
                                    "ce:indexed-name": "Lu X."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Tsao",
                                    "ce:indexed-name": "Tsao Y."
                                }
                            ]},
                            "ref-sourcetitle": "IEEE Signal Process. Lett."
                        },
                        "ce:source-text": "Hsieh, T.A.; Wang, H.M.; Lu, X.; Tsao, Y. Wavecrn: An efficient convolutional recurrent neural network for end-to-end speech enhancement. IEEE Signal Process. Lett. 2020, 27, 2149\u20132153. [CrossRef]"
                    },
                    {
                        "ref-fulltext": "Stoller, D.; Ewert, S.; Dixon, S. Wave-u-net: A multi-scale neural network for end-to-end audio source separation. arXiv 2018, arXiv:1806.03185.",
                        "@reference-instance-id": "OB2BibRecID-946940425-55b56b82f60d709063596af74c7567be-33",
                        "@id": "33",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2018"},
                            "refd-itemidlist": {"itemid": [
                                {
                                    "$": "2018",
                                    "@idtype": "ARXIV"
                                },
                                {
                                    "$": "85065607517",
                                    "@idtype": "SGR"
                                }
                            ]},
                            "ref-text": "arXiv",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "D.",
                                    "@_fa": "true",
                                    "ce:surname": "Stoller",
                                    "ce:indexed-name": "Stoller D."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Ewert",
                                    "ce:indexed-name": "Ewert S."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Dixon",
                                    "ce:indexed-name": "Dixon S."
                                }
                            ]},
                            "ref-sourcetitle": "Wave-U-Net: A Multi-Scale Neural Network for End-To-End Audio Source Separation"
                        },
                        "ce:source-text": "Stoller, D.; Ewert, S.; Dixon, S. Wave-u-net: A multi-scale neural network for end-to-end audio source separation. arXiv 2018, arXiv:1806.03185."
                    },
                    {
                        "ref-fulltext": "Pandey, A.; Wang, D. TCNN: Temporal convolutional neural network for real-time speech enhancement in the time domain. In Proceedings of the ICASSP 2019\u20142019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Brighton, UK, 12\u201317 May 2019; pp. 6875\u20136879.",
                        "@reference-instance-id": "OB2BibRecID-946940425-9303795376a8b687684186d6816186a2-34",
                        "@id": "34",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2019"},
                            "ref-title": {"ref-titletext": "TCNN: Temporal convolutional neural network for real-time speech enhancement in the time domain"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85068982096",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "6875",
                                "@last": "6879"
                            }},
                            "ref-text": "UK, 12\u201317 May",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "A.",
                                    "@_fa": "true",
                                    "ce:surname": "Pandey",
                                    "ce:indexed-name": "Pandey A."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "D.",
                                    "@_fa": "true",
                                    "ce:surname": "Wang",
                                    "ce:indexed-name": "Wang D."
                                }
                            ]},
                            "ref-sourcetitle": "Proceedings of the ICASSP 2019\u20142019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Brighton"
                        },
                        "ce:source-text": "Pandey, A.; Wang, D. TCNN: Temporal convolutional neural network for real-time speech enhancement in the time domain. In Proceedings of the ICASSP 2019\u20142019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Brighton, UK, 12\u201317 May 2019; pp. 6875\u20136879."
                    },
                    {
                        "ref-fulltext": "Hu, Y.; Liu, Y.; Lv, S.; Xing, M.; Zhang, S.; Fu, Y.; Xie, L. DCCRN: Deep complex convolution recurrent network for phase-aware speech enhancement. arXiv 2020, arXiv:2008.00264.",
                        "@reference-instance-id": "OB2BibRecID-946940425-403ebf43b9ff2d1ce8490ca0d30cbd0a-35",
                        "@id": "35",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2020"},
                            "refd-itemidlist": {"itemid": [
                                {
                                    "$": "2020",
                                    "@idtype": "ARXIV"
                                },
                                {
                                    "$": "85098107628",
                                    "@idtype": "SGR"
                                }
                            ]},
                            "ref-text": "arXiv",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Hu",
                                    "ce:indexed-name": "Hu Y."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Liu",
                                    "ce:indexed-name": "Liu Y."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Lv",
                                    "ce:indexed-name": "Lv S."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "M.",
                                    "@_fa": "true",
                                    "ce:surname": "Xing",
                                    "ce:indexed-name": "Xing M."
                                },
                                {
                                    "@seq": "5",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Zhang",
                                    "ce:indexed-name": "Zhang S."
                                },
                                {
                                    "@seq": "6",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Fu",
                                    "ce:indexed-name": "Fu Y."
                                },
                                {
                                    "@seq": "7",
                                    "ce:initials": "L.",
                                    "@_fa": "true",
                                    "ce:surname": "Xie",
                                    "ce:indexed-name": "Xie L."
                                }
                            ]},
                            "ref-sourcetitle": "DCCRN: Deep Complex Convolution Recurrent Network for Phase-Aware Speech Enhancement"
                        },
                        "ce:source-text": "Hu, Y.; Liu, Y.; Lv, S.; Xing, M.; Zhang, S.; Fu, Y.; Xie, L. DCCRN: Deep complex convolution recurrent network for phase-aware speech enhancement. arXiv 2020, arXiv:2008.00264."
                    },
                    {
                        "ref-fulltext": "Kolbæk, M.; Tan, Z.H.; Jensen, S.H.; Jensen, J. On loss functions for supervised monaural time-domain speech enhancement. IEEE/ACM Trans. Audio Speech Lang. Process. 2020, 28, 825\u2013838. [CrossRef]",
                        "@reference-instance-id": "OB2BibRecID-946940425-5ddcad28a92d0590e7fd2481dec326f3-36",
                        "@id": "36",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2020"},
                            "ref-title": {"ref-titletext": "On loss functions for supervised monaural time-domain speech enhancement"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85080954873",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {"@volume": "28"},
                                "pagerange": {
                                    "@first": "825",
                                    "@last": "838"
                                }
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "M.",
                                    "@_fa": "true",
                                    "ce:surname": "Kolbæk",
                                    "ce:indexed-name": "Kolbaek M."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "Z.H.",
                                    "@_fa": "true",
                                    "ce:surname": "Tan",
                                    "ce:indexed-name": "Tan Z.H."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "S.H.",
                                    "@_fa": "true",
                                    "ce:surname": "Jensen",
                                    "ce:indexed-name": "Jensen S.H."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "J.",
                                    "@_fa": "true",
                                    "ce:surname": "Jensen",
                                    "ce:indexed-name": "Jensen J."
                                }
                            ]},
                            "ref-sourcetitle": "IEEE/ACM Trans. Audio Speech Lang. Process."
                        },
                        "ce:source-text": "Kolbæk, M.; Tan, Z.H.; Jensen, S.H.; Jensen, J. On loss functions for supervised monaural time-domain speech enhancement. IEEE/ACM Trans. Audio Speech Lang. Process. 2020, 28, 825\u2013838. [CrossRef]"
                    },
                    {
                        "ref-fulltext": "Xiao, F.; Guan, J.; Kong, Q.; Wang, W. Time-domain speech enhancement with generative adversarial learning. arXiv 2021, arXiv:2103.16149.",
                        "@reference-instance-id": "OB2BibRecID-946940425-29bb5456b8726704b5c18b51586e94eb-37",
                        "@id": "37",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2021"},
                            "ref-title": {"ref-titletext": "Time-domain speech enhancement with generative adversarial learning"},
                            "refd-itemidlist": {"itemid": [
                                {
                                    "$": "2021",
                                    "@idtype": "ARXIV"
                                },
                                {
                                    "$": "85150485845",
                                    "@idtype": "SGR"
                                }
                            ]},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "F.",
                                    "@_fa": "true",
                                    "ce:surname": "Xiao",
                                    "ce:indexed-name": "Xiao F."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "J.",
                                    "@_fa": "true",
                                    "ce:surname": "Guan",
                                    "ce:indexed-name": "Guan J."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "Q.",
                                    "@_fa": "true",
                                    "ce:surname": "Kong",
                                    "ce:indexed-name": "Kong Q."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "W.",
                                    "@_fa": "true",
                                    "ce:surname": "Wang",
                                    "ce:indexed-name": "Wang W."
                                }
                            ]},
                            "ref-sourcetitle": "Arxiv"
                        },
                        "ce:source-text": "Xiao, F.; Guan, J.; Kong, Q.; Wang, W. Time-domain speech enhancement with generative adversarial learning. arXiv 2021, arXiv:2103.16149."
                    },
                    {
                        "ref-fulltext": "Panayotov, V.; Chen, G.; Povey, D.; Khudanpur, S. Librispeech: An asr corpus based on public domain audio books. In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), South Brisbane, Australia, 9\u201324 April 2015; pp. 5206\u20135210.",
                        "@reference-instance-id": "OB2BibRecID-946940425-64e0f0ea5609d3341d3e288ffcba8cbf-38",
                        "@id": "38",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2015"},
                            "ref-title": {"ref-titletext": "Librispeech: An asr corpus based on public domain audio books"},
                            "refd-itemidlist": {"itemid": {
                                "$": "84946015916",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "5206",
                                "@last": "5210"
                            }},
                            "ref-text": "South Brisbane, Australia, 9\u201324 April",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "V.",
                                    "@_fa": "true",
                                    "ce:surname": "Panayotov",
                                    "ce:indexed-name": "Panayotov V."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "G.",
                                    "@_fa": "true",
                                    "ce:surname": "Chen",
                                    "ce:indexed-name": "Chen G."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "D.",
                                    "@_fa": "true",
                                    "ce:surname": "Povey",
                                    "ce:indexed-name": "Povey D."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Khudanpur",
                                    "ce:indexed-name": "Khudanpur S."
                                }
                            ]},
                            "ref-sourcetitle": "Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"
                        },
                        "ce:source-text": "Panayotov, V.; Chen, G.; Povey, D.; Khudanpur, S. Librispeech: An asr corpus based on public domain audio books. In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), South Brisbane, Australia, 9\u201324 April 2015; pp. 5206\u20135210."
                    },
                    {
                        "ref-fulltext": "Zue, V.; Seneff, S.; Glass, J. Speech database development at MIT: TIMIT and beyond. Speech Commun. 1990, 9, 351\u2013356. [CrossRef]",
                        "@reference-instance-id": "OB2BibRecID-946940425-155513999315d1feb576e1766c7186a3-39",
                        "@id": "39",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "1990"},
                            "ref-title": {"ref-titletext": "Speech database development at MIT: TIMIT and beyond"},
                            "refd-itemidlist": {"itemid": {
                                "$": "0025477640",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {"@volume": "9"},
                                "pagerange": {
                                    "@first": "351",
                                    "@last": "356"
                                }
                            },
                            "ref-text": "[CrossRef]",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "V.",
                                    "@_fa": "true",
                                    "ce:surname": "Zue",
                                    "ce:indexed-name": "Zue V."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Seneff",
                                    "ce:indexed-name": "Seneff S."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "J.",
                                    "@_fa": "true",
                                    "ce:surname": "Glass",
                                    "ce:indexed-name": "Glass J."
                                }
                            ]},
                            "ref-sourcetitle": "Speech Commun"
                        },
                        "ce:source-text": "Zue, V.; Seneff, S.; Glass, J. Speech database development at MIT: TIMIT and beyond. Speech Commun. 1990, 9, 351\u2013356. [CrossRef]"
                    },
                    {
                        "ref-fulltext": "Veaux, C.; Yamagishi, J.; King, S. The voice bank corpus: Design, collection and data analysis of a large regional accent speech database. In Proceedings of the International Conference Oriental COCOSDA held jointly with 2013 Conference on Asian Spoken Language Research and Evaluation (O-COCOSDA/CASLRE), Gurgaon, India, 25\u201327 November 2013; pp. 1\u20134.",
                        "@reference-instance-id": "OB2BibRecID-946940425-87a006e49e9bcb9528fbfe07a191454b-40",
                        "@id": "40",
                        "ref-info": {
                            "ref-title": {"ref-titletext": "The voice bank corpus: Design, collection and data analysis of a large regional accent speech database"},
                            "refd-itemidlist": {"itemid": {
                                "$": "84894152556",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "1",
                                "@last": "4"
                            }},
                            "ref-text": "India, 25\u201327 November 2013",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "C.",
                                    "@_fa": "true",
                                    "ce:surname": "Veaux",
                                    "ce:indexed-name": "Veaux C."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "J.",
                                    "@_fa": "true",
                                    "ce:surname": "Yamagishi",
                                    "ce:indexed-name": "Yamagishi J."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "King",
                                    "ce:indexed-name": "King S."
                                }
                            ]},
                            "ref-sourcetitle": "Proceedings of the International Conference Oriental COCOSDA Held Jointly with 2013 Conference on Asian Spoken Language Research and Evaluation (O-COCOSDA/CASLRE), Gurgaon"
                        },
                        "ce:source-text": "Veaux, C.; Yamagishi, J.; King, S. The voice bank corpus: Design, collection and data analysis of a large regional accent speech database. In Proceedings of the International Conference Oriental COCOSDA held jointly with 2013 Conference on Asian Spoken Language Research and Evaluation (O-COCOSDA/CASLRE), Gurgaon, India, 25\u201327 November 2013; pp. 1\u20134."
                    },
                    {
                        "ref-fulltext": "Sun, S.; Yeh, C.F.; Ostendorf, M.; Hwang, M.Y.; Xie, L. Training augmentation with adversarial examples for robust speech recognition. arXiv 2018, arXiv:1806.02782.",
                        "@reference-instance-id": "OB2BibRecID-946940425-2e1d559ad3eb25c36c97d7e998e204d4-41",
                        "@id": "41",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2018"},
                            "refd-itemidlist": {"itemid": [
                                {
                                    "$": "2018",
                                    "@idtype": "ARXIV"
                                },
                                {
                                    "$": "85054984962",
                                    "@idtype": "SGR"
                                }
                            ]},
                            "ref-text": "arXiv",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Sun",
                                    "ce:indexed-name": "Sun S."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "C.F.",
                                    "@_fa": "true",
                                    "ce:surname": "Yeh",
                                    "ce:indexed-name": "Yeh C.F."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "M.",
                                    "@_fa": "true",
                                    "ce:surname": "Ostendorf",
                                    "ce:indexed-name": "Ostendorf M."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "M.Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Hwang",
                                    "ce:indexed-name": "Hwang M.Y."
                                },
                                {
                                    "@seq": "5",
                                    "ce:initials": "L.",
                                    "@_fa": "true",
                                    "ce:surname": "Xie",
                                    "ce:indexed-name": "Xie L."
                                }
                            ]},
                            "ref-sourcetitle": "Training Augmentation with Adversarial Examples for Robust Speech Recognition"
                        },
                        "ce:source-text": "Sun, S.; Yeh, C.F.; Ostendorf, M.; Hwang, M.Y.; Xie, L. Training augmentation with adversarial examples for robust speech recognition. arXiv 2018, arXiv:1806.02782."
                    },
                    {
                        "ref-fulltext": "Varga, A.; Steeneken, H.J. Assessment for automatic speech recognition: II. NOISEX-92: A database and an experiment to study the effect of additive noise on speech recognition systems. Speech Commun. 1993, 12, 247\u2013251. [CrossRef]",
                        "@reference-instance-id": "OB2BibRecID-946940425-c6ff977d22ffd31ea023a79bf984ce6b-42",
                        "@id": "42",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "1993"},
                            "ref-title": {"ref-titletext": "Assessment for automatic speech recognition: II. NOISEX-92: A database and an experiment to study the effect of additive noise on speech recognition systems"},
                            "refd-itemidlist": {"itemid": {
                                "$": "0027623210",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {"@volume": "12"},
                                "pagerange": {
                                    "@first": "247",
                                    "@last": "251"
                                }
                            },
                            "ref-text": "[CrossRef]",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "A.",
                                    "@_fa": "true",
                                    "ce:surname": "Varga",
                                    "ce:indexed-name": "Varga A."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "H.J.",
                                    "@_fa": "true",
                                    "ce:surname": "Steeneken",
                                    "ce:indexed-name": "Steeneken H.J."
                                }
                            ]},
                            "ref-sourcetitle": "Speech Commun"
                        },
                        "ce:source-text": "Varga, A.; Steeneken, H.J. Assessment for automatic speech recognition: II. NOISEX-92: A database and an experiment to study the effect of additive noise on speech recognition systems. Speech Commun. 1993, 12, 247\u2013251. [CrossRef]"
                    },
                    {
                        "ref-fulltext": "Thiemann, J.; Ito, N.; Vincent, E. The diverse environments multi-channel acoustic noise database (demand): A database of multichannel environmental noise recordings. Proc. Mtgs. Acoust. 2013, 19, 035081",
                        "@reference-instance-id": "OB2BibRecID-946940425-0b5c6e670494f4559299b1ae4353cd22-43",
                        "@id": "43",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2013"},
                            "ref-title": {"ref-titletext": "The diverse environments multi-channel acoustic noise database (demand): A database of multichannel environmental noise recordings"},
                            "refd-itemidlist": {"itemid": [
                                {
                                    "$": "035081",
                                    "@idtype": "ARTNUM"
                                },
                                {
                                    "$": "84878977625",
                                    "@idtype": "SGR"
                                }
                            ]},
                            "ref-volisspag": {"voliss": {"@volume": "19"}},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "J.",
                                    "@_fa": "true",
                                    "ce:surname": "Thiemann",
                                    "ce:indexed-name": "Thiemann J."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "N.",
                                    "@_fa": "true",
                                    "ce:surname": "Ito",
                                    "ce:indexed-name": "Ito N."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "E.",
                                    "@_fa": "true",
                                    "ce:surname": "Vincent",
                                    "ce:indexed-name": "Vincent E."
                                }
                            ]},
                            "ref-sourcetitle": "Proc. Mtgs. Acoust."
                        },
                        "ce:source-text": "Thiemann, J.; Ito, N.; Vincent, E. The diverse environments multi-channel acoustic noise database (demand): A database of multichannel environmental noise recordings. Proc. Mtgs. Acoust. 2013, 19, 035081"
                    },
                    {
                        "ref-fulltext": "Rix, A.W.; Beerends, J.G.; Hollier, M.P.; Hekstra, A.P. Perceptual evaluation of speech quality (PESQ)-a new method for speech quality assessment of telephone networks and codecs. In Proceedings of the International Conference on Acoustics, Speech and Signal Processing, Toronto, ON, Canada, 6\u201311 June 2021; pp. 749\u2013752.",
                        "@reference-instance-id": "OB2BibRecID-946940425-f168fab529ce448fc2c32d4fbe89a71d-44",
                        "@id": "44",
                        "ref-info": {
                            "ref-title": {"ref-titletext": "Perceptual evaluation of speech quality (PESQ)-a new method for speech quality assessment of telephone networks and codecs"},
                            "refd-itemidlist": {"itemid": {
                                "$": "0034847662",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "749",
                                "@last": "752"
                            }},
                            "ref-text": "6\u201311 June 2021",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "A.W.",
                                    "@_fa": "true",
                                    "ce:surname": "Rix",
                                    "ce:indexed-name": "Rix A.W."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "J.G.",
                                    "@_fa": "true",
                                    "ce:surname": "Beerends",
                                    "ce:indexed-name": "Beerends J.G."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "M.P.",
                                    "@_fa": "true",
                                    "ce:surname": "Hollier",
                                    "ce:indexed-name": "Hollier M.P."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "A.P.",
                                    "@_fa": "true",
                                    "ce:surname": "Hekstra",
                                    "ce:indexed-name": "Hekstra A.P."
                                }
                            ]},
                            "ref-sourcetitle": "In Proceedings of the International Conference on Acoustics, Speech and Signal Processing, Toronto, ON, Canada"
                        },
                        "ce:source-text": "Rix, A.W.; Beerends, J.G.; Hollier, M.P.; Hekstra, A.P. Perceptual evaluation of speech quality (PESQ)-a new method for speech quality assessment of telephone networks and codecs. In Proceedings of the International Conference on Acoustics, Speech and Signal Processing, Toronto, ON, Canada, 6\u201311 June 2021; pp. 749\u2013752."
                    },
                    {
                        "ref-fulltext": "Taal, C.H.; Hendriks, R.C.; Heusdens, R.; Jensen, J. A short-time objective intelligibility measure for time-frequency weighted noisy speech. In Proceedings of the International Conference on Acoustics, Speech and Signal Processing, Dallas, TX, USA, 14\u201319 March 2010; pp. 4214\u20134217.",
                        "@reference-instance-id": "OB2BibRecID-946940425-7bd6482a9d0202f6be5f85f2e2b38ad5-45",
                        "@id": "45",
                        "ref-info": {
                            "ref-title": {"ref-titletext": "A short-time objective intelligibility measure for time-frequency weighted noisy speech"},
                            "refd-itemidlist": {"itemid": {
                                "$": "78049365405",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "4214",
                                "@last": "4217"
                            }},
                            "ref-text": "TX, USA, 14\u201319 March 2010",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "C.H.",
                                    "@_fa": "true",
                                    "ce:surname": "Taal",
                                    "ce:indexed-name": "Taal C.H."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "R.C.",
                                    "@_fa": "true",
                                    "ce:surname": "Hendriks",
                                    "ce:indexed-name": "Hendriks R.C."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "R.",
                                    "@_fa": "true",
                                    "ce:surname": "Heusdens",
                                    "ce:indexed-name": "Heusdens R."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "J.",
                                    "@_fa": "true",
                                    "ce:surname": "Jensen",
                                    "ce:indexed-name": "Jensen J."
                                }
                            ]},
                            "ref-sourcetitle": "In Proceedings of the International Conference on Acoustics, Speech and Signal Processing, Dallas"
                        },
                        "ce:source-text": "Taal, C.H.; Hendriks, R.C.; Heusdens, R.; Jensen, J. A short-time objective intelligibility measure for time-frequency weighted noisy speech. In Proceedings of the International Conference on Acoustics, Speech and Signal Processing, Dallas, TX, USA, 14\u201319 March 2010; pp. 4214\u20134217."
                    },
                    {
                        "ref-fulltext": "Hu, Y.; Loizou, P.C. Evaluation of objective quality measures for speech enhancement. IEEE Trans. Audio Speech Lang. Process. 2007, 16, 229\u2013238. [CrossRef]",
                        "@reference-instance-id": "OB2BibRecID-946940425-60c2cae672ad120a7b3e94734574e8fb-46",
                        "@id": "46",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2007"},
                            "ref-title": {"ref-titletext": "Evaluation of objective quality measures for speech enhancement"},
                            "refd-itemidlist": {"itemid": {
                                "$": "44149106061",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {"@volume": "16"},
                                "pagerange": {
                                    "@first": "229",
                                    "@last": "238"
                                }
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Hu",
                                    "ce:indexed-name": "Hu Y."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "P.C.",
                                    "@_fa": "true",
                                    "ce:surname": "Loizou",
                                    "ce:indexed-name": "Loizou P.C."
                                }
                            ]},
                            "ref-sourcetitle": "IEEE Trans. Audio Speech Lang. Process."
                        },
                        "ce:source-text": "Hu, Y.; Loizou, P.C. Evaluation of objective quality measures for speech enhancement. IEEE Trans. Audio Speech Lang. Process. 2007, 16, 229\u2013238. [CrossRef]"
                    },
                    {
                        "ref-fulltext": "Chen, J.; Wang, D. Long short-term memory for speaker generalization in supervised speech separation. J. Acoust. Soc. Am. 2017, 141, 4705\u20134714. [CrossRef]",
                        "@reference-instance-id": "OB2BibRecID-946940425-81754720b200475c0fbd2c48053d2ac4-47",
                        "@id": "47",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2017"},
                            "ref-title": {"ref-titletext": "Long short-term memory for speaker generalization in supervised speech separation"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85021269901",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {"@volume": "141"},
                                "pagerange": {
                                    "@first": "4705",
                                    "@last": "4714"
                                }
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "J.",
                                    "@_fa": "true",
                                    "ce:surname": "Chen",
                                    "ce:indexed-name": "Chen J."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "D.",
                                    "@_fa": "true",
                                    "ce:surname": "Wang",
                                    "ce:indexed-name": "Wang D."
                                }
                            ]},
                            "ref-sourcetitle": "J. Acoust. Soc. Am."
                        },
                        "ce:source-text": "Chen, J.; Wang, D. Long short-term memory for speaker generalization in supervised speech separation. J. Acoust. Soc. Am. 2017, 141, 4705\u20134714. [CrossRef]"
                    },
                    {
                        "ref-fulltext": "Zheng, N.; Zhang, X.L. Phase-aware speech enhancement based on deep neural networks. IEEE/ACM Trans. Audio Speech Lang. Process. 2018, 27, 63\u201376. [CrossRef]",
                        "@reference-instance-id": "OB2BibRecID-946940425-90119759eb184710fa1e2e34d667696d-48",
                        "@id": "48",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2018"},
                            "ref-title": {"ref-titletext": "Phase-aware speech enhancement based on deep neural networks"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85053353390",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {"@volume": "27"},
                                "pagerange": {
                                    "@first": "63",
                                    "@last": "76"
                                }
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "N.",
                                    "@_fa": "true",
                                    "ce:surname": "Zheng",
                                    "ce:indexed-name": "Zheng N."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "X.L.",
                                    "@_fa": "true",
                                    "ce:surname": "Zhang",
                                    "ce:indexed-name": "Zhang X.L."
                                }
                            ]},
                            "ref-sourcetitle": "IEEE/ACM Trans. Audio Speech Lang. Process."
                        },
                        "ce:source-text": "Zheng, N.; Zhang, X.L. Phase-aware speech enhancement based on deep neural networks. IEEE/ACM Trans. Audio Speech Lang. Process. 2018, 27, 63\u201376. [CrossRef]"
                    },
                    {
                        "ref-fulltext": "Kounovsky, T.; Malek, J. Single channel speech enhancement using convolutional neural network. In Proceedings of the International Workshop of Electronics, Control, Measurement, Signals and their Application to Mechatronics (ECMSM), Donostia-San Sebastian, Spain, 24\u201326 May 2017; pp. 1\u20135.",
                        "@reference-instance-id": "OB2BibRecID-946940425-aa3a14594fee9fdd655f04471e502d40-49",
                        "@id": "49",
                        "ref-info": {
                            "ref-title": {"ref-titletext": "Single channel speech enhancement using convolutional neural network"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85022047759",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "1",
                                "@last": "5"
                            }},
                            "ref-text": "24\u201326 May 2017",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "T.",
                                    "@_fa": "true",
                                    "ce:surname": "Kounovsky",
                                    "ce:indexed-name": "Kounovsky T."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "J.",
                                    "@_fa": "true",
                                    "ce:surname": "Malek",
                                    "ce:indexed-name": "Malek J."
                                }
                            ]},
                            "ref-sourcetitle": "In Proceedings of the International Workshop of Electronics, Control, Measurement, Signals and Their Application to Mechatronics (ECMSM), Donostia-San Sebastian, Spain"
                        },
                        "ce:source-text": "Kounovsky, T.; Malek, J. Single channel speech enhancement using convolutional neural network. In Proceedings of the International Workshop of Electronics, Control, Measurement, Signals and their Application to Mechatronics (ECMSM), Donostia-San Sebastian, Spain, 24\u201326 May 2017; pp. 1\u20135."
                    },
                    {
                        "ref-fulltext": "Shah, N.; Patil, H.A.; Soni, M.H. Time-frequency mask-based speech enhancement using convolutional generative adversarial network. In Proceedings of the Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC), Honolulu, HI, USA, 12\u201315 November 2018; pp. 1246\u20131251.",
                        "@reference-instance-id": "OB2BibRecID-946940425-f67d802aa210efd532517be54ccafc52-50",
                        "@id": "50",
                        "ref-info": {
                            "ref-title": {"ref-titletext": "Time-frequency mask-based speech enhancement using convolutional generative adversarial network"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85063518737",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "1246",
                                "@last": "1251"
                            }},
                            "ref-text": "12\u201315 November 2018",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "N.",
                                    "@_fa": "true",
                                    "ce:surname": "Shah",
                                    "ce:indexed-name": "Shah N."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "H.A.",
                                    "@_fa": "true",
                                    "ce:surname": "Patil",
                                    "ce:indexed-name": "Patil H.A."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "M.H.",
                                    "@_fa": "true",
                                    "ce:surname": "Soni",
                                    "ce:indexed-name": "Soni M.H."
                                }
                            ]},
                            "ref-sourcetitle": "In Proceedings of the Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC), Honolulu, HI, USA"
                        },
                        "ce:source-text": "Shah, N.; Patil, H.A.; Soni, M.H. Time-frequency mask-based speech enhancement using convolutional generative adversarial network. In Proceedings of the Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC), Honolulu, HI, USA, 12\u201315 November 2018; pp. 1246\u20131251."
                    },
                    {
                        "ref-fulltext": "Hasannezhad, M.; Ouyang, Z.; Zhu, W.P.; Champagne, B. An integrated CNN-GRU framework for complex ratio mask estimation in speech enhancement. In Proceedings of the Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC), Auckland, New Zealand, 7\u201310 December 2020; pp. 764\u2013768.",
                        "@reference-instance-id": "OB2BibRecID-946940425-66f0e576ec3dc3d566ba8b298499bd3a-51",
                        "@id": "51",
                        "ref-info": {
                            "ref-title": {"ref-titletext": "An integrated CNN-GRU framework for complex ratio mask estimation in speech enhancement"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85100934042",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "764",
                                "@last": "768"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "M.",
                                    "@_fa": "true",
                                    "ce:surname": "Hasannezhad",
                                    "ce:indexed-name": "Hasannezhad M."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "Z.",
                                    "@_fa": "true",
                                    "ce:surname": "Ouyang",
                                    "ce:indexed-name": "Ouyang Z."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "W.P.",
                                    "@_fa": "true",
                                    "ce:surname": "Zhu",
                                    "ce:indexed-name": "Zhu W.P."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "B.",
                                    "@_fa": "true",
                                    "ce:surname": "Champagne",
                                    "ce:indexed-name": "Champagne B."
                                }
                            ]},
                            "ref-sourcetitle": "In Proceedings of the Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC), Auckland, New Zealand, 7\u201310 December 2020"
                        },
                        "ce:source-text": "Hasannezhad, M.; Ouyang, Z.; Zhu, W.P.; Champagne, B. An integrated CNN-GRU framework for complex ratio mask estimation in speech enhancement. In Proceedings of the Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC), Auckland, New Zealand, 7\u201310 December 2020; pp. 764\u2013768."
                    },
                    {
                        "ref-fulltext": "Ouyang, Z.; Yu, H.; Zhu, W.P.; Champagne, B. A fully convolutional neural network for complex spectrogram processing in speech enhancement. In Proceedings of the ICASSP 2019\u20142019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Brighton, UK, 12\u201317 May 2019; pp. 5756\u20135760.",
                        "@reference-instance-id": "OB2BibRecID-946940425-9956e4ecaee9dff0d6e5c2ca5c5fbe76-52",
                        "@id": "52",
                        "ref-info": {
                            "ref-title": {"ref-titletext": "A fully convolutional neural network for complex spectrogram processing in speech enhancement"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85068965890",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "5756",
                                "@last": "5760"
                            }},
                            "ref-text": "12\u201317 May 2019",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "Z.",
                                    "@_fa": "true",
                                    "ce:surname": "Ouyang",
                                    "ce:indexed-name": "Ouyang Z."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "H.",
                                    "@_fa": "true",
                                    "ce:surname": "Yu",
                                    "ce:indexed-name": "Yu H."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "W.P.",
                                    "@_fa": "true",
                                    "ce:surname": "Zhu",
                                    "ce:indexed-name": "Zhu W.P."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "B.",
                                    "@_fa": "true",
                                    "ce:surname": "Champagne",
                                    "ce:indexed-name": "Champagne B."
                                }
                            ]},
                            "ref-sourcetitle": "In Proceedings of the ICASSP 2019\u20142019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Brighton, UK"
                        },
                        "ce:source-text": "Ouyang, Z.; Yu, H.; Zhu, W.P.; Champagne, B. A fully convolutional neural network for complex spectrogram processing in speech enhancement. In Proceedings of the ICASSP 2019\u20142019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Brighton, UK, 12\u201317 May 2019; pp. 5756\u20135760."
                    },
                    {
                        "ref-fulltext": "Sun, P.; Qin, J. Low-rank and sparsity analysis applied to speech enhancement via online estimated dictionary. IEEE Signal Process. Lett. 2016, 23, 1862\u20131866. [CrossRef]",
                        "@reference-instance-id": "OB2BibRecID-946940425-f888234c38611643fa8ae327c414b9b8-53",
                        "@id": "53",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2016"},
                            "ref-title": {"ref-titletext": "Low-rank and sparsity analysis applied to speech enhancement via online estimated dictionary"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85012936699",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {"@volume": "23"},
                                "pagerange": {
                                    "@first": "1862",
                                    "@last": "1866"
                                }
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "P.",
                                    "@_fa": "true",
                                    "ce:surname": "Sun",
                                    "ce:indexed-name": "Sun P."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "J.",
                                    "@_fa": "true",
                                    "ce:surname": "Qin",
                                    "ce:indexed-name": "Qin J."
                                }
                            ]},
                            "ref-sourcetitle": "IEEE Signal Process. Lett."
                        },
                        "ce:source-text": "Sun, P.; Qin, J. Low-rank and sparsity analysis applied to speech enhancement via online estimated dictionary. IEEE Signal Process. Lett. 2016, 23, 1862\u20131866. [CrossRef]"
                    },
                    {
                        "ref-fulltext": "Shi, W.; Zhang, X.; Zou, X.; Han, W.; Min, G. Auditory mask estimation by RPCA for monaural speech enhancement. In Proceedings of the IEEE/ACIS 16th International Conference on Computer and Information Science (ICIS), Wuhan, China, 24\u201326 May 2017; pp. 179\u2013184.",
                        "@reference-instance-id": "OB2BibRecID-946940425-eceaada70bb791f83d65252e7d1ac787-54",
                        "@id": "54",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2017"},
                            "ref-title": {"ref-titletext": "Auditory mask estimation by RPCA for monaural speech enhancement"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85030637713",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "179",
                                "@last": "184"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "W.",
                                    "@_fa": "true",
                                    "ce:surname": "Shi",
                                    "ce:indexed-name": "Shi W."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "X.",
                                    "@_fa": "true",
                                    "ce:surname": "Zhang",
                                    "ce:indexed-name": "Zhang X."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "X.",
                                    "@_fa": "true",
                                    "ce:surname": "Zou",
                                    "ce:indexed-name": "Zou X."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "W.",
                                    "@_fa": "true",
                                    "ce:surname": "Han",
                                    "ce:indexed-name": "Han W."
                                },
                                {
                                    "@seq": "5",
                                    "ce:initials": "G.",
                                    "@_fa": "true",
                                    "ce:surname": "Min",
                                    "ce:indexed-name": "Min G."
                                }
                            ]},
                            "ref-sourcetitle": "In Proceedings of the IEEE/ACIS 16Th International Conference on Computer and Information Science (ICIS), Wuhan, China, 24\u201326 May"
                        },
                        "ce:source-text": "Shi, W.; Zhang, X.; Zou, X.; Han, W.; Min, G. Auditory mask estimation by RPCA for monaural speech enhancement. In Proceedings of the IEEE/ACIS 16th International Conference on Computer and Information Science (ICIS), Wuhan, China, 24\u201326 May 2017; pp. 179\u2013184."
                    },
                    {
                        "ref-fulltext": "Ephraim, Y.; Malah, D. Speech enhancement using a minimum-mean square error short-time spectral amplitude estimator. IEEE Trans. Acoust. Speech Signal Process. 1984, 32, 1109\u20131121. [CrossRef]",
                        "@reference-instance-id": "OB2BibRecID-946940425-c418d20289ac9983dcf99f54782e74dd-55",
                        "@id": "55",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "1984"},
                            "ref-title": {"ref-titletext": "Speech enhancement using a minimum-mean square error short-time spectral amplitude estimator"},
                            "refd-itemidlist": {"itemid": {
                                "$": "0021645331",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {"@volume": "32"},
                                "pagerange": {
                                    "@first": "1109",
                                    "@last": "1121"
                                }
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Ephraim",
                                    "ce:indexed-name": "Ephraim Y."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "D.",
                                    "@_fa": "true",
                                    "ce:surname": "Malah",
                                    "ce:indexed-name": "Malah D."
                                }
                            ]},
                            "ref-sourcetitle": "IEEE Trans. Acoust. Speech Signal Process."
                        },
                        "ce:source-text": "Ephraim, Y.; Malah, D. Speech enhancement using a minimum-mean square error short-time spectral amplitude estimator. IEEE Trans. Acoust. Speech Signal Process. 1984, 32, 1109\u20131121. [CrossRef]"
                    },
                    {
                        "ref-fulltext": "Këpuska, V.; Bohouta, G. Comparing speech recognition systems (Microsoft API, Google API and CMU Sphinx). Int. J. Eng. Res. Appl. 2017, 7, 20\u201324. [CrossRef]",
                        "@reference-instance-id": "OB2BibRecID-946940425-dcdb6ed33455c6cea41ee6698be0b02f-56",
                        "@id": "56",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2017"},
                            "ref-title": {"ref-titletext": "Comparing speech recognition systems (Microsoft API, Google API and CMU Sphinx)"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85028881327",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {"@volume": "7"},
                                "pagerange": {
                                    "@first": "20",
                                    "@last": "24"
                                }
                            },
                            "ref-text": "[CrossRef]",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "V.",
                                    "@_fa": "true",
                                    "ce:surname": "Këpuska",
                                    "ce:indexed-name": "Kepuska V."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "G.",
                                    "@_fa": "true",
                                    "ce:surname": "Bohouta",
                                    "ce:indexed-name": "Bohouta G."
                                }
                            ]},
                            "ref-sourcetitle": "Int. J. Eng. Res. Appl."
                        },
                        "ce:source-text": "Këpuska, V.; Bohouta, G. Comparing speech recognition systems (Microsoft API, Google API and CMU Sphinx). Int. J. Eng. Res. Appl. 2017, 7, 20\u201324. [CrossRef]"
                    },
                    {
                        "ref-fulltext": "Saleem, N.; Khattak, M.I.; Perez, E.V. Spectral phase estimation based on deep neural networks for single channel speech enhancement. J. Commun. Technol. Electron. 2019, 64, 1372\u20131382. [CrossRef]",
                        "@reference-instance-id": "OB2BibRecID-946940425-d2b754b9f765f6e94a196c1c859c7282-57",
                        "@id": "57",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2019"},
                            "ref-title": {"ref-titletext": "Spectral phase estimation based on deep neural networks for single channel speech enhancement"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85081155328",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {"@volume": "64"},
                                "pagerange": {
                                    "@first": "1372",
                                    "@last": "1382"
                                }
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "N.",
                                    "@_fa": "true",
                                    "ce:surname": "Saleem",
                                    "ce:indexed-name": "Saleem N."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "M.I.",
                                    "@_fa": "true",
                                    "ce:surname": "Khattak",
                                    "ce:indexed-name": "Khattak M.I."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "E.V.",
                                    "@_fa": "true",
                                    "ce:surname": "Perez",
                                    "ce:indexed-name": "Perez E.V."
                                }
                            ]},
                            "ref-sourcetitle": "J. Commun. Technol. Electron."
                        },
                        "ce:source-text": "Saleem, N.; Khattak, M.I.; Perez, E.V. Spectral phase estimation based on deep neural networks for single channel speech enhancement. J. Commun. Technol. Electron. 2019, 64, 1372\u20131382. [CrossRef]"
                    }
                ]
            }}
        }
    },
    "affiliation": [
        {
            "affiliation-city": "Hefei",
            "@id": "60133708",
            "affilname": "National Engineering Laboratory for Speech and Language Information Processing",
            "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60133708",
            "affiliation-country": "China"
        },
        {
            "affiliation-city": "Peshawar",
            "@id": "60106555",
            "affilname": "Islamia College, Peshawar",
            "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60106555",
            "affiliation-country": "Pakistan"
        },
        {
            "affiliation-city": "Bangkok",
            "@id": "60028190",
            "affilname": "Chulalongkorn University",
            "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60028190",
            "affiliation-country": "Thailand"
        }
    ],
    "coredata": {
        "srctype": "j",
        "eid": "2-s2.0-85140933315",
        "dc:description": "Because of their simple design structure, end-to-end deep learning (E2E-DL) models have gained a lot of attention for speech enhancement. A number of DL models have achieved excellent results in eliminating the background noise and enhancing the quality as well as the intelligibility of noisy speech. Designing resource-efficient and compact models during real-time processing is still a key challenge. In order to enhance the accomplishment of E2E models, the sequential and local characteristics of speech signal should be efficiently taken into consideration while modeling. In this paper, we present resource-efficient and compact neural models for end-to-end noise-robust waveform-based speech enhancement. Combining the Convolutional Encode-Decoder (CED) and Recurrent Neural Networks (RNNs) in the Convolutional Recurrent Network (CRN) framework, we have aimed at different speech enhancement systems. Different noise types and speakers are used to train and test the proposed models. With LibriSpeech and the DEMAND dataset, the experiments show that the proposed models lead to improved quality and intelligibility with fewer trainable parameters, notably reduced model complexity, and inference time than existing recurrent and convolutional models. The quality and intelligibility are improved by 31.61% and 17.18% over the noisy speech. We further performed cross corpus analysis to demonstrate the generalization of the proposed E2E SE models across different speech datasets.",
        "pubmed-id": "36298131",
        "prism:coverDate": "2022-10-01",
        "prism:aggregationType": "Journal",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85140933315",
        "dc:creator": {"author": [{
            "ce:given-name": "Rizwan",
            "preferred-name": {
                "ce:given-name": "Rizwan",
                "ce:initials": "R.",
                "ce:surname": "Ullah",
                "ce:indexed-name": "Ullah R."
            },
            "@seq": "1",
            "ce:initials": "R.",
            "@_fa": "true",
            "affiliation": {
                "@id": "60028190",
                "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60028190"
            },
            "ce:surname": "Ullah",
            "@auid": "58256620500",
            "author-url": "https://api.elsevier.com/content/author/author_id/58256620500",
            "ce:indexed-name": "Ullah R."
        }]},
        "link": [
            {
                "@_fa": "true",
                "@rel": "self",
                "@href": "https://api.elsevier.com/content/abstract/scopus_id/85140933315"
            },
            {
                "@_fa": "true",
                "@rel": "scopus",
                "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85140933315&origin=inward"
            },
            {
                "@_fa": "true",
                "@rel": "scopus-citedby",
                "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85140933315&origin=inward"
            }
        ],
        "source-id": "130124",
        "citedby-count": "3",
        "prism:volume": "22",
        "subtype": "ar",
        "dc:title": "End-to-End Deep Convolutional Recurrent Models for Noise Robust Waveform Speech Enhancement",
        "openaccess": "1",
        "prism:issn": "14248220",
        "publishercopyright": "© 2022 by the authors.",
        "article-number": "7782",
        "prism:issueIdentifier": "20",
        "subtypeDescription": "Article",
        "prism:publicationName": "Sensors",
        "openaccessFlag": "true",
        "prism:doi": "10.3390/s22207782",
        "dc:identifier": "SCOPUS_ID:85140933315",
        "dc:publisher": "MDPI"
    },
    "idxterms": {"mainterm": [
        {
            "$": "Convolutional encode-decoder",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "Convolutional recurrent network",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "E2E speech processing",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "End to end",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "Intelligibility",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "Noise robust",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "Recurrent models",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "Recurrent networks",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "Speech quality",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "Waveforms",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "Neural Networks, Computer",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "Noise",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "Speech",
            "@weight": "a",
            "@candidate": "n"
        },
        {
            "$": "Speech Perception",
            "@weight": "a",
            "@candidate": "n"
        }
    ]},
    "language": {"@xml:lang": "eng"},
    "authkeywords": {"author-keyword": [
        {
            "@_fa": "true",
            "$": "Convolutional Encode-Decoder"
        },
        {
            "@_fa": "true",
            "$": "Convolutional Recurrent Network"
        },
        {
            "@_fa": "true",
            "$": "E2E speech processing"
        },
        {
            "@_fa": "true",
            "$": "intelligibility"
        },
        {
            "@_fa": "true",
            "$": "speech quality"
        }
    ]},
    "subject-areas": {"subject-area": [
        {
            "@_fa": "true",
            "$": "Analytical Chemistry",
            "@code": "1602",
            "@abbrev": "CHEM"
        },
        {
            "@_fa": "true",
            "$": "Information Systems",
            "@code": "1710",
            "@abbrev": "COMP"
        },
        {
            "@_fa": "true",
            "$": "Atomic and Molecular Physics, and Optics",
            "@code": "3107",
            "@abbrev": "PHYS"
        },
        {
            "@_fa": "true",
            "$": "Biochemistry",
            "@code": "1303",
            "@abbrev": "BIOC"
        },
        {
            "@_fa": "true",
            "$": "Instrumentation",
            "@code": "3105",
            "@abbrev": "PHYS"
        },
        {
            "@_fa": "true",
            "$": "Electrical and Electronic Engineering",
            "@code": "2208",
            "@abbrev": "ENGI"
        }
    ]},
    "authors": {"author": [
        {
            "ce:given-name": "Rizwan",
            "preferred-name": {
                "ce:given-name": "Rizwan",
                "ce:initials": "R.",
                "ce:surname": "Ullah",
                "ce:indexed-name": "Ullah R."
            },
            "@seq": "1",
            "ce:initials": "R.",
            "@_fa": "true",
            "affiliation": {
                "@id": "60028190",
                "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60028190"
            },
            "ce:surname": "Ullah",
            "@auid": "58256620500",
            "author-url": "https://api.elsevier.com/content/author/author_id/58256620500",
            "ce:indexed-name": "Ullah R."
        },
        {
            "ce:given-name": "Lunchakorn",
            "preferred-name": {
                "ce:given-name": "Lunchakorn",
                "ce:initials": "L.",
                "ce:surname": "Wuttisittikulkij",
                "ce:indexed-name": "Wuttisittikulkij L."
            },
            "@seq": "2",
            "ce:initials": "L.",
            "@_fa": "true",
            "affiliation": {
                "@id": "60028190",
                "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60028190"
            },
            "ce:surname": "Wuttisittikulkij",
            "@auid": "6701827990",
            "author-url": "https://api.elsevier.com/content/author/author_id/6701827990",
            "ce:indexed-name": "Wuttisittikulkij L."
        },
        {
            "ce:given-name": "Sushank",
            "preferred-name": {
                "ce:given-name": "Sushank",
                "ce:initials": "S.",
                "ce:surname": "Chaudhary",
                "ce:indexed-name": "Chaudhary S."
            },
            "@seq": "3",
            "ce:initials": "S.",
            "@_fa": "true",
            "affiliation": {
                "@id": "60028190",
                "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60028190"
            },
            "ce:surname": "Chaudhary",
            "@auid": "56243987800",
            "author-url": "https://api.elsevier.com/content/author/author_id/56243987800",
            "ce:indexed-name": "Chaudhary S."
        },
        {
            "ce:given-name": "Amir",
            "preferred-name": {
                "ce:given-name": "Amir",
                "ce:initials": "A.",
                "ce:surname": "Parnianifard",
                "ce:indexed-name": "Parnianifard A."
            },
            "@seq": "4",
            "ce:initials": "A.",
            "@_fa": "true",
            "affiliation": {
                "@id": "60028190",
                "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60028190"
            },
            "ce:surname": "Parnianifard",
            "@auid": "57240218700",
            "author-url": "https://api.elsevier.com/content/author/author_id/57240218700",
            "ce:indexed-name": "Parnianifard A."
        },
        {
            "ce:given-name": "Shashi",
            "preferred-name": {
                "ce:given-name": "Shashi",
                "ce:initials": "S.",
                "ce:surname": "Shah",
                "ce:indexed-name": "Shah S."
            },
            "@seq": "5",
            "ce:initials": "S.",
            "@_fa": "true",
            "affiliation": {
                "@id": "60028190",
                "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60028190"
            },
            "ce:surname": "Shah",
            "@auid": "56890141600",
            "author-url": "https://api.elsevier.com/content/author/author_id/56890141600",
            "ce:indexed-name": "Shah S."
        },
        {
            "ce:given-name": "Muhammad",
            "preferred-name": {
                "ce:given-name": "Muhammad",
                "ce:initials": "M.",
                "ce:surname": "Ibrar",
                "ce:indexed-name": "Ibrar M."
            },
            "@seq": "6",
            "ce:initials": "M.",
            "@_fa": "true",
            "affiliation": {
                "@id": "60106555",
                "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60106555"
            },
            "ce:surname": "Ibrar",
            "@auid": "7801542125",
            "author-url": "https://api.elsevier.com/content/author/author_id/7801542125",
            "ce:indexed-name": "Ibrar M."
        },
        {
            "ce:given-name": "Fazal-E",
            "preferred-name": {
                "ce:given-name": "Fazal E.",
                "ce:initials": "F.E.",
                "ce:surname": "Wahab",
                "ce:indexed-name": "Wahab F.E."
            },
            "@seq": "7",
            "ce:initials": "F.-E.",
            "@_fa": "true",
            "affiliation": {
                "@id": "60133708",
                "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60133708"
            },
            "ce:surname": "Wahab",
            "@auid": "25226056000",
            "author-url": "https://api.elsevier.com/content/author/author_id/25226056000",
            "ce:indexed-name": "Wahab F.-E."
        }
    ]}
}}